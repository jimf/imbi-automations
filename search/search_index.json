{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Imbi Automations CLI","text":"<p>A comprehensive CLI framework for executing automated workflows across software project repositories with AI-powered transformations and deep integration to the Imbi DevOps Service Management Platform.</p>"},{"location":"#overview","title":"Overview","text":"<p>Imbi Automations enables bulk automation across your software projects with intelligent targeting, conditional execution, and powerful transformation capabilities. Built on a modern async Python architecture, it provides seamless integration with GitHub and the Imbi.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>GitHub Integration: Native GitHub API integration for comprehensive repository operations</li> <li>AI-Powered Transformations: Claude Code SDK for intelligent code changes</li> <li>Advanced Filtering: Target specific project subsets with multiple criteria</li> <li>Conditional Execution: Smart workflow execution based on repository state</li> <li>Batch Processing: Concurrent processing with resumption capabilities</li> <li>Template System: Jinja2-based file generation with full project context</li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":"<p>Across all of your software projects and repositories, Imbi Automations can automate the following tasks:</p> <ul> <li>Project Updates: Upgrade projects to the latest syntax, update dependencies, and fix CI/CD pipelines</li> <li>Project Migrations: Convert all projects from a language like JavaScript to TypeScript</li> <li>Standards Compliance: Identify and report on places where project standards are not being followed</li> <li>Project Analysis: Update Imbi Project Facts based on project analysis results</li> <li>Code Quality Improvements: Apply linting, formatting, and pre-commit hooks</li> <li>Infrastructure Updates: Modernize project configurations and tooling</li> <li>Project Reviews: Automated code reviews and code quality analysis</li> <li>Security Updates: Update dependencies with security patches</li> <li>Software Upgrades: Upgrade projects to newer software versions</li> </ul>"},{"location":"#real-life-examples","title":"Real Life Examples","text":"<p>At AWeber, we've used Imbi Automations to:</p> <ul> <li>Migrate several hundred projects from GitLab to GitHub, automating the transition from GitLab CI to GitHub Actions.</li> <li>Finish our Python 3.9 to 3.12 migration by updating all projects to use the latest syntax, tooling, and project standards.</li> <li>Update base Docker images across all projects in minutes instead of months.</li> <li>Scan all projects leveraging Claude Code, creating comprehensive AGENTS.md files for every project to ensure Agent readiness to work on project related tasks.</li> <li>Automate the scanning of our projects for standards compliance, updating Imbi project facts with the results.</li> </ul>"},{"location":"#action-types","title":"Action Types","text":"<p>The framework supports multiple transformation types:</p> <ul> <li>Callable Actions: Direct API method calls with dynamic parameters</li> <li>Claude Code Integration: Complex multi-file analysis and AI transformations</li> <li>Docker Operations: Container-based file extraction and manipulation</li> <li>File Actions: Copy, move, delete, and regex replacement operations</li> <li>Git Operations: Extract files from previous commits, clone repositories, etc.</li> <li>Imbi Actions: Update project facts</li> <li>Shell Commands: Execute arbitrary commands with template variables</li> </ul>"},{"location":"#installation","title":"Installation","text":""},{"location":"#from-pypi","title":"From PyPI","text":"<pre><code>pip install imbi-automations\n</code></pre>"},{"location":"#development-installation","title":"Development Installation","text":"<pre><code>git clone &lt;repository-url&gt;\ncd imbi-automations-cli\npip install -e .[dev]\npre-commit install\n</code></pre>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#1-configuration","title":"1. Configuration","text":"<p>Create a <code>config.toml</code> file with your API credentials:</p> <pre><code>[github]\napi_key = \"ghp_your_github_token\"\nhostname = \"github.com\"  # Optional, defaults to github.com\n\n[imbi]\napi_key = \"your-imbi-api-key\"\nhostname = \"imbi.example.com\"\n\n[claude_code]\nexecutable = \"claude\"  # Optional, defaults to 'claude'\n</code></pre>"},{"location":"#2-run-a-workflow","title":"2. Run a Workflow","text":"<p>Execute workflows across all your projects:</p> <pre><code># Run a specific workflow\nimbi-automations config.toml workflows/workflow-name --all-projects\n\n# Resume from a specific project (useful for large batches)\nimbi-automations config.toml workflows/workflow-name --all-projects --start-from-project my-project-slug\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<ul> <li>Architecture Guide: Comprehensive technical documentation</li> <li>Workflow Configuration: Creating and running workflows</li> <li>Workflow Actions: Complete action types reference</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.12 or higher</li> <li>Imbi project management system access</li> <li>GitHub API access (for GitHub workflows)</li> </ul>"},{"location":"architecture/","title":"Architecture Guide","text":"<p>This guide provides a comprehensive overview of the Imbi Automations CLI architecture, components, and implementation patterns.</p>"},{"location":"architecture/#system-overview","title":"System Overview","text":"<p>Imbi Automations is built on a modern async Python architecture designed for scalability, maintainability, and extensibility. The system follows a modular design with clear separation of concerns between different layers.</p>"},{"location":"architecture/#core-architecture-principles","title":"Core Architecture Principles","text":"<ul> <li>Async-First: Full async/await implementation with concurrent processing</li> <li>Modular Design: Clean separation between clients, models, and business logic</li> <li>Type Safety: Comprehensive type hints throughout the codebase</li> <li>Configuration-Driven: TOML-based workflows with Pydantic validation</li> <li>Extensible: Plugin-ready architecture for new action types and providers</li> </ul>"},{"location":"architecture/#component-architecture","title":"Component Architecture","text":""},{"location":"architecture/#primary-components","title":"Primary Components","text":""},{"location":"architecture/#cli-interface-clipy","title":"CLI Interface (<code>cli.py</code>)","text":"<p>The entry point for the application, responsible for: - Command-line argument parsing and validation - Colored logging configuration with different levels - Workflow validation and loading - Error handling and user feedback</p>"},{"location":"architecture/#controller-controllerpy","title":"Controller (<code>controller.py</code>)","text":"<p>Main automation controller implementing the iterator pattern: - Project iteration and filtering - Workflow orchestration across multiple targets - Concurrent processing with proper resource management - Progress tracking and resumption capabilities</p>"},{"location":"architecture/#workflow-engine-workflow_enginepy","title":"Workflow Engine (<code>workflow_engine.py</code>)","text":"<p>Core execution engine that handles: - Action execution with context management - Temporary directory handling for repository operations - Error recovery and action restart mechanisms - Template variable resolution with Jinja2 - Comprehensive logging and status reporting</p>"},{"location":"architecture/#client-layer","title":"Client Layer","text":"<p>The client layer provides abstraction for external service interactions:</p>"},{"location":"architecture/#http-client-clientshttppy","title":"HTTP Client (<code>clients/http.py</code>)","text":"<p>Base async HTTP client with: - Authentication handling for various providers - Automatic retry logic with exponential backoff - Request/response logging with credential sanitization - Error handling and timeout management</p>"},{"location":"architecture/#imbi-client-clientsimbipy","title":"Imbi Client (<code>clients/imbi.py</code>)","text":"<p>Integration with Imbi project management system: - Project data retrieval and filtering - Environment and metadata synchronization - Fact validation and updates via ImbiMetadataCache - Pagination handling for large datasets</p>"},{"location":"architecture/#github-client-clientsgithubpy","title":"GitHub Client (<code>clients/github.py</code>)","text":"<p>GitHub API integration featuring: - Repository and organization operations - Pattern-aware workflow file detection - Environment management - Pull request creation and management - Rate limiting and API quota management</p>"},{"location":"architecture/#data-models","title":"Data Models","text":"<p>All models use Pydantic for validation and type safety:</p>"},{"location":"architecture/#configuration-models-modelsconfigurationpy","title":"Configuration Models (<code>models/configuration.py</code>)","text":"<ul> <li>TOML-based configuration with secret handling</li> <li>Provider-specific settings (GitHub, Imbi)</li> <li>Claude Code SDK integration settings</li> <li>Validation rules and default values</li> </ul>"},{"location":"architecture/#workflow-models-modelsworkflowpy","title":"Workflow Models (<code>models/workflow.py</code>)","text":"<p>Comprehensive workflow definition including:</p> <ul> <li>Actions: Sequence of operations with type validation</li> <li>Conditions: Repository state requirements (local and remote)</li> <li>Filters: Project targeting and selection criteria</li> <li>Templates: Jinja2 template configurations</li> </ul>"},{"location":"architecture/#provider-models","title":"Provider Models","text":"<ul> <li>GitHub Models (<code>models/github.py</code>): Repository, organization, and API response models</li> <li>Imbi Models (<code>models/imbi.py</code>): Project management system models</li> </ul>"},{"location":"architecture/#supporting-components","title":"Supporting Components","text":""},{"location":"architecture/#imbi-metadata-cache-imcpy","title":"Imbi Metadata Cache (<code>imc.py</code>)","text":"<p>Cache (<code>ImbiMetadataCache</code>) for Imbi metadata with 15-minute TTL and safe-by-default design:</p> <ul> <li>Caches environments, project types, fact types</li> <li>Always initialized with empty collections (no <code>None</code> state)</li> <li>Enables parse-time validation of workflow filters</li> <li>Stored in <code>~/.cache/imbi-automations/metadata.json</code> (configurable)</li> <li>Auto-refreshes when expired via <code>refresh_from_cache()</code></li> <li>Provides fuzzy-matched suggestions for typos</li> <li>Graceful degradation: returns empty sets when unpopulated</li> </ul>"},{"location":"architecture/#actions-dispatcher-actions__init__py","title":"Actions Dispatcher (<code>actions/__init__.py</code>)","text":"<p>Centralized action execution using Python 3.12 match/case:</p> <ul> <li>Type-safe action routing to specialized handlers</li> <li>Callable, Claude, Docker, File, Git, GitHub, Imbi, Shell, Template actions</li> <li>Consistent error handling across action types</li> </ul>"},{"location":"architecture/#git-operations-gitpy","title":"Git Operations (<code>git.py</code>)","text":"<p>Comprehensive Git integration:</p> <ul> <li>Repository cloning with authentication</li> <li>Branch management and switching</li> <li>Commit creation via Committer class</li> <li>Uses <code>git add --all</code> for staging</li> <li>Tag and version handling</li> </ul>"},{"location":"architecture/#committer-committerpy","title":"Committer (<code>committer.py</code>)","text":"<p>Handles git commit operations:</p> <ul> <li>AI-powered commit message generation</li> <li>Manual commit messages with templates</li> <li>Proper author attribution</li> <li>Commit message formatting standards</li> </ul>"},{"location":"architecture/#condition-checker-condition_checkerpy","title":"Condition Checker (<code>condition_checker.py</code>)","text":"<p>Workflow condition evaluation:</p> <ul> <li>Local file system checks (post-clone)</li> <li>Remote repository checks via GitHub API (pre-clone)</li> <li>Regex pattern matching with string fallback</li> <li>Performance optimization with early filtering</li> </ul>"},{"location":"architecture/#actions-layer-actions","title":"Actions Layer (<code>actions/</code>)","text":"<p>Specialized action handlers:</p> <ul> <li>Callable (<code>actions/callablea.py</code>): Direct Python function/method invocation with async support and template rendering</li> <li>Claude (<code>actions/claude.py</code>): AI-powered transformations via Claude Code SDK</li> <li>Docker (<code>actions/docker.py</code>): Container operations and file extraction</li> <li>File (<code>actions/filea.py</code>): Copy (with globs), move, delete, regex replacement</li> <li>Git (<code>actions/git.py</code>): Revert, extract, branch management</li> <li>GitHub (<code>actions/github.py</code>): GitHub-specific operations</li> <li>Imbi (<code>actions/imbi.py</code>): Project fact management with validation</li> <li>Shell (<code>actions/shell.py</code>): Command execution via <code>subprocess_shell</code> (supports globs)</li> <li>Template (<code>actions/template.py</code>): Jinja2 rendering with workflow context</li> </ul>"},{"location":"architecture/#workflow-system","title":"Workflow System","text":""},{"location":"architecture/#workflow-structure","title":"Workflow Structure","text":"<p>Workflows are defined in TOML configuration files with three main sections:</p> <pre><code># Project filtering\n[filter]\nproject_ids = [123, 456]\nproject_types = [\"apis\", \"consumers\"]\ngithub_identifier_required = true\n\n# Execution conditions\n[[conditions]]\nremote_file_exists = \"package.json\"\n\n[[conditions]]\nfile_contains = \"python.*3\\\\.12\"\nfile = \"pyproject.toml\"\n\n# Action sequence\n[[actions]]\nname = \"update-dependencies\"\ntype = \"claude\"\n# ... action configuration\n</code></pre>"},{"location":"architecture/#action-types","title":"Action Types","text":""},{"location":"architecture/#1-callable-actions","title":"1. Callable Actions","text":"<p>Direct Python function/method invocation with async support: <pre><code>[[actions]]\nname = \"update-fact\"\ntype = \"callable\"\ncallable = \"imbi_automations.clients.imbi:Imbi.set_fact\"\nargs = [123, \"deployment_status\", \"completed\"]\nkwargs = {notes = \"{{ workflow.name }} finished\"}\nai_commit = true\n</code></pre></p>"},{"location":"architecture/#2-claude-code-integration","title":"2. Claude Code Integration","text":"<p>AI-powered transformations: <pre><code>[[actions]]\ntype = \"claude\"\ntask_prompt = \"prompts/update-readme.md\"\n</code></pre></p>"},{"location":"architecture/#3-file-operations","title":"3. File Operations","text":"<p>Direct file manipulation: <pre><code>[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"templates/config.yml\"\ndestination = \"repository:///config/production.yml\"\n</code></pre></p>"},{"location":"architecture/#4-shell-commands","title":"4. Shell Commands","text":"<p>Arbitrary command execution: <pre><code>[[actions]]\ntype = \"shell\"\ncommand = \"python -m pytest tests/\"\nworking_directory = \"repository:///\"\n</code></pre></p>"},{"location":"architecture/#condition-system","title":"Condition System","text":""},{"location":"architecture/#remote-conditions-pre-clone","title":"Remote Conditions (Pre-Clone)","text":"<p>Evaluated using provider APIs before repository cloning:</p> <ul> <li>Performance Benefit: Skip cloning for non-matching repositories</li> <li>Bandwidth Efficient: Reduce network usage for large batch operations</li> <li>Early Filtering: Fail fast before expensive operations</li> </ul> <pre><code>[[conditions]]\nremote_file_exists = \".github/workflows/ci.yml\"\n\n[[conditions]]\nremote_file_contains = \"python.*3\\\\.[0-9]+\"\nremote_file = \"pyproject.toml\"\n</code></pre>"},{"location":"architecture/#local-conditions-post-clone","title":"Local Conditions (Post-Clone)","text":"<p>Evaluated after repository cloning for complex analysis:</p> <ul> <li>Full Access: Complete repository content available</li> <li>Complex Patterns: Multi-file analysis and cross-references</li> <li>File Content Analysis: Deep inspection of file contents</li> </ul> <pre><code>[[conditions]]\nfile_exists = \"docker-compose.yml\"\n\n[[conditions]]\nfile_contains = \"FROM python:3\\\\.[0-9]+\"\nfile = \"Dockerfile\"\n</code></pre>"},{"location":"architecture/#template-system","title":"Template System","text":"<p>Jinja2-based template engine with full project context:</p>"},{"location":"architecture/#available-variables","title":"Available Variables","text":"<ul> <li><code>{{ imbi_project }}</code>: Complete Imbi project data</li> <li><code>{{ github_repository }}</code>: GitHub repository information</li> <li><code>{{ workflow_name }}</code>: Current workflow identifier</li> <li><code>{{ repository_path }}</code>: Local repository path</li> <li><code>{{ timestamp }}</code>: Execution timestamp</li> </ul>"},{"location":"architecture/#template-files","title":"Template Files","text":"<pre><code># Pull Request Template\n## Summary\nUpdating {{ imbi_project.name }} to use Python {{ target_version }}\n\n## Changes\n- Updated pyproject.toml Python version requirement\n- Modified GitHub Actions workflow\n- Updated Dockerfile base image\n\nGenerated by: {{ workflow_name }}\nDate: {{ timestamp }}\n</code></pre>"},{"location":"architecture/#error-handling-and-recovery","title":"Error Handling and Recovery","text":""},{"location":"architecture/#action-restart-mechanism","title":"Action Restart Mechanism","text":"<p>Actions support automatic restart on failure: <pre><code>[[actions]]\nname = \"fragile-operation\"\non_failure = \"cleanup-action\"  # Restart from this action\nmax_retries = 3\n</code></pre></p>"},{"location":"architecture/#failure-indication","title":"Failure Indication","text":"<ul> <li>Failure Files: Create specific failure files to signal workflow abortion</li> <li>Detailed Logging: Include actionable error information</li> <li>Recovery Strategies: Configurable retry mechanisms and <code>on_failure</code> action chains</li> </ul>"},{"location":"architecture/#resource-management","title":"Resource Management","text":"<ul> <li>Temporary Directory Cleanup: Automatic cleanup on success or failure</li> <li>Connection Pooling: Efficient HTTP connection reuse</li> <li>Memory Management: LRU caching for expensive operations</li> </ul>"},{"location":"architecture/#performance-optimizations","title":"Performance Optimizations","text":""},{"location":"architecture/#concurrent-processing","title":"Concurrent Processing","text":"<ul> <li>Batch Operations: Process multiple projects concurrently</li> <li>Connection Pooling: Reuse HTTP connections across requests</li> <li>Async Operations: Non-blocking I/O throughout the system</li> </ul>"},{"location":"architecture/#caching-strategy","title":"Caching Strategy","text":"<ul> <li>LRU Caching: Cache expensive API calls and computations</li> <li>Repository State: Cache repository metadata between operations</li> <li>Template Compilation: Pre-compile Jinja2 templates</li> </ul>"},{"location":"architecture/#early-filtering","title":"Early Filtering","text":"<ul> <li>Remote Conditions: Filter projects before cloning</li> <li>Project Filtering: Apply filters before workflow execution</li> <li>Resumption: Skip already processed projects</li> </ul>"},{"location":"architecture/#testing-architecture","title":"Testing Architecture","text":""},{"location":"architecture/#test-infrastructure","title":"Test Infrastructure","text":"<ul> <li>Base Class: <code>AsyncTestCase</code> for async test support</li> <li>HTTP Mocking: <code>httpx.MockTransport</code> with JSON fixtures</li> <li>Test Isolation: Clean state between test runs</li> <li>Coverage Requirements: Comprehensive test coverage with exclusions</li> </ul>"},{"location":"architecture/#mock-data-strategy","title":"Mock Data Strategy","text":"<ul> <li>Path-Based Fixtures: JSON files matching URL patterns</li> <li>Realistic Data: Production-like test data</li> <li>Edge Cases: Comprehensive error condition testing</li> </ul>"},{"location":"architecture/#integration-testing","title":"Integration Testing","text":"<ul> <li>End-to-End Workflows: Complete workflow execution tests</li> <li>Provider Integration: Real API integration tests (optional)</li> <li>Performance Testing: Load and concurrency testing</li> </ul>"},{"location":"architecture/#security-considerations","title":"Security Considerations","text":""},{"location":"architecture/#credential-management","title":"Credential Management","text":"<ul> <li>Secret Strings: Automatic credential masking in logs</li> <li>Configuration Validation: Secure handling of API keys</li> <li>Environment Variables: Support for environment-based configuration</li> </ul>"},{"location":"architecture/#api-security","title":"API Security","text":"<ul> <li>Authentication: Proper token and key management</li> <li>Rate Limiting: Respect provider API limits</li> <li>SSL/TLS: Secure communication with all external services</li> </ul>"},{"location":"architecture/#repository-security","title":"Repository Security","text":"<ul> <li>Temporary Directories: Secure cleanup of cloned repositories</li> <li>File Permissions: Proper permission handling</li> <li>Branch Protection: Safe branch and tag operations</li> </ul>"},{"location":"architecture/#extensibility","title":"Extensibility","text":""},{"location":"architecture/#adding-new-action-types","title":"Adding New Action Types","text":"<ol> <li>Create action handler in appropriate module</li> <li>Add action type to workflow model validation</li> <li>Implement action execution logic</li> <li>Add comprehensive tests</li> </ol>"},{"location":"architecture/#adding-new-providers","title":"Adding New Providers","text":"<ol> <li>Implement client interface in <code>clients/</code></li> <li>Create provider-specific models</li> <li>Add configuration support</li> <li>Implement authentication and API integration</li> </ol>"},{"location":"architecture/#custom-workflows","title":"Custom Workflows","text":"<ol> <li>Create workflow directory structure</li> <li>Define <code>config.toml</code> with actions and conditions</li> <li>Add template files if needed</li> <li>Test with target projects</li> </ol> <p>This architecture provides a solid foundation for scalable automation across software projects while maintaining flexibility for future enhancements and integrations.</p>"},{"location":"cli/","title":"Command-Line Interface","text":"<p>Imbi Automations provides a comprehensive CLI for executing workflows across projects with flexible targeting, concurrency control, and debugging capabilities.</p>"},{"location":"cli/#basic-usage","title":"Basic Usage","text":"<pre><code>imbi-automations CONFIG WORKFLOW [OPTIONS]\n</code></pre> <p>Arguments:</p> <ul> <li><code>CONFIG</code>: Path to configuration TOML file</li> <li><code>WORKFLOW</code>: Path to workflow directory containing config.toml</li> </ul> <p>Example: <pre><code>imbi-automations config.toml workflows/update-python --all-projects\n</code></pre></p>"},{"location":"cli/#complete-syntax","title":"Complete Syntax","text":"<pre><code>imbi-automations [-h] [-V] [--debug] [-v]\n                 [--max-concurrency N]\n                 [--exit-on-error]\n                 [--preserve-on-error]\n                 [--error-dir DIR]\n                 [--dry-run]\n                 [--dry-run-dir DIR]\n                 [--cache-dir DIR]\n                 [--start-from-project ID_OR_SLUG]\n                 (--project-id ID |\n                  --project-type SLUG |\n                  --all-projects |\n                  --github-repository URL |\n                  --github-organization ORG |\n                  --all-github-repositories)\n                 CONFIG WORKFLOW\n</code></pre>"},{"location":"cli/#positional-arguments","title":"Positional Arguments","text":""},{"location":"cli/#config","title":"CONFIG","text":"<p>Path to configuration file containing API credentials and settings.</p> <p>Type: File path Format: TOML file  </p> <p>Required: Yes  </p> <p>Example: <pre><code>imbi-automations config.toml workflows/my-workflow --all-projects\nimbi-automations /etc/imbi/prod.toml workflows/deploy --all-projects\n</code></pre></p> <p>See Also: Configuration Documentation</p>"},{"location":"cli/#workflow","title":"WORKFLOW","text":"<p>Path to workflow directory containing workflow configuration file.</p> <p>Type: Directory path Required: Yes Must Contain: <code>workflow.toml</code></p> <p>Example: <pre><code>imbi-automations config.toml workflows/update-python --all-projects\nimbi-automations config.toml ./my-workflow --project-id 123\n</code></pre></p> <p>Structure: <pre><code>workflows/my-workflow/\n\u251c\u2500\u2500 workflow.toml        # Required\n\u251c\u2500\u2500 prompts/             # Optional\n\u2502   \u2514\u2500\u2500 prompt.md\n\u2514\u2500\u2500 templates/           # Optional\n    \u2514\u2500\u2500 template.j2\n</code></pre></p>"},{"location":"cli/#targeting-options","title":"Targeting Options","text":"<p>Exactly one targeting option is required to specify which projects/repositories to process.</p>"},{"location":"cli/#-project-id-id","title":"--project-id ID","text":"<p>Process a single Imbi project by ID.</p> <p>Type: Integer Use Case: Testing workflows on specific project</p> <p>Example: <pre><code>imbi-automations config.toml workflows/fix-config --project-id 123\n</code></pre></p> <p>Output: <pre><code>Processing: my-project (123)\n\u2713 Completed: my-project\n</code></pre></p>"},{"location":"cli/#-project-type-slug","title":"--project-type SLUG","text":"<p>Process all Imbi projects of a specific type.</p> <p>Type: String (project type slug) Use Case: Target specific project categories</p> <p>Example: <pre><code>imbi-automations config.toml workflows/update-apis --project-type api\n</code></pre></p> <p>Common Project Types:</p> <ul> <li><code>api</code> - API services</li> <li><code>consumer</code> - Message consumers</li> <li><code>scheduled-job</code> - Scheduled tasks</li> <li><code>frontend</code> - Frontend applications</li> <li><code>library</code> - Shared libraries</li> </ul> <p>Output: <pre><code>Found 47 projects of type 'api'\nProcessing: api-service-1 (123)\nProcessing: api-service-2 (124)\n...\nCompleted: 45/47 projects successful\n</code></pre></p>"},{"location":"cli/#-all-projects","title":"--all-projects","text":"<p>Process all projects in Imbi.</p> <p>Type: Flag (boolean) Use Case: Batch updates across entire organization</p> <p>Example: <pre><code>imbi-automations config.toml workflows/update-deps --all-projects\n</code></pre></p> <p>Output: <pre><code>Found 664 total projects\nProcessing 664 projects...\n\u2713 Completed: 650/664 successful\n</code></pre></p> <p>Warning: This processes ALL projects. Use with caution and test workflow first with <code>--project-id</code>.</p>"},{"location":"cli/#-github-repository-url","title":"--github-repository URL","text":"<p>Process a single GitHub repository by URL.</p> <p>Type: URL string Format: <code>https://github.com/org/repo</code> or <code>org/repo</code> </p> <p>Use Case: Target specific GitHub repository</p> <p>Example: <pre><code>imbi-automations config.toml workflows/fix-actions \\\n  --github-repository https://github.com/myorg/myrepo\n</code></pre></p> <p>Accepted Formats: <pre><code>--github-repository https://github.com/org/repo\n--github-repository github.com/org/repo\n--github-repository org/repo\n</code></pre></p>"},{"location":"cli/#-github-organization-org","title":"--github-organization ORG","text":"<p>Process all repositories in a GitHub organization.</p> <p>Type: String (organization name) Use Case: Update all repos in an organization</p> <p>Example: <pre><code>imbi-automations config.toml workflows/update-workflows \\\n  --github-organization myorg\n</code></pre></p> <p>Output: <pre><code>Found 32 repositories in organization 'myorg'\nProcessing: myorg/repo1\nProcessing: myorg/repo2\n...\nCompleted: 30/32 successful\n</code></pre></p>"},{"location":"cli/#-all-github-repositories","title":"--all-github-repositories","text":"<p>Process all GitHub repositories across all organizations.</p> <p>Type: Flag (boolean) Use Case: Organization-wide GitHub updates</p> <p>Example: <pre><code>imbi-automations config.toml workflows/security-update \\\n  --all-github-repositories\n</code></pre></p> <p>Note: Discovers repositories from all organizations the API key has access to.  </p>"},{"location":"cli/#execution-control-options","title":"Execution Control Options","text":""},{"location":"cli/#-start-from-project-id_or_slug","title":"--start-from-project ID_OR_SLUG","text":"<p>Resume batch processing from a specific project.</p> <p>Type: Integer (ID) or String (slug) Use Case: Resume interrupted batch runs</p> <p>Example: <pre><code># By project ID\nimbi-automations config.toml workflows/update-all \\\n  --all-projects \\\n  --start-from-project 456\n\n# By project slug\nimbi-automations config.toml workflows/update-all \\\n  --all-projects \\\n  --start-from-project my-project-slug\n</code></pre></p> <p>Behavior: </p> <ul> <li>Skips all projects up to and including the specified project</li> <li>Starts processing from the next project</li> <li>Useful for resuming after interruption or failure</li> </ul> <p>Example Scenario: <pre><code># Initial run interrupted at project ID 456\nimbi-automations config.toml workflows/big-update --all-projects\n# ... processes projects 1-456, then interrupted\n\n# Resume from where it left off\nimbi-automations config.toml workflows/big-update \\\n  --all-projects \\\n  --start-from-project 456\n# ... starts from project 457\n</code></pre></p>"},{"location":"cli/#-max-concurrency-n","title":"--max-concurrency N","text":"<p>Set maximum number of concurrent workflow executions.</p> <p>Type: Integer Default: <code>1</code> (sequential) Range: 1-100 (practical limit depends on system resources)</p> <p>Example: <pre><code># Process 5 projects simultaneously\nimbi-automations config.toml workflows/update-deps \\\n  --all-projects \\\n  --max-concurrency 5\n</code></pre></p> <p>Performance Considerations:</p> Concurrency Use Case Memory Risk 1 Debugging, testing Low None 2-5 Normal batch processing Medium Low 10+ Large-scale updates High Higher 20+ Maximum throughput Very High Monitor carefully <p>Example Performance: <pre><code># Sequential (slower, safer)\n--max-concurrency 1\n# ~1 project/minute = 664 projects in 11 hours\n\n# Parallel (faster, more resources)\n--max-concurrency 10\n# ~10 projects/minute = 664 projects in 1.1 hours\n</code></pre></p> <p>Warning: Higher concurrency increases:</p> <ul> <li>Memory usage (each workflow uses ~100-500MB)</li> <li>API rate limit pressure</li> <li>Disk I/O (simultaneous git clones)</li> <li>Debugging complexity</li> </ul>"},{"location":"cli/#-exit-on-error","title":"--exit-on-error","text":"<p>Stop immediately when any project fails.</p> <p>Type: Flag (boolean) Default: <code>false</code> (continue with other projects)  </p> <p>Example: <pre><code>imbi-automations config.toml workflows/critical-update \\\n  --all-projects \\\n  --exit-on-error\n</code></pre></p> <p>Behavior: </p> <ul> <li>Without flag: Logs error, continues to next project</li> <li>With flag: Exits immediately with error code</li> </ul> <p>Use Cases: </p> <ul> <li>CI/CD pipelines requiring atomic success</li> <li>Testing workflows before batch runs</li> <li>Critical updates that must succeed for all projects</li> <li>Debugging specific failure</li> </ul> <p>Example Comparison: <pre><code># Default: continues on error\nimbi-automations config.toml workflows/update --all-projects\n# Processes all 664 projects even if some fail\n# Exit code: 0 if any succeeded\n\n# Exits on first error\nimbi-automations config.toml workflows/update --all-projects --exit-on-error\n# Stops at first failure\n# Exit code: 5 on failure\n</code></pre></p>"},{"location":"cli/#debugging-options","title":"Debugging Options","text":""},{"location":"cli/#-preserve-on-error","title":"--preserve-on-error","text":"<p>Save working directory state when workflows fail.</p> <p>Type: Flag (boolean) Default: <code>false</code> </p> <p>Example: <pre><code>imbi-automations config.toml workflows/failing-workflow \\\n  --project-id 123 \\\n  --preserve-on-error\n</code></pre></p> <p>What Gets Saved:</p> <ul> <li>Complete Git repository state</li> <li>Workflow resource files</li> <li>Docker extracted files</li> <li>All temporary files</li> <li><code>debug.log</code> with complete execution trace</li> </ul> <p>Storage Location: <code>./errors/workflow-name/project-slug-timestamp/</code></p> <p>See Also: Debugging Documentation</p>"},{"location":"cli/#-error-dir-dir","title":"--error-dir DIR","text":"<p>Specify directory for saving error states.</p> <p>Type: Directory path Default: <code>./errors</code> </p> <p>Example: <pre><code>imbi-automations config.toml workflows/test \\\n  --project-id 123 \\\n  --preserve-on-error \\\n  --error-dir /tmp/workflow-errors\n</code></pre></p> <p>Directory Structure: <pre><code>/tmp/workflow-errors/\n\u2514\u2500\u2500 workflow-name/\n    \u2514\u2500\u2500 project-slug-20250103-143052/\n        \u251c\u2500\u2500 repository/\n        \u251c\u2500\u2500 workflow/\n        \u2514\u2500\u2500 debug.log\n</code></pre></p>"},{"location":"cli/#-dry-run","title":"--dry-run","text":"<p>Execute workflows without pushing changes or creating pull requests.</p> <p>Type: Flag (boolean) Default: <code>false</code> </p> <p>Example: <pre><code>imbi-automations config.toml workflows/update-deps \\\n  --project-id 123 \\\n  --dry-run\n</code></pre></p> <p>Behavior: </p> <p>When enabled, the workflow executes normally including: - Cloning repositories - Running all actions - Making file changes - Creating commits locally</p> <p>But skips:</p> <ul> <li>Pushing commits to remote</li> <li>Creating pull requests</li> </ul> <p>Working directory is preserved to: <code>./dry-runs/workflow-name/project-slug-timestamp/</code></p> <p>Use Cases: </p> <ul> <li>Testing workflows before production runs</li> <li>Validating changes without affecting remote repositories</li> <li>Reviewing commit messages and file changes</li> <li>Debugging workflow logic safely</li> <li>Training and demonstration</li> </ul> <p>Example Output: <pre><code>Processing: my-project (123)\n\u2713 Cloned repository\n\u2713 Executed 5 actions\n\u2713 Created commit: \"Update dependencies\"\n\ud83d\udd0d dry-run mode: saving repository state to ./dry-runs\n\u2713 Completed: my-project (dry-run)\n</code></pre></p> <p>Inspection: <pre><code># View the commit that would have been pushed\ncd dry-runs/update-deps/my-project-20250103-143052/repository\ngit log -1\ngit show HEAD\n\n# View all changes\ngit diff HEAD~1\n</code></pre></p> <p>See Also: Debugging - Dry Run Mode</p>"},{"location":"cli/#-dry-run-dir-dir","title":"--dry-run-dir DIR","text":"<p>Specify directory for saving dry-run repository states.</p> <p>Type: Directory path Default: <code>./dry-runs</code></p> <p>Example: <pre><code>imbi-automations config.toml workflows/update \\\n  --all-projects \\\n  --dry-run \\\n  --dry-run-dir /tmp/review-changes\n</code></pre></p> <p>Docker: When running in Docker, use <code>--dry-run-dir /opt/dry-runs</code> and mount a host directory to <code>/opt/dry-runs</code> to persist dry-run artifacts outside the container.</p> <p>Directory Structure: <pre><code>/tmp/review-changes/\n\u2514\u2500\u2500 workflow-name/\n    \u2514\u2500\u2500 project-slug-20250103-143052/\n        \u251c\u2500\u2500 repository/        # Full git repository with commits\n        \u251c\u2500\u2500 workflow/          # Workflow files and templates\n        \u2514\u2500\u2500 extracted/         # Docker extracted files (if any)\n</code></pre></p> <p>Use Cases: </p> <ul> <li>Organize dry runs by date or workflow</li> <li>Review changes across multiple projects</li> <li>Share results with team for review</li> <li>Temporary storage for CI/CD validation</li> <li>Custom inspection pipelines</li> </ul> <p>Example with Batch Review: <pre><code># Run dry-run on all projects\nimbi-automations config.toml workflows/security-patch \\\n  --all-projects \\\n  --dry-run \\\n  --dry-run-dir ./review/$(date +%Y%m%d)\n\n# Review all changes\nfor dir in ./review/*/workflow-name/*/repository; do\n    echo \"=== $(basename $(dirname $dir)) ===\"\n    cd \"$dir\"\n    git log -1 --oneline\n    git diff HEAD~1 --stat\ndone\n</code></pre></p>"},{"location":"cli/#-cache-dir-dir","title":"--cache-dir DIR","text":"<p>Specify directory for Imbi metadata cache storage.</p> <p>Type: Directory path Default: <code>~/.cache/imbi-automations</code> </p> <p>Example: <pre><code>imbi-automations config.toml workflows/update \\\n  --all-projects \\\n  --cache-dir /tmp/imbi-cache\n</code></pre></p> <p>Use Cases: </p> <ul> <li>Custom cache location for multi-user systems</li> <li>Temporary cache for testing</li> <li>Network-mounted cache for shared environments</li> <li>CI/CD pipeline isolation</li> </ul> <p>Cache Contents:</p> <p>The cache directory will contain <code>metadata.json</code> with Imbi metadata including environments, project types, and fact type definitions. This cache is automatically refreshed every 15 minutes.</p> <p>See Also: Configuration - Imbi Metadata Cache</p>"},{"location":"cli/#-debug","title":"--debug","text":"<p>Enable DEBUG level logging for all components.</p> <p>Type: Flag (boolean) Default: <code>false</code> (INFO level)  </p> <p>Example: <pre><code>imbi-automations config.toml workflows/test \\\n  --project-id 123 \\\n  --debug\n</code></pre></p> <p>Output: <pre><code>2025-01-03 14:30:52 - imbi_automations.workflow_engine - DEBUG - Executing action: copy-files\n2025-01-03 14:30:52 - imbi_automations.actions.filea - DEBUG - Copying workflow:///template to repository:///config\n2025-01-03 14:30:52 - imbi_automations.utils - DEBUG - Resolved path: /tmp/workflow123/workflow/template\n</code></pre></p> <p>Log Categories:</p> <ul> <li>Action execution details</li> <li>HTTP requests/responses (API calls)</li> <li>Git operations</li> <li>File operations</li> <li>Template rendering</li> <li>Condition evaluation</li> </ul> <p>See Also: Debugging Documentation</p>"},{"location":"cli/#-v-verbose","title":"-v, --verbose","text":"<p>Show action start/end INFO messages.</p> <p>Type: Flag (boolean) Default: <code>false</code> </p> <p>Example: <pre><code>imbi-automations config.toml workflows/update \\\n  --project-id 123 \\\n  --verbose\n</code></pre></p> <p>Output: <pre><code>2025-01-03 14:30:50 - INFO - Starting action: backup-files\n2025-01-03 14:30:52 - INFO - Completed action: backup-files\n2025-01-03 14:30:52 - INFO - Starting action: update-configs\n</code></pre></p> <p>Difference from --debug:</p> <ul> <li><code>--verbose</code>: Action-level progress (cleaner output)</li> <li><code>--debug</code>: Everything (very detailed)</li> </ul>"},{"location":"cli/#general-options","title":"General Options","text":""},{"location":"cli/#-h-help","title":"-h, --help","text":"<p>Show help message and exit.</p> <p>Example: <pre><code>imbi-automations --help\n</code></pre></p>"},{"location":"cli/#-v-version","title":"-V, --version","text":"<p>Show version number and exit.</p> <p>Example: <pre><code>imbi-automations --version\n</code></pre></p> <p>Output: <pre><code>0.1.0\n</code></pre></p>"},{"location":"cli/#common-usage-patterns","title":"Common Usage Patterns","text":""},{"location":"cli/#test-on-single-project","title":"Test on Single Project","text":"<p>Test workflow before batch execution:</p> <pre><code>imbi-automations config.toml workflows/new-workflow \\\n  --project-id 123 \\\n  --preserve-on-error \\\n  --debug\n</code></pre>"},{"location":"cli/#dry-run-testing","title":"Dry Run Testing","text":"<p>Test workflow without making remote changes:</p> <pre><code># Single project dry run\nimbi-automations config.toml workflows/new-feature \\\n  --project-id 123 \\\n  --dry-run \\\n  --debug\n\n# Batch dry run for review\nimbi-automations config.toml workflows/update-all \\\n  --all-projects \\\n  --dry-run \\\n  --dry-run-dir ./review \\\n  --max-concurrency 5\n</code></pre>"},{"location":"cli/#batch-update-with-debugging","title":"Batch Update with Debugging","text":"<p>Process all projects with error preservation:</p> <pre><code>imbi-automations config.toml workflows/update-deps \\\n  --all-projects \\\n  --max-concurrency 5 \\\n  --preserve-on-error \\\n  --error-dir ./errors \\\n  --verbose\n</code></pre>"},{"location":"cli/#resume-interrupted-run","title":"Resume Interrupted Run","text":"<p>Continue from where you left off:</p> <pre><code>imbi-automations config.toml workflows/large-update \\\n  --all-projects \\\n  --start-from-project 456 \\\n  --max-concurrency 5\n</code></pre>"},{"location":"cli/#github-organization-update","title":"GitHub Organization Update","text":"<p>Update all repos in an organization:</p> <pre><code>imbi-automations config.toml workflows/update-actions \\\n  --github-organization myorg \\\n  --max-concurrency 3 \\\n  --verbose\n</code></pre>"},{"location":"cli/#critical-production-update","title":"Critical Production Update","text":"<p>Ensure all or nothing success:</p> <pre><code>imbi-automations config.toml workflows/security-patch \\\n  --all-projects \\\n  --exit-on-error \\\n  --preserve-on-error \\\n  --verbose\n</code></pre>"},{"location":"cli/#debugging-specific-failure","title":"Debugging Specific Failure","text":"<p>Deep dive into a failing project:</p> <pre><code>imbi-automations config.toml workflows/failing \\\n  --project-id 123 \\\n  --preserve-on-error \\\n  --error-dir ./debug \\\n  --debug \\\n  --verbose \\\n  --exit-on-error\n</code></pre>"},{"location":"cli/#project-type-targeted-update","title":"Project Type Targeted Update","text":"<p>Update only APIs:</p> <pre><code>imbi-automations config.toml workflows/update-api-configs \\\n  --project-type api \\\n  --max-concurrency 5 \\\n  --verbose\n</code></pre>"},{"location":"cli/#exit-codes","title":"Exit Codes","text":"Code Meaning 0 Success - all workflows completed successfully 1 Configuration error (invalid config, missing workflow) 2 Interrupted (Ctrl+C) 3 Runtime error (unexpected exception) 5 Workflow failure (one or more projects failed) <p>Example Usage in Scripts: <pre><code>#!/bin/bash\nimbi-automations config.toml workflows/update --all-projects\n\nif [ $? -eq 0 ]; then\n    echo \"All projects updated successfully\"\nelif [ $? -eq 5 ]; then\n    echo \"Some projects failed - check logs\"\n    exit 1\nelse\n    echo \"Fatal error - check configuration\"\n    exit 1\nfi\n</code></pre></p>"},{"location":"cli/#environment-variables","title":"Environment Variables","text":"<p>While not CLI switches, these environment variables affect behavior:</p> Variable Purpose Example <code>ANTHROPIC_API_KEY</code> Claude API key <code>sk-ant-api03-...</code> <code>GITHUB_TOKEN</code> GitHub API token (if not in config) <code>ghp_...</code> <code>IMBI_API_KEY</code> Imbi API key (if not in config) <code>uuid-here</code> <p>Example: <pre><code>export ANTHROPIC_API_KEY=\"sk-ant-api03-...\"\nexport GITHUB_TOKEN=\"ghp_...\"\n\nimbi-automations config.toml workflows/ai-workflow --all-projects\n</code></pre></p>"},{"location":"cli/#performance-tips","title":"Performance Tips","text":""},{"location":"cli/#optimize-concurrency","title":"Optimize Concurrency","text":"<p>Start conservative, increase gradually:</p> <pre><code># Test with 1\n--max-concurrency 1\n\n# Increase to 5\n--max-concurrency 5\n\n# Monitor system resources, adjust\n--max-concurrency 10\n</code></pre>"},{"location":"cli/#use-filtering","title":"Use Filtering","text":"<p>Reduce scope with workflow filters in <code>config.toml</code>:</p> <pre><code>[filter]\nproject_types = [\"api\", \"consumer\"]\ngithub_identifier_required = true\n</code></pre>"},{"location":"cli/#batch-smartly","title":"Batch Smartly","text":"<p>Split large runs into chunks:</p> <pre><code># Process 100 at a time\n--all-projects --max-concurrency 5 --start-from-project 0\n# ... after completion\n--all-projects --max-concurrency 5 --start-from-project 100\n</code></pre>"},{"location":"cli/#troubleshooting","title":"Troubleshooting","text":""},{"location":"cli/#no-module-named-imbi_automations","title":"\"No module named imbi_automations\"","text":"<p>Problem: CLI not installed or not in PATH</p> <p>Solution: <pre><code>pip install -e .\n# or\npip install imbi-automations\n</code></pre></p>"},{"location":"cli/#workflow-path-is-not-a-directory","title":"\"Workflow path is not a directory\"","text":"<p>Problem: Incorrect workflow path</p> <p>Solution: <pre><code># Correct - path to directory\nimbi-automations config.toml workflows/my-workflow --all-projects\n\n# Incorrect - don't include config.toml\nimbi-automations config.toml workflows/my-workflow/config.toml --all-projects\n</code></pre></p>"},{"location":"cli/#exactly-one-targeting-option-required","title":"\"Exactly one targeting option required\"","text":"<p>Problem: No targeting flag specified</p> <p>Solution: <pre><code># Must include one of:\n--project-id 123\n--project-type api\n--all-projects\n--github-repository org/repo\n# etc.\n</code></pre></p>"},{"location":"cli/#configuration-validation-failed","title":"\"Configuration validation failed\"","text":"<p>Problem: Invalid or missing config values</p> <p>Solution: <pre><code># Validate config separately\npython -c \"from imbi_automations.cli import load_configuration; load_configuration(open('config.toml'))\"\n</code></pre></p>"},{"location":"cli/#advanced-examples","title":"Advanced Examples","text":""},{"location":"cli/#parallel-processing-with-error-handling","title":"Parallel Processing with Error Handling","text":"<pre><code>imbi-automations config.toml workflows/complex-update \\\n  --all-projects \\\n  --max-concurrency 10 \\\n  --preserve-on-error \\\n  --error-dir /var/log/imbi-errors \\\n  --verbose \\\n  2&gt;&amp;1 | tee workflow.log\n</code></pre>"},{"location":"cli/#conditional-batch-processing","title":"Conditional Batch Processing","text":"<pre><code>#!/bin/bash\n# Process projects by type with different concurrency\nfor type in api consumer scheduled-job; do\n    echo \"Processing $type projects...\"\n    imbi-automations config.toml workflows/update \\\n        --project-type $type \\\n        --max-concurrency 5 \\\n        --verbose\ndone\n</code></pre>"},{"location":"cli/#error-analysis-pipeline","title":"Error Analysis Pipeline","text":"<pre><code>#!/bin/bash\n# Run workflow with error preservation\nimbi-automations config.toml workflows/update \\\n    --all-projects \\\n    --preserve-on-error \\\n    --error-dir ./errors\n\n# Analyze errors\necho \"Failed projects:\"\nfind ./errors -name \"debug.log\" -exec grep -l \"ERROR\" {} \\; | \\\n    sed 's|.*/\\(.*\\)-[0-9]*-[0-9]*/debug.log|\\1|'\n\n# Count by error type\necho \"\\nError types:\"\nfind ./errors -name \"debug.log\" -exec grep \"ERROR\" {} \\; | \\\n    cut -d: -f4 | sort | uniq -c\n</code></pre>"},{"location":"cli/#see-also","title":"See Also","text":"<ul> <li>Configuration - Configure API keys and settings</li> <li>Debugging - Detailed debugging guide</li> <li>Actions - Workflow action reference</li> <li>Architecture - System design and components</li> </ul>"},{"location":"configuration/","title":"Configuration File","text":"<p>Imbi Automations uses TOML-based configuration files with Pydantic validation for all settings. This document describes all available configuration options.</p>"},{"location":"configuration/#configuration-file-location","title":"Configuration File Location","text":"<p>By default, the CLI expects a <code>config.toml</code> file as the first argument:</p> <pre><code>imbi-automations config.toml workflows/workflow-name --all-projects\n</code></pre>"},{"location":"configuration/#complete-configuration-example","title":"Complete Configuration Example","text":"<pre><code># Global Settings\nai_commits = false\ndry_run = false\ndry_run_dir = \"./dry-runs\"\nerror_dir = \"./errors\"\npreserve_on_error = false\n\n# Anthropic API Configuration\n[anthropic]\napi_key = \"${ANTHROPIC_API_KEY}\"  # Or set directly\nbedrock = false\nmodel = \"claude-haiku-4-5-20251001\"\n\n# Claude Agent SDK Configuration\n[claude]\nexecutable = \"claude\"\nenabled = true\nmodel = \"claude-haiku-4-5\"\n\n# Git Configuration\n[git]\nuser_name = \"Imbi Automations\"\nuser_email = \"automations@imbi.ai\"\n\n# GitHub API Configuration\n[github]\ntoken = \"ghp_your_github_token\"\nhost = \"github.com\"\n\n# Imbi Project Management Configuration\n[imbi]\napi_key = \"your-imbi-api-key\"\nhostname = \"imbi.example.com\"\ngithub_identifier = \"github\"\ngithub_link = \"GitHub Repository\"\n</code></pre>"},{"location":"configuration/#global-settings","title":"Global Settings","text":""},{"location":"configuration/#ai_commits","title":"ai_commits","text":"<p>Enable AI-powered commit message generation.</p> <p>Type: <code>boolean</code> Default: <code>false</code> </p> <p>When enabled, uses Anthropic API to generate commit messages based on changes.</p> <pre><code>ai_commits = true\n</code></pre>"},{"location":"configuration/#error_dir","title":"error_dir","text":"<p>Directory to store error logs and debugging information when workflows fail.</p> <p>Type: <code>path</code> Default: <code>./errors</code> </p> <pre><code>error_dir = \"/var/log/imbi-automations/errors\"\n</code></pre>"},{"location":"configuration/#preserve_on_error","title":"preserve_on_error","text":"<p>Preserve working directories when errors occur for debugging.</p> <p>Type: <code>boolean</code> Default: <code>false</code> </p> <p>When <code>true</code>, temporary directories are not cleaned up after failures, allowing manual inspection.</p> <pre><code>preserve_on_error = true\n</code></pre>"},{"location":"configuration/#dry_run","title":"dry_run","text":"<p>Execute workflows without pushing changes or creating pull requests.</p> <p>Type: <code>boolean</code> Default: <code>false</code> </p> <p>When enabled, workflows execute completely (clone, actions, commits) but skip remote operations:</p> <pre><code>dry_run = true\n</code></pre> <p>Behavior:</p> <p>\u2713 Clones repositories \u2713 Runs all actions \u2713 Makes file changes \u2713 Creates commits locally \u2717 Skips pushing to remote \u2717 Skips creating pull requests  </p> <p>Use Cases:</p> <ul> <li>Testing new workflows safely</li> <li>Validating changes before production runs</li> <li>Reviewing commit messages and diffs</li> <li>Training and demonstration</li> <li>CI/CD validation pipelines</li> </ul> <p>Working directories are preserved to <code>dry_run_dir</code> for inspection.</p> <p>Note: Can be overridden by <code>--dry-run</code> CLI flag.  </p>"},{"location":"configuration/#dry_run_dir","title":"dry_run_dir","text":"<p>Directory for saving repository state during dry-run executions.</p> <p>Type: <code>path</code> Default: <code>./dry-runs</code> </p> <pre><code>dry_run_dir = \"./review-changes\"\n</code></pre> <p>Directory Structure: <pre><code>./review-changes/\n\u2514\u2500\u2500 workflow-name/\n    \u2514\u2500\u2500 project-slug-timestamp/\n        \u251c\u2500\u2500 repository/    # Full git repository with commits\n        \u251c\u2500\u2500 workflow/      # Workflow files and templates\n        \u2514\u2500\u2500 extracted/     # Docker extracted files (if any)\n</code></pre></p> <p>Example Inspection: <pre><code># View commits that would have been pushed\ncd ./dry-runs/update-deps/my-project-20250103-143052/repository\ngit log -1\ngit show HEAD\ngit diff HEAD~1\n</code></pre></p> <p>Note: Can be overridden by <code>--dry-run-dir</code> CLI flag.  </p>"},{"location":"configuration/#anthropic-configuration","title":"Anthropic Configuration","text":"<p>Configuration for Anthropic Claude API used in Claude actions and AI commit generation.</p>"},{"location":"configuration/#anthropicapi_key","title":"[anthropic].api_key","text":"<p>Anthropic API key for Claude models.</p> <p>Type: <code>string</code> (secret) Default: <code>$ANTHROPIC_API_KEY</code> environment variable Required: For Claude actions or <code>ai_commits = true</code> </p> <pre><code>[anthropic]\napi_key = \"sk-ant-api03-...\"\n</code></pre> <p>Or use environment variable: <pre><code>export ANTHROPIC_API_KEY=\"sk-ant-api03-...\"\n</code></pre></p>"},{"location":"configuration/#anthropicbedrock","title":"[anthropic].bedrock","text":"<p>Use AWS Bedrock instead of direct Anthropic API.</p> <p>Type: <code>boolean</code> Default: <code>false</code> </p> <pre><code>[anthropic]\nbedrock = true\n</code></pre> <p>Note: Requires AWS credentials configured separately.  </p>"},{"location":"configuration/#anthropicmodel","title":"[anthropic].model","text":"<p>Claude model to use for API requests.</p> <p>Type: <code>string</code> Default: <code>claude-haiku-4-5-20251001</code> </p> <pre><code>[anthropic]\nmodel = \"claude-opus-4-5\"\n</code></pre>"},{"location":"configuration/#claude-configuration","title":"Claude Configuration","text":"<p>Configuration for Claude Agent SDK integration.</p>"},{"location":"configuration/#claudeexecutable","title":"[claude].executable","text":"<p>Path or command name for Claude Code executable.</p> <p>Type: <code>string</code> Default: <code>claude</code></p> <pre><code>[claude]\nexecutable = \"/usr/local/bin/claude\"\n</code></pre>"},{"location":"configuration/#claudeenabled","title":"[claude].enabled","text":"<p>Enable Claude Code actions in workflows.</p> <p>Type: <code>boolean</code> Default: <code>true</code></p> <p>Set to <code>false</code> to disable all Claude actions:</p> <pre><code>[claude]\nenabled = false\n</code></pre>"},{"location":"configuration/#claudemodel","title":"[claude].model","text":"<p>Claude model to use for Claude Code SDK operations.</p> <p>Type: <code>string</code> Default: <code>claude-haiku-4-5</code> Environment Variable: <code>CLAUDE_MODEL</code></p> <pre><code>[claude]\nmodel = \"claude-sonnet-4-5\"\n</code></pre> <p>Available models include:</p> <ul> <li><code>claude-haiku-4-5</code> - Fast, cost-effective (default)</li> <li><code>claude-sonnet-4-5</code> - Balanced performance</li> <li><code>claude-opus-4-5</code> - Most capable</li> </ul>"},{"location":"configuration/#claudebase_prompt","title":"[claude].base_prompt","text":"<p>Custom base prompt file for Claude Code sessions.</p> <p>Type: <code>path</code> Default: <code>src/imbi_automations/prompts/claude.md</code></p> <pre><code>[claude]\nbase_prompt = \"/path/to/custom-prompt.md\"\n</code></pre>"},{"location":"configuration/#claudeplugins","title":"[claude].plugins","text":"<p>Plugin and marketplace configuration for Claude Code. These settings are merged with workflow-level plugin settings (workflow values take precedence).</p> <p>Type: <code>ClaudePluginConfig</code> object Default: Empty (no plugins)</p>"},{"location":"configuration/#claudepluginsenabled_plugins","title":"[claude.plugins].enabled_plugins","text":"<p>Enable or disable specific plugins from marketplaces.</p> <p>Type: <code>dict[string, boolean]</code> Format: <code>plugin-name@marketplace-name\" = true/false</code> </p> <pre><code>[claude.plugins.enabled_plugins]\n\"git-repository@aweber-marketplace\" = true\n\"python-developer@aweber-marketplace\" = true\n\"grafana-mcp@aweber-marketplace\" = false\n</code></pre>"},{"location":"configuration/#claudepluginsmarketplaces","title":"[claude.plugins.marketplaces]","text":"<p>Configure additional marketplace sources for plugins.</p> <p>Type: <code>dict[string, ClaudeMarketplace]</code> </p> <p>Each marketplace requires a <code>source</code> type and corresponding field:</p> Source Type Required Field Description <code>github</code> <code>repo</code> GitHub repository (e.g., <code>org/repo</code>) <code>git</code> <code>url</code> Any git URL <code>directory</code> <code>path</code> Local directory (development only) <pre><code># GitHub marketplace\n[claude.plugins.marketplaces.company-tools]\nsource = \"github\"\nrepo = \"company-org/claude-plugins\"\n\n# Git URL marketplace (e.g., GitHub Enterprise)\n[claude.plugins.marketplaces.enterprise-tools]\nsource = \"git\"\nurl = \"https://github.enterprise.com/org/claude-plugins.git\"\n\n# Local directory (development)\n[claude.plugins.marketplaces.dev-plugins]\nsource = \"directory\"\npath = \"/path/to/local/marketplace\"\n</code></pre>"},{"location":"configuration/#claudepluginslocal_plugins","title":"[[claude.plugins.local_plugins]]","text":"<p>Load local plugin directories directly via the Claude Agent SDK.</p> <p>Type: <code>list[ClaudeLocalPlugin]</code> </p> <pre><code>[[claude.plugins.local_plugins]]\npath = \"/path/to/local/plugin\"\n\n[[claude.plugins.local_plugins]]\npath = \"/another/plugin/directory\"\n</code></pre>"},{"location":"configuration/#complete-plugin-configuration-example","title":"Complete Plugin Configuration Example","text":"<pre><code>[claude]\nenabled = true\nmodel = \"claude-sonnet-4-5\"\n\n[claude.plugins.enabled_plugins]\n\"git-repository@aweber-marketplace\" = true\n\"python-developer@aweber-marketplace\" = true\n\"grafana-mcp@aweber-marketplace\" = false\n\n[claude.plugins.marketplaces.aweber-marketplace]\nsource = \"git\"\nurl = \"https://github.enterprise.com/claude/marketplace.git\"\n\n[claude.plugins.marketplaces.community]\nsource = \"github\"\nrepo = \"anthropics/claude-plugins\"\n\n[[claude.plugins.local_plugins]]\npath = \"/home/user/my-custom-plugin\"\n</code></pre>"},{"location":"configuration/#git-configuration","title":"Git Configuration","text":"<p>Configuration for git commit operations.</p>"},{"location":"configuration/#gituser_name","title":"[git].user_name","text":"<p>Git commit author name.</p> <p>Type: <code>string</code> Default: <code>Imbi Automations</code></p> <pre><code>[git]\nuser_name = \"Bot User\"\n</code></pre>"},{"location":"configuration/#gituser_email","title":"[git].user_email","text":"<p>Git commit author email address.</p> <p>Type: <code>string</code> Default: <code>automations@imbi.ai</code></p> <pre><code>[git]\nuser_email = \"bot@example.com\"\n</code></pre>"},{"location":"configuration/#gitgpg_sign","title":"[git].gpg_sign","text":"<p>Enable GPG signing for commits.</p> <p>Type: <code>boolean</code> Default: <code>false</code></p> <pre><code>[git]\ngpg_sign = true\nsigning_key = \"ABCD1234...\"\n</code></pre>"},{"location":"configuration/#gitgpg_format","title":"[git].gpg_format","text":"<p>GPG signing format.</p> <p>Type: <code>string</code> Default: <code>null</code> Options: <code>gpg</code>, <code>ssh</code>, <code>x509</code>, <code>openpgp</code></p> <pre><code>[git]\ngpg_format = \"ssh\"\n</code></pre>"},{"location":"configuration/#gitsigning_key","title":"[git].signing_key","text":"<p>GPG or SSH signing key identifier.</p> <p>Type: <code>string</code> Default: <code>null</code></p> <pre><code>[git]\nsigning_key = \"~/.ssh/id_ed25519.pub\"\n</code></pre>"},{"location":"configuration/#gitssh_program","title":"[git].ssh_program","text":"<p>SSH program for commit signing (for SSH signing with 1Password, etc.).</p> <p>Type: <code>string</code> Default: <code>null</code></p> <pre><code>[git]\ngpg_format = \"ssh\"\nssh_program = \"/Applications/1Password.app/Contents/MacOS/op-ssh-sign\"\n</code></pre>"},{"location":"configuration/#gitgpg_program","title":"[git].gpg_program","text":"<p>GPG program path for traditional GPG signing.</p> <p>Type: <code>string</code> Default: <code>null</code></p> <pre><code>[git]\ngpg_sign = true\ngpg_program = \"/usr/local/bin/gpg\"\n</code></pre>"},{"location":"configuration/#gitcommit_args","title":"[git].commit_args","text":"<p>Additional arguments to pass to git commit commands.</p> <p>Type: <code>string</code> Default: <code>\"\"</code></p> <pre><code>[git]\ncommit_args = \"--no-verify\"\n</code></pre>"},{"location":"configuration/#github-configuration","title":"GitHub Configuration","text":"<p>Configuration for GitHub API integration.</p>"},{"location":"configuration/#githubtoken","title":"[github].token","text":"<p>GitHub personal access token or fine-grained token.</p> <p>Type: <code>string</code> (secret) Required: For GitHub workflows</p> <p>Token Permissions Required:</p> <ul> <li><code>repo</code> - Full repository access</li> <li><code>workflow</code> - Update GitHub Actions workflows</li> <li><code>admin:org</code> - Manage organization (for environment sync)</li> </ul> <pre><code>[github]\ntoken = \"ghp_your_github_personal_access_token\"\n</code></pre>"},{"location":"configuration/#githubhost","title":"[github].host","text":"<p>GitHub hostname for Enterprise installations.</p> <p>Type: <code>string</code> Default: <code>github.com</code></p> <p>For GitHub Enterprise: <pre><code>[github]\nhost = \"github.enterprise.com\"\n</code></pre></p>"},{"location":"configuration/#imbi-configuration","title":"Imbi Configuration","text":"<p>Configuration for Imbi project management system integration.</p>"},{"location":"configuration/#imbiapi_key","title":"[imbi].api_key","text":"<p>Imbi API authentication key.</p> <p>Type: <code>string</code> (secret) Required: Always (core functionality)  </p> <pre><code>[imbi]\napi_key = \"your-imbi-api-key-uuid\"\n</code></pre>"},{"location":"configuration/#imbihostname","title":"[imbi].hostname","text":"<p>Imbi instance hostname.</p> <p>Type: <code>string</code> Required: Always  </p> <pre><code>[imbi]\nhostname = \"imbi.example.com\"\n</code></pre>"},{"location":"configuration/#imbi_identifier","title":"[imbi].*_identifier","text":"<p>Project identifier field names in Imbi for external systems.</p> <p>Type: <code>string</code> Defaults: </p> <ul> <li><code>github_identifier = \"github</code></li> <li><code>pagerduty_identifier = \"pagerduty</code></li> <li><code>sonarqube_identifier = \"sonarqube</code></li> <li><code>sentry_identifier = \"sentry</code></li> </ul> <p>These specify which Imbi project identifier fields contain external system references:</p> <pre><code>[imbi]\ngithub_identifier = \"github-id\"\n</code></pre>"},{"location":"configuration/#imbi_link","title":"[imbi].*_link","text":"<p>Link type names in Imbi for external system URLs.</p> <p>Type: <code>string</code> Defaults: </p> <ul> <li><code>github_link = \"GitHub Repository</code></li> <li><code>grafana_link = \"Grafana Dashboard</code></li> <li><code>pagerduty_link = \"PagerDuty</code></li> <li><code>sentry_link = \"Sentry</code></li> <li><code>sonarqube_link = \"SonarQube</code></li> </ul> <p>These specify the link type names used in Imbi to store external URLs:</p> <pre><code>[imbi]\ngithub_link = \"GitHub Repo\"\n</code></pre>"},{"location":"configuration/#imbi-metadata-cache","title":"Imbi Metadata Cache","text":"<p>The ImbiMetadataCache system caches Imbi metadata locally for improved performance and parse-time validation.</p>"},{"location":"configuration/#cache-location","title":"Cache Location","text":"<p>Path: <code>~/.cache/imbi-automations/metadata.json</code> (configurable via <code>cache_dir</code> setting or <code>--cache-dir</code> CLI option)  </p> <p>TTL: 15 minutes  </p> <p>Contents: </p> <ul> <li>Environments</li> <li>Project type slugs and IDs</li> <li>Fact type definitions with enums and ranges</li> <li>Enum values for fact validation</li> </ul>"},{"location":"configuration/#cache-behavior","title":"Cache Behavior","text":"<p>The metadata cache is automatically managed and safe by default:</p> <ul> <li>First run: Fetches all metadata from Imbi API</li> <li>Subsequent runs: Uses cached data if less than 15 minutes old</li> <li>Expired cache: Auto-refreshes from API</li> <li>Validation: Enables parse-time validation of workflow filters</li> <li>Uninitialized: Returns empty collections (graceful degradation)</li> </ul>"},{"location":"configuration/#configuring-cache-location","title":"Configuring Cache Location","text":"<p>Override the default cache directory in configuration:</p> <pre><code># Optional: Override cache directory\ncache_dir = \"/custom/path/to/cache\"\n</code></pre> <p>Or via CLI option:</p> <pre><code>imbi-automations config.toml workflows/workflow-name \\\n  --cache-dir /tmp/imbi-cache \\\n  --all-projects\n</code></pre>"},{"location":"configuration/#manual-cache-management","title":"Manual Cache Management","text":"<pre><code># View cache location\nls -lah ~/.cache/imbi-automations/\n\n# Clear cache (forces refresh on next run)\nrm ~/.cache/imbi-automations/metadata.json\n\n# View cache contents\ncat ~/.cache/imbi-automations/metadata.json | jq .\n</code></pre>"},{"location":"configuration/#benefits","title":"Benefits","text":"<ul> <li>Parse-time validation: Catches typos in <code>project_types</code> and <code>project_facts</code> before workflow execution</li> <li>Fuzzy suggestions: Provides helpful suggestions for misspelled values</li> <li>Reduced API calls: Avoids repeated metadata fetches</li> <li>Fast filter validation: Instant validation without network calls</li> </ul>"},{"location":"configuration/#environment-variables","title":"Environment Variables","text":"<p>All configuration sections support automatic environment variable loading via Pydantic Settings. Each section has a prefix:</p> Section Prefix Example Variable <code>[anthropic]</code> <code>ANTHROPIC_</code> <code>ANTHROPIC_API_KEY</code> <code>[claude]</code> <code>CLAUDE_</code> <code>CLAUDE_MODEL</code> <code>[git]</code> <code>GIT_</code> <code>GIT_USER_NAME</code> <code>[github]</code> <code>GH_</code> <code>GH_TOKEN</code> <code>[imbi]</code> <code>IMBI_</code> <code>IMBI_API_KEY</code> <p>For a complete reference of all available environment variables, see Environment Variables.</p>"},{"location":"configuration/#quick-example","title":"Quick Example","text":"<pre><code># Set required environment variables\nexport GH_TOKEN=\"ghp_xxxxxxxxxxxxxxxxxxxx\"\nexport IMBI_API_KEY=\"your-api-key-uuid\"\nexport IMBI_HOSTNAME=\"imbi.example.com\"\n</code></pre> <p>Then use empty sections in your config to load from environment:</p> <pre><code>[github]\n[imbi]\n</code></pre>"},{"location":"configuration/#minimal-configuration","title":"Minimal Configuration","text":"<p>The absolute minimum configuration for basic GitHub workflows:</p> <pre><code>[github]\ntoken = \"ghp_your_token\"\n\n[imbi]\napi_key = \"your-imbi-key\"\nhostname = \"imbi.example.com\"\n</code></pre>"},{"location":"configuration/#configuration-validation","title":"Configuration Validation","text":"<p>Configuration is validated at startup using Pydantic. Common errors:</p>"},{"location":"configuration/#missing-required-fields","title":"Missing Required Fields","text":"<pre><code>ValidationError: 1 validation error for Configuration\ngithub.token\n  field required (type=value_error.missing)\n</code></pre> <p>Solution: Add the required field to your config.toml</p>"},{"location":"configuration/#invalid-token-format","title":"Invalid Token Format","text":"<pre><code>ValidationError: 1 validation error for Configuration\ngithub.token\n  string does not match regex (type=value_error.str.regex)\n</code></pre> <p>Solution: Check API key format and validity</p>"},{"location":"configuration/#invalid-hostname","title":"Invalid Hostname","text":"<pre><code>ValidationError: 1 validation error for Configuration\nimbi.hostname\n  invalid hostname (type=value_error.url.host)\n</code></pre> <p>Solution: Use valid hostname without protocol (no <code>https://</code>)</p>"},{"location":"configuration/#security-best-practices","title":"Security Best Practices","text":""},{"location":"configuration/#api-key-storage","title":"API Key Storage","text":"<p>DO NOT commit API keys to version control:</p> <pre><code># \u274c BAD - Keys in config file\n[github]\ntoken = \"ghp_actual_key_here\"\n\n# \u2705 GOOD - Environment variables\n[github]\ntoken = \"${GITHUB_TOKEN}\"\n</code></pre>"},{"location":"configuration/#file-permissions","title":"File Permissions","text":"<p>Restrict config file permissions:</p> <pre><code>chmod 600 config.toml\n</code></pre>"},{"location":"configuration/#environment-variables_1","title":"Environment Variables","text":"<p>Set sensitive values via environment:</p> <pre><code>export GITHUB_TOKEN=\"ghp_...\"\nexport ANTHROPIC_API_KEY=\"sk-ant-...\"\nexport IMBI_API_KEY=\"uuid-here\"\n\nimbi-automations config.toml workflows/workflow-name --all-projects\n</code></pre>"},{"location":"configuration/#separate-configurations","title":"Separate Configurations","text":"<p>Use different config files for different environments:</p> <pre><code># Development\nimbi-automations config.dev.toml workflows/test\n\n# Production\nimbi-automations config.prod.toml workflows/deploy\n</code></pre>"},{"location":"configuration/#configuration-examples","title":"Configuration Examples","text":""},{"location":"configuration/#github-only-workflows","title":"GitHub Only Workflows","text":"<pre><code>[git]\nuser_name = \"GitHub Bot\"\nuser_email = \"bot@example.com\"\n\n[github]\ntoken = \"${GITHUB_TOKEN}\"\n\n[imbi]\napi_key = \"${IMBI_API_KEY}\"\nhostname = \"imbi.example.com\"\n</code></pre>"},{"location":"configuration/#github-enterprise","title":"GitHub Enterprise","text":"<pre><code>[github]\ntoken = \"${GITHUB_ENTERPRISE_TOKEN}\"\nhost = \"github.enterprise.com\"\n\n[imbi]\napi_key = \"${IMBI_API_KEY}\"\nhostname = \"imbi.example.com\"\n</code></pre>"},{"location":"configuration/#with-ai-features","title":"With AI Features","text":"<pre><code>ai_commits = true\n\n[anthropic]\napi_key = \"${ANTHROPIC_API_KEY}\"\nmodel = \"claude-sonnet-4-5-20250514\"\n\n[claude]\nenabled = true\nmodel = \"claude-sonnet-4-5\"\n\n[github]\ntoken = \"${GITHUB_TOKEN}\"\n\n[imbi]\napi_key = \"${IMBI_API_KEY}\"\nhostname = \"imbi.example.com\"\n</code></pre>"},{"location":"configuration/#with-debugging","title":"With Debugging","text":"<pre><code>preserve_on_error = true\nerror_dir = \"/tmp/imbi-errors\"\n\n[github]\ntoken = \"${GITHUB_TOKEN}\"\n\n[imbi]\napi_key = \"${IMBI_API_KEY}\"\nhostname = \"imbi.example.com\"\n</code></pre>"},{"location":"configuration/#with-dry-run-mode","title":"With Dry Run Mode","text":"<pre><code># Enable dry-run globally for safe testing\ndry_run = true\ndry_run_dir = \"./review-changes\"\n\n[github]\ntoken = \"${GITHUB_TOKEN}\"\n\n[imbi]\napi_key = \"${IMBI_API_KEY}\"\nhostname = \"imbi.example.com\"\n</code></pre> <p>All workflows will execute but skip pushing and PR creation. Review changes in <code>./review-changes/</code> before disabling dry-run mode.</p>"},{"location":"configuration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"configuration/#configuration-not-loading","title":"Configuration Not Loading","text":"<p>Problem: <code>FileNotFoundError: config.toml not found</code></p> <p>Solution: Provide full path to config file: <pre><code>imbi-automations /path/to/config.toml workflows/name --all-projects\n</code></pre></p>"},{"location":"configuration/#authentication-failures","title":"Authentication Failures","text":"<p>Problem: <code>401 Unauthorized</code> errors</p> <p>Solutions: 1. Verify API key is valid and not expired 2. Check API key has required permissions 3. Ensure environment variables are exported 4. Test API access manually with curl</p>"},{"location":"configuration/#invalid-toml-syntax","title":"Invalid TOML Syntax","text":"<p>Problem: <code>toml.decoder.TomlDecodeError</code></p> <p>Solutions: 1. Validate TOML syntax with online validator 2. Check for missing quotes around strings 3. Verify section headers use <code>[section]</code> format 4. Ensure key-value pairs use <code>key = \"value</code> format</p>"},{"location":"configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"configuration/#custom-error-directory-structure","title":"Custom Error Directory Structure","text":"<pre><code>error_dir = \"/var/log/imbi-automations/errors\"\n</code></pre> <p>Creates: <pre><code>/var/log/imbi-automations/errors/\n\u2514\u2500\u2500 workflow-name/\n    \u2514\u2500\u2500 project-slug-timestamp/\n        \u251c\u2500\u2500 repository/\n        \u251c\u2500\u2500 workflow/\n        \u2514\u2500\u2500 error.log\n</code></pre></p>"},{"location":"configuration/#custom-git-author-per-workflow","title":"Custom Git Author Per Workflow","text":"<p>Set in workflow config.toml instead:</p> <pre><code># workflows/my-workflow/config.toml\n[git]\nuser_name = \"Workflow Bot\"\nuser_email = \"workflow@example.com\"\n</code></pre> <p>Overrides global git author settings for that workflow only.</p>"},{"location":"configuration/#see-also","title":"See Also","text":"<ul> <li>Environment Variables - Complete environment variable reference</li> <li>Workflow Actions - Complete action configuration reference</li> <li>Architecture - System design and components</li> <li>GitHub Actions - GitHub-specific configuration</li> <li>Claude Actions - AI transformation configuration</li> </ul>"},{"location":"debugging/","title":"Debugging Workflows","text":"<p>Imbi Automations provides comprehensive debugging capabilities to troubleshoot workflow failures, including error preservation, detailed logging, and diagnostic tools.</p>"},{"location":"debugging/#quick-start","title":"Quick Start","text":"<p>To debug a failing workflow, use these flags together:</p> <pre><code>imbi-automations config.toml workflows/failing-workflow \\\n  --all-projects \\\n  --preserve-on-error \\\n  --error-dir ./debug \\\n  --debug \\\n  --verbose\n</code></pre> <p>This will:</p> <ul> <li><code>--preserve-on-error</code>: Save working directory state on failures</li> <li><code>--error-dir ./debug</code>: Store error states in <code>./debug/</code></li> <li><code>--debug</code>: Enable DEBUG level logging (all log messages)</li> <li><code>--verbose</code>: Show action start/end messages</li> </ul>"},{"location":"debugging/#debugging-flags","title":"Debugging Flags","text":""},{"location":"debugging/#-preserve-on-error","title":"--preserve-on-error","text":"<p>Preserves the complete working directory when a workflow fails, including: - Cloned repository state - Workflow resource files - Extracted Docker files - All intermediate files - <code>.state</code> file (MessagePack format) for resuming execution</p> <p>Usage: <pre><code>imbi-automations config.toml workflows/my-workflow \\\n  --all-projects \\\n  --preserve-on-error\n</code></pre></p> <p>Default: <code>false</code> (working directories are cleaned up)  </p> <p>When to Use:</p> <ul> <li>Investigating why a workflow failed</li> <li>Examining repository state at time of failure</li> <li>Debugging file operations</li> <li>Analyzing Claude action failures</li> <li>Need to resume workflow from failure point (see <code>--resume</code> below)</li> </ul>"},{"location":"debugging/#-error-dir","title":"--error-dir","text":"<p>Specifies where to save preserved error states.</p> <p>Usage: <pre><code>imbi-automations config.toml workflows/my-workflow \\\n  --all-projects \\\n  --preserve-on-error \\\n  --error-dir /tmp/imbi-errors\n</code></pre></p> <p>Default: <code>./errors</code> </p> <p>Directory Structure: <pre><code>errors/\n\u2514\u2500\u2500 workflow-name/\n    \u2514\u2500\u2500 project-slug-timestamp/\n        \u251c\u2500\u2500 repository/          # Cloned Git repository\n        \u251c\u2500\u2500 workflow/            # Workflow resources\n        \u251c\u2500\u2500 extracted/           # Docker extracted files (if any)\n        \u251c\u2500\u2500 debug.log            # Complete DEBUG level logs\n        \u251c\u2500\u2500 .state               # Resume state file (MessagePack binary)\n        \u2514\u2500\u2500 other temporary files\n</code></pre></p> <p>Example Paths: <pre><code>errors/\n\u2514\u2500\u2500 python39-project-fix/\n    \u251c\u2500\u2500 api-service-20250103-143052/\n    \u2502   \u251c\u2500\u2500 repository/\n    \u2502   \u251c\u2500\u2500 workflow/\n    \u2502   \u2514\u2500\u2500 debug.log\n    \u2514\u2500\u2500 consumer-app-20250103-143105/\n        \u251c\u2500\u2500 repository/\n        \u251c\u2500\u2500 workflow/\n        \u2514\u2500\u2500 debug.log\n</code></pre></p>"},{"location":"debugging/#-debug","title":"--debug","text":"<p>Enables DEBUG level logging for all components, showing detailed operation traces.</p> <p>Usage: <pre><code>imbi-automations config.toml workflows/my-workflow \\\n  --all-projects \\\n  --debug\n</code></pre></p> <p>Default: <code>false</code> (INFO level)  </p> <p>What Gets Logged:</p> <ul> <li>All action executions with parameters</li> <li>HTTP requests/responses</li> <li>Git operations</li> <li>File operations</li> <li>Template rendering</li> <li>Claude API interactions</li> <li>Condition evaluations</li> <li>All internal state changes</li> </ul> <p>Example Output: <pre><code>2025-01-03 14:30:52 - imbi_automations.workflow_engine - DEBUG - Executing action: copy-gitignore\n2025-01-03 14:30:52 - imbi_automations.actions.filea - DEBUG - Copying workflow:///.gitignore to repository:///.gitignore\n2025-01-03 14:30:52 - imbi_automations.utils - DEBUG - Resolved path: /tmp/workflow123/workflow/.gitignore\n2025-01-03 14:30:52 - imbi_automations.utils - DEBUG - Resolved path: /tmp/workflow123/repository/.gitignore\n</code></pre></p>"},{"location":"debugging/#-verbose","title":"--verbose","text":"<p>Shows action start/end messages at INFO level without full DEBUG output.</p> <p>Usage: <pre><code>imbi-automations config.toml workflows/my-workflow \\\n  --all-projects \\\n  --verbose\n</code></pre></p> <p>Default: <code>false</code> </p> <p>What Gets Logged:</p> <ul> <li>Action start messages</li> <li>Action completion messages</li> <li>Major workflow milestones</li> <li>Success/failure summaries</li> </ul> <p>Example Output: <pre><code>2025-01-03 14:30:50 - imbi_automations.workflow_engine - INFO - Starting action: backup-files\n2025-01-03 14:30:52 - imbi_automations.workflow_engine - INFO - Completed action: backup-files\n2025-01-03 14:30:52 - imbi_automations.workflow_engine - INFO - Starting action: ai-refactor\n</code></pre></p>"},{"location":"debugging/#-exit-on-error","title":"--exit-on-error","text":"<p>Stop processing immediately when any project fails instead of continuing with remaining projects.</p> <p>Usage: <pre><code>imbi-automations config.toml workflows/my-workflow \\\n  --all-projects \\\n  --exit-on-error\n</code></pre></p> <p>Default: <code>false</code> (continue with other projects)  </p> <p>When to Use:</p> <ul> <li>Testing workflows on small batches</li> <li>CI/CD environments</li> <li>When failures are critical</li> <li>Debugging specific project issues</li> </ul>"},{"location":"debugging/#-resume","title":"--resume","text":"<p>Resume workflow execution from a previously preserved error state.</p> <p>Usage: <pre><code># First run that fails with --preserve-on-error\nimbi-automations config.toml workflows/my-workflow \\\n  --project-id 123 \\\n  --preserve-on-error\n\n# Resume from the preserved error directory\nimbi-automations config.toml workflows/my-workflow \\\n  --resume ./errors/my-workflow/project-slug-20251026-150000\n</code></pre></p> <p>Default: Not set (normal execution)  </p> <p>Requirements:</p> <ul> <li>Error directory must contain <code>.state</code> file</li> <li>Original workflow must have used <code>--preserve-on-error</code></li> <li>Must run from same machine (absolute paths in state)</li> </ul> <p>Behavior: </p> <ul> <li>Reuses exact preserved working directory (repository, workflow, extracted files)</li> <li>Retries from the failed action (not the next action)</li> <li>Skips remote/local conditions (already validated)</li> <li>Skips git clone (repository already present)</li> <li>Warns if configuration changed since original run</li> <li>Cleans up preserved state after successful completion</li> </ul> <p>When to Use:</p> <ul> <li>Workflow failed due to transient issues (network, API limits)</li> <li>Need to investigate failure before retrying</li> <li>Manual fixes required before retry (e.g., fix pre-commit hooks)</li> <li>Multi-retry debugging of same failure</li> </ul> <p>Limitations:</p> <ul> <li>Single-project only (no <code>--all-projects</code> with <code>--resume</code>)</li> <li>Requires same machine (absolute paths)</li> <li>Configuration changes between runs may cause issues (warning shown)</li> </ul>"},{"location":"debugging/#dry-run-mode","title":"Dry Run Mode","text":"<p>The <code>--dry-run</code> flag executes workflows without pushing changes or creating pull requests, useful for testing and validation.</p> <p>Usage: <pre><code>imbi-automations config.toml workflows/my-workflow \\\n  --project-id 123 \\\n  --dry-run\n</code></pre></p> <p>Behavior: </p> <ul> <li>Clones repositories and executes all actions normally</li> <li>Creates commits locally</li> <li>Skips pushing to remote and creating PRs</li> <li>Preserves working directory to <code>./dry-runs/</code> (or <code>--dry-run-dir</code>)</li> </ul> <p>Use Cases: </p> <ul> <li>Testing workflows before production runs</li> <li>Validating changes without affecting remote repositories</li> <li>Reviewing commit messages and file changes</li> <li>Training and demonstration</li> </ul> <p>Inspecting Results: <pre><code>cd dry-runs/workflow-name/project-slug-timestamp/repository/\ngit log -1          # View commit that would be pushed\ngit show HEAD       # View commit details\ngit diff HEAD~1     # View all changes\n</code></pre></p> <p>See Also: CLI Reference - --dry-run for complete options</p>"},{"location":"debugging/#debuglog-file","title":"debug.log File","text":"<p>When <code>--preserve-on-error</code> is enabled, a <code>debug.log</code> file is automatically created in each error directory containing ALL DEBUG level logs for that specific project execution.</p>"},{"location":"debugging/#contents","title":"Contents","text":"<p>The <code>debug.log</code> file includes:</p> <ul> <li>Complete action execution trace</li> <li>All HTTP API requests and responses</li> <li>File operations with full paths</li> <li>Git commands and output</li> <li>Template rendering details</li> <li>Claude/Anthropic API interactions</li> <li>Error messages and stack traces</li> <li>Timing information</li> </ul>"},{"location":"debugging/#format","title":"Format","text":"<pre><code>2025-01-03 14:30:50,123 - imbi_automations.controller - INFO - Processing my-project (123)\n2025-01-03 14:30:50,456 - imbi_automations.git - DEBUG - Cloning repository: https://github.com/org/repo.git\n2025-01-03 14:30:52,789 - imbi_automations.workflow_engine - DEBUG - Executing action: copy-files\n2025-01-03 14:30:52,890 - imbi_automations.actions.filea - DEBUG - Copying workflow:///templates/ to repository:///config/\n2025-01-03 14:30:53,123 - imbi_automations.actions.filea - ERROR - Failed to copy: Source directory not found\n</code></pre>"},{"location":"debugging/#location","title":"Location","text":"<pre><code># Default location\n./errors/workflow-name/project-slug-timestamp/debug.log\n\n# Custom error-dir\n/tmp/debug/workflow-name/project-slug-timestamp/debug.log\n</code></pre>"},{"location":"debugging/#per-project-isolation","title":"Per-Project Isolation","text":"<p>Each project execution gets its own <code>debug.log</code> file, even when running workflows concurrently with <code>--max-concurrency &gt; 1</code>. This is achieved using Python's <code>contextvars</code> to isolate log captures per async task.</p>"},{"location":"debugging/#error-directory-contents","title":"Error Directory Contents","text":"<p>When a workflow fails and <code>--preserve-on-error</code> is enabled, the error directory contains:</p>"},{"location":"debugging/#repository","title":"repository/","text":"<p>Complete clone of the Git repository at the point of failure: - All files in their current state - <code>.git/</code> directory with full history - Working tree changes (staged and unstaged) - Any files created by workflow actions</p> <p>Use Cases: </p> <ul> <li>Examine file modifications made by actions</li> <li>Check what Claude Code changed</li> <li>Review git history and commits</li> <li>Test fixes locally</li> </ul> <pre><code>cd errors/workflow-name/project-slug-timestamp/repository/\ngit log\ngit diff HEAD\ngit status\n</code></pre>"},{"location":"debugging/#workflow","title":"workflow/","text":"<p>Copy of workflow resources: - Template files - Prompt files - Static resources - Any files copied from workflow directory</p> <p>Use Cases: </p> <ul> <li>Verify template content</li> <li>Check prompt files</li> <li>Review workflow resources</li> </ul>"},{"location":"debugging/#extracted-if-present","title":"extracted/ (if present)","text":"<p>Files extracted from Docker containers by docker actions: - Configuration files - Binary artifacts - Library files</p> <p>Use Cases: </p> <ul> <li>Verify Docker extraction worked</li> <li>Check extracted file contents</li> <li>Debug docker action issues</li> </ul>"},{"location":"debugging/#debuglog","title":"debug.log","text":"<p>Complete DEBUG level logs (see above section).</p>"},{"location":"debugging/#state-if-present","title":".state (if present)","text":"<p>MessagePack binary file containing resume state: - Workflow and project identification - Failed action index and name - Completed action indices - WorkflowContext restoration data - Configuration hash for compatibility checking - Error details (message, timestamp)</p> <p>Use Cases: </p> <ul> <li>Resume workflow from failure point using <code>--resume</code></li> <li>Inspect state with msgpack-tools: <code>msgpack-python -d &lt; .state</code></li> <li>Verify configuration compatibility before retry</li> </ul> <p>Note: <code>.state</code> file only created when using <code>--preserve-on-error</code> </p>"},{"location":"debugging/#other-files","title":"Other Files","text":"<p>Any temporary files created during workflow execution: - Action-specific output files - Intermediate processing files - Failure indicator files (e.g., <code>ACTION_FAILED</code>)</p>"},{"location":"debugging/#common-debugging-scenarios","title":"Common Debugging Scenarios","text":""},{"location":"debugging/#debugging-failed-actions","title":"Debugging Failed Actions","text":"<p>Scenario: An action fails and you need to understand why.</p> <p>Steps: 1. Run with error preservation:    <pre><code>imbi-automations config.toml workflows/my-workflow \\\n  --project-id 123 \\\n  --preserve-on-error \\\n  --debug\n</code></pre></p> <ol> <li> <p>Check console output for immediate errors</p> </li> <li> <p>Examine the error directory:    <pre><code>cd errors/my-workflow/project-name-*\ncat debug.log | grep ERROR\n</code></pre></p> </li> <li> <p>Review repository state:    <pre><code>cd repository/\ngit status\ngit log -1\n</code></pre></p> </li> <li> <p>Check for failure files:    <pre><code>find . -name \"*FAILED\"\ncat ACTION_FAILED  # If exists\n</code></pre></p> </li> </ol>"},{"location":"debugging/#debugging-claude-actions","title":"Debugging Claude Actions","text":"<p>Scenario: Claude Code action fails or produces unexpected results.</p> <p>Steps: 1. Enable full debugging:    <pre><code>imbi-automations config.toml workflows/claude-workflow \\\n  --project-id 123 \\\n  --preserve-on-error \\\n  --debug \\\n  --verbose\n</code></pre></p> <ol> <li> <p>Check <code>debug.log</code> for Claude interactions:    <pre><code>cd errors/claude-workflow/project-*\ngrep -A 10 \"Claude\" debug.log\ngrep -A 5 \"Anthropic\" debug.log\n</code></pre></p> </li> <li> <p>Review the prompt sent to Claude:    <pre><code>grep -B 5 -A 20 \"Execute agent prompt\" debug.log\n</code></pre></p> </li> <li> <p>Check for failure files:    <pre><code>ls repository/*FAILED\ncat repository/ACTION_FAILED\n</code></pre></p> </li> <li> <p>Examine repository changes:    <pre><code>cd repository/\ngit diff\n</code></pre></p> </li> </ol>"},{"location":"debugging/#debugging-file-actions","title":"Debugging File Actions","text":"<p>Scenario: File copy/move operations aren't working as expected.</p> <p>Steps: 1. Run with verbose debugging:    <pre><code>imbi-automations config.toml workflows/file-workflow \\\n  --project-id 123 \\\n  --preserve-on-error \\\n  --debug\n</code></pre></p> <ol> <li> <p>Check resolved paths in <code>debug.log</code>:    <pre><code>grep \"Resolved path\" debug.log\ngrep \"Copying\\|Moving\\|Writing\" debug.log\n</code></pre></p> </li> <li> <p>Verify file existence:    <pre><code>cd errors/file-workflow/project-*/\nls -laR repository/\nls -laR workflow/\n</code></pre></p> </li> <li> <p>Check for permission or path errors:    <pre><code>grep \"Permission denied\\|No such file\" debug.log\n</code></pre></p> </li> </ol>"},{"location":"debugging/#debugging-template-actions","title":"Debugging Template Actions","text":"<p>Scenario: Templates aren't rendering correctly or variables are undefined.</p> <p>Steps: 1. Enable debugging:    <pre><code>imbi-automations config.toml workflows/template-workflow \\\n  --project-id 123 \\\n  --preserve-on-error \\\n  --debug\n</code></pre></p> <ol> <li> <p>Check template rendering in logs:    <pre><code>grep \"Template\\|Jinja2\" debug.log\n</code></pre></p> </li> <li> <p>Examine rendered output:    <pre><code>cd errors/template-workflow/project-*/repository/\ncat rendered-file.yaml\n</code></pre></p> </li> <li> <p>Review workflow template files:    <pre><code>cd ../workflow/\ncat template-file.j2\n</code></pre></p> </li> <li> <p>Check for undefined variable errors:    <pre><code>grep \"undefined\\|UndefinedError\" debug.log\n</code></pre></p> </li> </ol>"},{"location":"debugging/#debugging-shell-actions","title":"Debugging Shell Actions","text":"<p>Scenario: Shell commands fail or produce unexpected output.</p> <p>Steps: 1. Enable debugging:    <pre><code>imbi-automations config.toml workflows/shell-workflow \\\n  --project-id 123 \\\n  --preserve-on-error \\\n  --debug\n</code></pre></p> <ol> <li> <p>Check command execution in logs:    <pre><code>grep \"Executing shell command\\|Command stdout\\|Command stderr\" debug.log\n</code></pre></p> </li> <li> <p>Re-run command manually:    <pre><code>cd errors/shell-workflow/project-*/repository/\n# Copy command from debug.log and run it\npytest tests/ -v\n</code></pre></p> </li> <li> <p>Check exit codes:    <pre><code>grep \"exit code\" debug.log\n</code></pre></p> </li> </ol>"},{"location":"debugging/#debugging-concurrent-execution","title":"Debugging Concurrent Execution","text":"<p>Scenario: Running with <code>--max-concurrency &gt; 1</code> and need to debug specific project.</p> <p>Steps: 1. First, identify the failing project in normal execution 2. Re-run with just that project:    <pre><code>imbi-automations config.toml workflows/my-workflow \\\n  --project-id 123 \\\n  --preserve-on-error \\\n  --debug \\\n  --exit-on-error\n</code></pre></p> <ol> <li>Each project gets isolated <code>debug.log</code> even in concurrent mode</li> <li>Check error directory for all failed projects:    <pre><code>ls -ltr errors/my-workflow/\n</code></pre></li> </ol>"},{"location":"debugging/#resuming-failed-workflows","title":"Resuming Failed Workflows","text":"<p>Scenario: Workflow failed and you want to retry from the point of failure without re-running successful actions.</p> <p>Steps: 1. Run workflow with error preservation:    <pre><code>imbi-automations config.toml workflows/my-workflow \\\n  --project-id 123 \\\n  --preserve-on-error \\\n  --debug\n</code></pre></p> <ol> <li> <p>Workflow fails and creates preserved state:    <pre><code>errors/my-workflow/project-slug-20251026-150000/\n\u251c\u2500\u2500 repository/\n\u251c\u2500\u2500 workflow/\n\u251c\u2500\u2500 .state\n\u2514\u2500\u2500 debug.log\n</code></pre></p> </li> <li> <p>Examine the failure:    <pre><code>cd errors/my-workflow/project-slug-20251026-150000\ncat debug.log | grep ERROR\ncd repository &amp;&amp; git status\n</code></pre></p> </li> <li> <p>Fix any external issues (if needed):</p> </li> <li>Network problems resolved</li> <li>API rate limits lifted</li> <li>Pre-commit hooks fixed</li> <li> <p>Manual file edits if necessary</p> </li> <li> <p>Resume from the preserved state:    <pre><code>imbi-automations config.toml workflows/my-workflow \\\n  --resume ./errors/my-workflow/project-slug-20251026-150000\n</code></pre></p> </li> <li> <p>On success, preserved directory automatically cleaned up</p> </li> </ol> <p>Benefits:</p> <ul> <li>Skips successful actions (no re-execution)</li> <li>Reuses exact repository state at failure</li> <li>No need to re-clone or re-run conditions</li> <li>Can retry multiple times from same state</li> </ul> <p>Common Resume Scenarios:</p> <ul> <li>Transient Network Failure: API call failed, network restored, retry</li> <li>Pre-commit Hook Failure: Fixed ruff/linting issues, retry commit</li> <li>API Rate Limit: Waited for rate limit reset, retry</li> <li>Manual Investigation: Made manual fixes to repository, retry workflow</li> </ul>"},{"location":"debugging/#configuration-file-debugging","title":"Configuration File Debugging","text":"<p>You can also set error preservation in <code>config.toml</code>:</p> <pre><code>preserve_on_error = true\nerror_dir = \"/var/log/imbi-errors\"\n</code></pre> <p>Note: CLI flags override config file settings.  </p>"},{"location":"debugging/#log-levels","title":"Log Levels","text":"<p>Imbi Automations uses Python's standard logging levels:</p> Level Description When to Use DEBUG All operations and internal state Debugging failures INFO Major milestones and progress Normal operation WARNING Recoverable issues Monitoring ERROR Action failures Alert on issues CRITICAL Fatal errors System failures <p>Set via CLI: <pre><code># DEBUG level\n--debug\n\n# INFO level (default)\n# No flag needed\n\n# INFO level with action details\n--verbose\n</code></pre></p>"},{"location":"debugging/#performance-impact","title":"Performance Impact","text":""},{"location":"debugging/#-preserve-on-error_1","title":"--preserve-on-error","text":"<p>Impact: Minimal during execution, significant on failure</p> <ul> <li>No overhead during successful workflows</li> <li>On failure: Copies entire working directory (can be large)</li> <li>Storage: Requires disk space for preserved directories</li> </ul> <p>Recommendation: Enable for debugging, disable for production batch processing</p>"},{"location":"debugging/#-debug_1","title":"--debug","text":"<p>Impact: Moderate logging overhead</p> <ul> <li>Increases log volume significantly</li> <li>Slightly slower due to additional logging calls</li> <li>Memory impact from buffering logs</li> </ul> <p>Recommendation: Use for troubleshooting specific issues, not for large batch runs</p>"},{"location":"debugging/#-verbose_1","title":"--verbose","text":"<p>Impact: Minimal</p> <ul> <li>Only logs action start/end messages</li> <li>Negligible performance impact</li> </ul> <p>Recommendation: Safe to use in production</p>"},{"location":"debugging/#cleaning-up-error-directories","title":"Cleaning Up Error Directories","text":"<p>Error directories accumulate over time. Clean them periodically:</p> <pre><code># Remove all error directories\nrm -rf errors/\n\n# Remove errors older than 7 days\nfind errors/ -type d -mtime +7 -exec rm -rf {} +\n\n# Remove errors for specific workflow\nrm -rf errors/workflow-name/\n\n# Keep only latest N errors per workflow\ncd errors/workflow-name/\nls -t | tail -n +6 | xargs rm -rf\n</code></pre>"},{"location":"debugging/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Start Small: Debug single projects before batch runs    <pre><code>--project-id 123 --preserve-on-error --debug\n</code></pre></p> </li> <li> <p>Isolate Issues: Use <code>--exit-on-error</code> when debugging    <pre><code>--all-projects --exit-on-error --preserve-on-error\n</code></pre></p> </li> <li> <p>Review Logs First: Check <code>debug.log</code> before examining files    <pre><code>grep ERROR errors/workflow/project/debug.log\n</code></pre></p> </li> <li> <p>Clean Up Regularly: Remove old error directories    <pre><code>find errors/ -mtime +7 -delete\n</code></pre></p> </li> <li> <p>Use Specific Targeting: Debug exact failing project    <pre><code>--project-id 123  # Instead of --all-projects\n</code></pre></p> </li> <li> <p>Disable in Production: Don't preserve errors for large batch runs    <pre><code># Production: no preserve-on-error\nimbi-automations config.toml workflows/prod --all-projects\n</code></pre></p> </li> <li> <p>Combine Flags Effectively:    <pre><code># Maximum debugging\n--preserve-on-error --debug --verbose --exit-on-error\n\n# Light debugging\n--verbose\n\n# Specific issue\n--project-id 123 --preserve-on-error --debug\n</code></pre></p> </li> </ol>"},{"location":"debugging/#troubleshooting-the-debugger","title":"Troubleshooting the Debugger","text":""},{"location":"debugging/#error-directories-not-created","title":"Error Directories Not Created","text":"<p>Problem: <code>--preserve-on-error</code> set but no directories in <code>errors/</code></p> <p>Causes:</p> <ul> <li>Workflow succeeded (no errors to preserve)</li> <li>Insufficient permissions to create directories</li> <li>Disk space full</li> </ul> <p>Solution: <pre><code># Check permissions\nls -ld errors/\nmkdir -p errors/test\n\n# Check disk space\ndf -h .\n\n# Try explicit error-dir\n--error-dir /tmp/imbi-errors\n</code></pre></p>"},{"location":"debugging/#debuglog-missing-or-empty","title":"debug.log Missing or Empty","text":"<p>Problem: Error directory created but <code>debug.log</code> missing</p> <p>Causes:</p> <ul> <li>Failure occurred before logging started</li> <li>Logging not properly initialized</li> <li>Concurrent execution issue</li> </ul> <p>Solution: <pre><code># Run single-threaded\n--max-concurrency 1\n\n# Ensure debug logging\n--debug --preserve-on-error\n</code></pre></p>"},{"location":"debugging/#too-much-log-output","title":"Too Much Log Output","text":"<p>Problem: <code>--debug</code> generates too much output</p> <p>Solution: <pre><code># Use --verbose instead for less output\n--verbose\n\n# Or filter debug output\n--debug 2&gt;&amp;1 | grep -v \"anthropic\\|httpx\\|httpcore\"\n</code></pre></p>"},{"location":"debugging/#see-also","title":"See Also","text":"<ul> <li>Configuration - Configure error directories in config.toml</li> <li>Architecture - Understanding workflow execution</li> <li>Actions - Action-specific debugging tips</li> </ul>"},{"location":"docker/","title":"Docker","text":"<p>This guide covers running imbi-automations in Docker containers.</p> <p>Pre-built images are available from Docker Hub and GitHub Container Registry:</p> <ul> <li><code>aweber/imbi-automations:latest</code></li> <li><code>ghcr.io/aweber-imbi/imbi-automations:latest</code></li> </ul>"},{"location":"docker/#running-workflows","title":"Running Workflows","text":"<pre><code>docker run --rm \\\n    -v $(pwd)/config.toml:/opt/config/config.toml:ro \\\n    -v $(pwd)/workflows:/opt/workflows:ro \\\n    -v ~/.ssh:/home/imbi-automations/.ssh:ro \\\n    -e ANTHROPIC_API_KEY=\"$ANTHROPIC_API_KEY\" \\\n    -e IMBI_API_KEY=\"$IMBI_API_KEY\" \\\n    -e GH_TOKEN=\"$GH_TOKEN\" \\\n    aweber/imbi-automations:latest \\\n    /opt/config/config.toml \\\n    /opt/workflows/my-workflow \\\n    --all-projects\n</code></pre>"},{"location":"docker/#volume-mounts","title":"Volume Mounts","text":"Path Purpose Notes <code>/opt/config/config.toml</code> Configuration file Mount as read-only <code>/opt/workflows</code> Workflow definitions Mount as read-only <code>/home/imbi-automations/.ssh</code> SSH keys Mount as read-only; enables commit signing <code>/opt/dry-runs</code> Dry-run artifacts Mount if using <code>--dry-run</code> <code>/opt/errors</code> Error preservation Mount if using <code>--preserve-on-error</code> <code>/docker-entrypoint-init.d</code> Initialization scripts See Initialization Directory"},{"location":"docker/#environment-variables","title":"Environment Variables","text":""},{"location":"docker/#required-variables","title":"Required Variables","text":"<p>The following environment variables must be set when running the container. The entrypoint will exit with an error if any are missing:</p> Variable Description <code>ANTHROPIC_API_KEY</code> Anthropic API key for Claude <code>IMBI_API_KEY</code> Imbi API key <code>GH_TOKEN</code> GitHub personal access token <p>Note</p> <p>These variables are required even if the same values are specified in the configuration file. When running in Docker, the configuration file does not need to include <code>anthropic.api_key</code>, <code>imbi.api_key</code>, or <code>github.token</code> - they are automatically loaded from environment variables via pydantic-settings.</p>"},{"location":"docker/#optional-variables","title":"Optional Variables","text":"Variable Default Description <code>GIT_USER_NAME</code> <code>Imbi Automations</code> Git commit author name <code>GIT_USER_EMAIL</code> <code>imbi-automations@aweber.com</code> Git commit author email <code>GH_HOST</code> <code>github.com</code> GitHub hostname (for GitHub Enterprise)"},{"location":"docker/#ssh-commit-signing","title":"SSH Commit Signing","text":"<p>When SSH keys are mounted to <code>/home/imbi-automations/.ssh</code>, the entrypoint automatically configures git commit signing:</p> <ul> <li>Searches for keys in order: <code>id_ed25519</code>, <code>id_rsa</code>, <code>id_ecdsa</code></li> <li>Configures <code>gpg.format ssh</code> and <code>commit.gpgsign true</code></li> <li>Creates an <code>allowed_signers</code> file for verification</li> </ul> <p>Ensure your SSH key permissions are correct before mounting:</p> <pre><code>chmod 600 ~/.ssh/id_ed25519\nchmod 700 ~/.ssh\n</code></pre> <p>Note</p> <p>For GitHub to verify signed commits, add the same SSH key as a \"Signing Key\" in your GitHub account settings (separate from authentication keys).</p>"},{"location":"docker/#github-cli-authentication","title":"GitHub CLI Authentication","text":"<p>The <code>gh</code> CLI is pre-installed. Authentication is configured automatically using one of these methods (in order of precedence):</p> <ol> <li>Environment variable: Set <code>GH_TOKEN</code> when running the container</li> <li>Token file: Mount a file containing the token to <code>/config/gh-token</code> or <code>~/.config/gh/token</code></li> </ol>"},{"location":"docker/#using-environment-variable","title":"Using Environment Variable","text":"<pre><code>docker run --rm \\\n    -e GH_TOKEN=\"ghp_your_personal_access_token\" \\\n    aweber/imbi-automations:latest ...\n</code></pre>"},{"location":"docker/#using-token-file","title":"Using Token File","text":"<pre><code># Create token file\necho \"ghp_your_token\" &gt; gh-token\n\n# Mount it\ndocker run --rm \\\n    -v $(pwd)/gh-token:/config/gh-token:ro \\\n    aweber/imbi-automations:latest ...\n</code></pre>"},{"location":"docker/#required-token-scopes","title":"Required Token Scopes","text":"<p>For full functionality, your token needs:</p> <ul> <li><code>repo</code> - Repository access</li> <li><code>read:org</code> - Organization membership (for org repos)</li> <li><code>workflow</code> - GitHub Actions (if syncing workflows)</li> </ul>"},{"location":"docker/#initialization-directory","title":"Initialization Directory","text":"<p>The container supports an initialization directory at <code>/docker-entrypoint-init.d/</code> for installing additional packages or running setup scripts at container startup. This pattern is similar to database images like PostgreSQL's <code>/docker-entrypoint-initdb.d</code>.</p> <p>Files are processed in sorted order (use numeric prefixes for ordering) and support three extensions:</p> Extension Purpose Processing <code>.apt</code> System packages Installed via <code>apt-get install</code> <code>.pip</code> Python packages Installed via <code>pip install -r</code> <code>.sh</code> Shell scripts Executed with <code>bash</code>"},{"location":"docker/#example-files","title":"Example Files","text":"<p><code>10-system.apt</code> - System packages (one per line, comments supported):</p> <pre><code># Build dependencies\nbuild-essential\nlibpq-dev\n\n# Other tools\njq\n</code></pre> <p><code>20-python.pip</code> - Python packages (standard requirements format):</p> <pre><code>pandas&gt;=2.0\nsqlalchemy\nrequests\n</code></pre> <p><code>30-custom.sh</code> - Custom setup script:</p> <pre><code>#!/bin/bash\nnpm install -g some-tool\n</code></pre>"},{"location":"docker/#usage","title":"Usage","text":"<p>Mount individual files:</p> <pre><code>docker run --rm \\\n    -v ./my-packages.apt:/docker-entrypoint-init.d/10-packages.apt:ro \\\n    -v ./requirements.pip:/docker-entrypoint-init.d/20-python.pip:ro \\\n    aweber/imbi-automations:latest ...\n</code></pre> <p>Or mount a directory containing multiple init files:</p> <pre><code>docker run --rm \\\n    -v ./init.d:/docker-entrypoint-init.d:ro \\\n    aweber/imbi-automations:latest ...\n</code></pre>"},{"location":"docker/#docker-compose-example","title":"Docker Compose Example","text":"<pre><code>services:\n  imbi-automations:\n    image: aweber/imbi-automations:latest\n    volumes:\n      - ./config.toml:/opt/config/config.toml:ro\n      - ./workflows:/opt/workflows:ro\n      - ./init.d:/docker-entrypoint-init.d:ro\n</code></pre> <p>Note</p> <p>Initialization runs on every container start. For production workflows with many dependencies, consider building a custom image instead.</p>"},{"location":"docker/#debugging","title":"Debugging","text":""},{"location":"docker/#interactive-shell","title":"Interactive Shell","text":"<pre><code>docker run --rm -it \\\n    -v $(pwd)/config.toml:/opt/config/config.toml:ro \\\n    -v $(pwd)/workflows:/opt/workflows:ro \\\n    --entrypoint /bin/bash \\\n    aweber/imbi-automations:latest\n</code></pre>"},{"location":"docker/#view-entrypoint-output","title":"View Entrypoint Output","text":"<p>The entrypoint logs configuration steps to stderr:</p> <pre><code>Configuring git commit signing with SSH key: /home/imbi-automations/.ssh/id_ed25519\nLoaded GitHub token from /config/gh-token\n</code></pre>"},{"location":"docker/#verify-configuration","title":"Verify Configuration","text":"<p>Inside the container:</p> <pre><code># Check git signing config\ngit config --global --list | grep -E \"(gpg|sign)\"\n\n# Verify gh authentication\ngh auth status\n\n# Test SSH connection\nssh -T git@github.com\n</code></pre>"},{"location":"docker/#wrapper-script-example","title":"Wrapper Script Example","text":"<p>For repeated use, create a wrapper script that handles image updates, authentication, and volume mounts:</p> <pre><code>#!/bin/bash\nset -e\n\nWORKFLOW=$1\nshift\n\n# Always ensure the latest image is pulled\ndocker pull aweber/imbi-automations:latest\n\n# Refresh AWS SSO credentials if using AWS Bedrock\naws sts get-caller-identity --profile my-profile &gt; /dev/null\nexport $(aws configure export-credentials --format env --profile my-profile)\n\ndocker run --rm -t --group-add staff \\\n    -v $(pwd)/.ssh:/home/imbi-automations/.ssh:ro \\\n    -v $(pwd)/config.toml:/opt/config/config.toml:ro \\\n    -v $(pwd)/docker-entrypoint-init.d:/docker-entrypoint-init.d:ro \\\n    -v $(pwd)/dry-runs:/opt/dry-runs \\\n    -v $(pwd)/errors:/opt/errors \\\n    -v $(pwd):/opt/workflows:ro \\\n    -v /var/run/docker.sock:/var/run/docker.sock:rw \\\n    -e AWS_ACCESS_KEY_ID \\\n    -e AWS_SECRET_ACCESS_KEY \\\n    -e AWS_SESSION_TOKEN \\\n    -e GH_HOST=github.example.com \\\n    -e GIT_USER_NAME=\"Your Name\" \\\n    -e GIT_USER_EMAIL=\"you@example.com\" \\\n    --env-file .env \\\n    aweber/imbi-automations:latest \\\n    /opt/config/config.toml \\\n    /opt/workflows/${WORKFLOW} \\\n    \"$@\"\n</code></pre> <p>Key features of this script:</p> <ul> <li>Pulls the latest image before each run</li> <li>Refreshes AWS SSO credentials for Bedrock access</li> <li>Uses <code>--env-file .env</code> to load secrets (containing <code>ANTHROPIC_API_KEY</code>, <code>IMBI_API_KEY</code>, <code>GH_TOKEN</code>)</li> <li>Mounts Docker socket for workflows that use Docker actions</li> <li>Passes additional arguments to the workflow via <code>\"$@\"</code></li> </ul> <p>Usage:</p> <pre><code>./run-workflow.sh my-workflow --all-projects\n./run-workflow.sh my-workflow --project-id 123\n</code></pre>"},{"location":"docker/#docker-compose-example_1","title":"Docker Compose Example","text":"<pre><code>services:\n  imbi-automations:\n    image: aweber/imbi-automations:latest\n    volumes:\n      - ./config.toml:/opt/config/config.toml:ro\n      - ./workflows:/opt/workflows:ro\n      - ./.ssh:/home/imbi-automations/.ssh:ro\n      - ./docker-entrypoint-init.d:/docker-entrypoint-init.d:ro\n      - ./dry-runs:/opt/dry-runs\n      - ./errors:/opt/errors\n      - /var/run/docker.sock:/var/run/docker.sock:rw\n    env_file:\n      - .env\n    environment:\n      # Optional overrides\n      - GIT_USER_NAME=Imbi Automations\n      - GIT_USER_EMAIL=imbi-automations@example.com\n</code></pre> <p>Run with:</p> <pre><code>docker compose run --rm imbi-automations \\\n    /opt/config/config.toml \\\n    /opt/workflows/my-workflow \\\n    --all-projects\n</code></pre>"},{"location":"environment-variables/","title":"Environment Variables","text":"<p>Imbi Automations supports configuration through environment variables. These can be used instead of or in addition to the TOML configuration file. Environment variables take precedence when a configuration section is not explicitly defined in the config file.</p>"},{"location":"environment-variables/#quick-reference","title":"Quick Reference","text":"Variable Description Required <code>ANTHROPIC_API_KEY</code> Anthropic API key for Claude For AI features <code>GH_TOKEN</code> GitHub personal access token For GitHub workflows <code>IMBI_API_KEY</code> Imbi API authentication key Always <code>IMBI_HOSTNAME</code> Imbi instance hostname Always"},{"location":"environment-variables/#how-environment-variables-work","title":"How Environment Variables Work","text":"<p>Each configuration section uses a prefix for its environment variables:</p> Section Prefix Example <code>[anthropic]</code> <code>ANTHROPIC_</code> <code>ANTHROPIC_API_KEY</code> <code>[claude]</code> <code>CLAUDE_</code> <code>CLAUDE_MODEL</code> <code>[git]</code> <code>GIT_</code> <code>GIT_USER_NAME</code> <code>[github]</code> <code>GH_</code> <code>GH_TOKEN</code> <code>[imbi]</code> <code>IMBI_</code> <code>IMBI_API_KEY</code> <p>Environment variables are case-insensitive and support <code>.env</code> file loading.</p>"},{"location":"environment-variables/#anthropic-configuration","title":"Anthropic Configuration","text":"<p>Environment variables for Anthropic Claude API integration.</p> Variable Type Default Description <code>ANTHROPIC_API_KEY</code> secret - Anthropic API key for Claude models <code>ANTHROPIC_BEDROCK</code> boolean <code>false</code> Use AWS Bedrock instead of direct API <code>ANTHROPIC_MODEL</code> string <code>claude-haiku-4-5-20251001</code> Claude model to use <p>Example: <pre><code>export ANTHROPIC_API_KEY=\"sk-ant-api03-...\"\nexport ANTHROPIC_MODEL=\"claude-sonnet-4-20250514\"\n</code></pre></p>"},{"location":"environment-variables/#claude-agent-sdk-configuration","title":"Claude Agent SDK Configuration","text":"<p>Environment variables for Claude Agent SDK integration.</p> Variable Type Default Description <code>CLAUDE_EXECUTABLE</code> string <code>claude</code> Path to Claude Code executable <code>CLAUDE_BASE_PROMPT</code> path (built-in) Custom base prompt file path <code>CLAUDE_ENABLED</code> boolean <code>true</code> Enable Claude Code actions <code>CLAUDE_MODEL</code> string <code>claude-haiku-4-5</code> Model for Claude Agent SDK <p>Example: <pre><code>export CLAUDE_EXECUTABLE=\"/usr/local/bin/claude\"\nexport CLAUDE_MODEL=\"claude-sonnet-4-5\"\nexport CLAUDE_ENABLED=\"true\"\n</code></pre></p>"},{"location":"environment-variables/#git-configuration","title":"Git Configuration","text":"<p>Environment variables for git commit operations.</p> Variable Type Default Description <code>GIT_USER_NAME</code> string <code>Imbi Automations</code> Git commit author name <code>GIT_USER_EMAIL</code> string <code>automations@imbi.ai</code> Git commit author email <code>GIT_GPG_SIGN</code> boolean <code>false</code> Enable GPG signing for commits <code>GIT_GPG_FORMAT</code> string - Signing format: <code>gpg</code>, <code>ssh</code>, <code>x509</code>, <code>openpgp</code> <code>GIT_SIGNING_KEY</code> string - GPG or SSH signing key identifier <code>GIT_SSH_PROGRAM</code> string - SSH program for signing <code>GIT_GPG_PROGRAM</code> string - GPG program path <code>GIT_COMMIT_ARGS</code> string <code>\"\"</code> Additional git commit arguments <p>Example: <pre><code>export GIT_USER_NAME=\"CI Bot\"\nexport GIT_USER_EMAIL=\"ci-bot@example.com\"\nexport GIT_GPG_SIGN=\"true\"\nexport GIT_GPG_FORMAT=\"ssh\"\nexport GIT_SIGNING_KEY=\"~/.ssh/id_ed25519.pub\"\n</code></pre></p>"},{"location":"environment-variables/#github-configuration","title":"GitHub Configuration","text":"<p>Environment variables for GitHub API integration.</p> Variable Type Default Description <code>GH_TOKEN</code> secret required GitHub personal access token <code>GH_HOST</code> string <code>github.com</code> GitHub hostname (for Enterprise) <p>Example: <pre><code>export GH_TOKEN=\"ghp_xxxxxxxxxxxxxxxxxxxx\"\nexport GH_HOST=\"github.enterprise.com\"\n</code></pre></p> <p>Token Permissions Required:</p> <ul> <li><code>repo</code> - Full repository access</li> <li><code>workflow</code> - Update GitHub Actions workflows</li> <li><code>admin:org</code> - Manage organization (for environment sync)</li> </ul>"},{"location":"environment-variables/#imbi-configuration","title":"Imbi Configuration","text":"<p>Environment variables for Imbi project management integration.</p> Variable Type Default Description <code>IMBI_API_KEY</code> secret required Imbi API authentication key <code>IMBI_HOSTNAME</code> string required Imbi instance hostname <code>IMBI_GITHUB_IDENTIFIER</code> string <code>github</code> Project identifier field for GitHub <code>IMBI_PAGERDUTY_IDENTIFIER</code> string <code>pagerduty</code> Project identifier field for PagerDuty <code>IMBI_SONARQUBE_IDENTIFIER</code> string <code>sonarqube</code> Project identifier field for SonarQube <code>IMBI_SENTRY_IDENTIFIER</code> string <code>sentry</code> Project identifier field for Sentry <code>IMBI_GITHUB_LINK</code> string <code>GitHub Repository</code> Link type name for GitHub URLs <code>IMBI_GRAFANA_LINK</code> string <code>Grafana Dashboard</code> Link type name for Grafana URLs <code>IMBI_PAGERDUTY_LINK</code> string <code>PagerDuty</code> Link type name for PagerDuty URLs <code>IMBI_SENTRY_LINK</code> string <code>Sentry</code> Link type name for Sentry URLs <code>IMBI_SONARQUBE_LINK</code> string <code>SonarQube</code> Link type name for SonarQube URLs <p>Example: <pre><code>export IMBI_API_KEY=\"your-api-key-uuid\"\nexport IMBI_HOSTNAME=\"imbi.example.com\"\nexport IMBI_GITHUB_IDENTIFIER=\"github-id\"\n</code></pre></p>"},{"location":"environment-variables/#using-env-files","title":"Using .env Files","text":"<p>Imbi Automations automatically loads environment variables from a <code>.env</code> file in the current directory:</p> <pre><code># .env\nANTHROPIC_API_KEY=sk-ant-api03-...\nGH_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxx\nIMBI_API_KEY=your-api-key-uuid\nIMBI_HOSTNAME=imbi.example.com\n</code></pre> <p>Security Note: Never commit <code>.env</code> files to version control. Add <code>.env</code> to your <code>.gitignore</code>.</p>"},{"location":"environment-variables/#precedence-rules","title":"Precedence Rules","text":"<p>Configuration values are resolved in the following order (highest to lowest priority):</p> <ol> <li>Environment variables - Always checked first</li> <li>Config file values - From TOML configuration</li> <li>Default values - Built-in defaults</li> </ol> <p>When a configuration section is defined in the TOML file, environment variables serve as defaults for any fields not explicitly set in that section.</p> <p>Example: <pre><code># config.toml\n[github]\nhost = \"github.enterprise.com\"\n# token not set - will use GH_TOKEN environment variable\n</code></pre></p> <pre><code>export GH_TOKEN=\"ghp_xxxxxxxxxxxxxxxxxxxx\"\n</code></pre> <p>In this case, <code>host</code> comes from the config file and <code>token</code> comes from the environment variable.</p>"},{"location":"environment-variables/#minimal-environment-setup","title":"Minimal Environment Setup","text":"<p>For basic GitHub workflows, set these environment variables:</p> <pre><code>export GH_TOKEN=\"ghp_xxxxxxxxxxxxxxxxxxxx\"\nexport IMBI_API_KEY=\"your-api-key-uuid\"\nexport IMBI_HOSTNAME=\"imbi.example.com\"\n</code></pre> <p>Then use a minimal config file:</p> <pre><code># config.toml\n[github]\n[imbi]\n</code></pre>"},{"location":"environment-variables/#cicd-integration","title":"CI/CD Integration","text":""},{"location":"environment-variables/#github-actions","title":"GitHub Actions","text":"<pre><code>env:\n  ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}\n  GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n  IMBI_API_KEY: ${{ secrets.IMBI_API_KEY }}\n  IMBI_HOSTNAME: imbi.example.com\n\nsteps:\n  - name: Run workflow\n    run: imbi-automations config.toml workflows/update-deps --all-projects\n</code></pre>"},{"location":"environment-variables/#docker","title":"Docker","text":"<pre><code>docker run -e GH_TOKEN -e IMBI_API_KEY -e IMBI_HOSTNAME \\\n  imbi-automations config.toml workflows/update-deps --all-projects\n</code></pre> <p>Or with an env file:</p> <pre><code>docker run --env-file .env \\\n  imbi-automations config.toml workflows/update-deps --all-projects\n</code></pre>"},{"location":"environment-variables/#troubleshooting","title":"Troubleshooting","text":""},{"location":"environment-variables/#variable-not-being-read","title":"Variable Not Being Read","text":"<ol> <li>Check the variable name matches the expected prefix + field name</li> <li>Environment variables are case-insensitive</li> <li>Ensure the config section exists (even if empty) in the TOML file</li> </ol>"},{"location":"environment-variables/#secret-values-in-logs","title":"Secret Values in Logs","text":"<p>Secret values (<code>api_key</code>, <code>token</code>) are stored as <code>SecretStr</code> and will not appear in logs or error messages. They display as <code>**********</code> when printed.</p>"},{"location":"environment-variables/#checking-current-configuration","title":"Checking Current Configuration","text":"<p>Use verbose mode to see which configuration values are being used:</p> <pre><code>imbi-automations config.toml workflows/test --all-projects -vvv\n</code></pre>"},{"location":"environment-variables/#see-also","title":"See Also","text":"<ul> <li>Configuration Reference - Complete TOML configuration options</li> <li>CLI Reference - Command-line options</li> <li>Docker - Running in containers</li> </ul>"},{"location":"path-schemes/","title":"Path Schemes","text":"<p>Path schemes (ResourceUrls) provide a consistent way to reference files and directories across different contexts in workflow actions. They use a URI-like syntax to specify the base location for file operations.</p>"},{"location":"path-schemes/#overview","title":"Overview","text":"<p>Many workflow actions accept <code>source</code>, <code>destination</code>, or <code>path</code> parameters. These parameters use path schemes to indicate where files are located relative to the workflow execution environment.</p> <p>Format: <code>scheme:///path/to/file</code></p> <p>Example: <code>repository:///config.yaml</code></p>"},{"location":"path-schemes/#available-schemes","title":"Available Schemes","text":""},{"location":"path-schemes/#repository","title":"<code>repository:///</code>","text":"<p>Base Directory: Cloned git repository</p> <p>Use Case: Files within the project repository being processed</p> <p>Examples: <pre><code># Read from repository\nsource = \"repository:///src/config.yaml\"\n\n# Write to repository\ndestination = \"repository:///.github/workflows/ci.yml\"\n\n# Delete from repository\npath = \"repository:///legacy-config.json\"\n</code></pre></p> <p>Common Patterns: - Reading existing project files - Modifying repository contents - Creating new files in the repository - Any operation that should be committed and pushed</p>"},{"location":"path-schemes/#workflow","title":"<code>workflow:///</code>","text":"<p>Base Directory: Workflow directory (where <code>config.toml</code> lives)</p> <p>Use Case: Template files, configuration files, and resources bundled with the workflow</p> <p>Examples: <pre><code># Copy template from workflow to repository\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///templates/.gitignore\"\ndestination = \"repository:///.gitignore\"\n\n# Render template from workflow\n[[actions]]\ntype = \"template\"\nsource_path = \"workflow:///config.yaml.j2\"\ndestination_path = \"repository:///config.yaml\"\n</code></pre></p> <p>Typical Structure: <pre><code>workflows/my-workflow/\n\u251c\u2500\u2500 config.toml\n\u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 .gitignore\n\u2502   \u251c\u2500\u2500 ci.yml\n\u2502   \u2514\u2500\u2500 config.yaml.j2\n\u2514\u2500\u2500 scripts/\n    \u2514\u2500\u2500 setup.sh\n</code></pre></p>"},{"location":"path-schemes/#extracted","title":"<code>extracted:///</code>","text":"<p>Base Directory: Extracted files directory (typically from Docker operations)</p> <p>Use Case: Files extracted from Docker containers</p> <p>Examples: <pre><code># Extract from Docker image\n[[actions]]\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"myapp\"\nsource = \"/app/dist/\"\ndestination = \"extracted:///dist/\"\n\n# Copy extracted files to repository\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"extracted:///dist/bundle.js\"\ndestination = \"repository:///public/bundle.js\"\n</code></pre></p> <p>Workflow: 1. Docker action extracts files to <code>extracted:///</code> 2. Subsequent actions can reference those files 3. Files can be copied to repository or used for processing</p>"},{"location":"path-schemes/#external","title":"<code>external:///</code>","text":"<p>Base Directory: Absolute filesystem path (outside working directory)</p> <p>Use Case: Exporting files, creating collections, writing to known locations</p> <p>Examples: <pre><code># Extract configuration for analysis\n[[actions]]\nname = \"export-config\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///config.yaml\"\ndestination = \"external:///tmp/project-configs/{{ imbi_project.slug }}/config.yaml\"\ncommittable = false\n\n# Build a collection across projects\n[[actions]]\nname = \"collect-dockerfiles\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///Dockerfile\"\ndestination = \"external:///var/exports/dockerfiles/{{ imbi_project.slug }}/Dockerfile\"\ncommittable = false\n</code></pre></p> <p>Important Notes: - Always set <code>committable = false</code> for external operations - Paths are absolute (e.g., <code>/tmp/</code>, <code>/var/</code>, <code>/Users/...</code>) - Useful for extract-only workflows that don't modify repositories - Workflow engine skips push/PR creation when only external operations occur</p>"},{"location":"path-schemes/#file-or-no-scheme","title":"<code>file:///</code> (or no scheme)","text":"<p>Base Directory: Working directory root (temporary directory)</p> <p>Use Case: Temporary files, intermediate processing</p> <p>Examples: <pre><code># Write temporary file (both forms equivalent)\npath = \"file:///temp-data.json\"\npath = \"temp-data.json\"\n\n# Process temporary files\nsource = \"intermediate-results.csv\"\n</code></pre></p> <p>Notes: - Rarely used directly in workflows - Defaults to working directory - Files created here are automatically cleaned up after workflow execution</p>"},{"location":"path-schemes/#usage-by-action-type","title":"Usage by Action Type","text":""},{"location":"path-schemes/#file-actions","title":"File Actions","text":"<p>All file commands (<code>copy</code>, <code>move</code>, <code>delete</code>, <code>append</code>, <code>write</code>) support all schemes:</p> <pre><code>[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///template.txt\"      # Any scheme\ndestination = \"repository:///output.txt\"  # Any scheme\n</code></pre>"},{"location":"path-schemes/#template-actions","title":"Template Actions","text":"<pre><code>[[actions]]\ntype = \"template\"\nsource_path = \"workflow:///config.j2\"      # Typically workflow:///\ndestination_path = \"repository:///config\"   # Typically repository:///\n</code></pre>"},{"location":"path-schemes/#docker-actions","title":"Docker Actions","text":"<pre><code>[[actions]]\ntype = \"docker\"\ncommand = \"extract\"\nsource = \"/container/path\"                  # Container path (no scheme)\ndestination = \"extracted:///local/path\"     # extracted:/// for local storage\n</code></pre>"},{"location":"path-schemes/#git-actions","title":"Git Actions","text":"<pre><code>[[actions]]\ntype = \"git\"\ncommand = \"extract\"\nurl = \"https://github.com/org/repo.git\"\ndestination = \"extracted:///repo-files\"     # extracted:/// for git extracts\n</code></pre>"},{"location":"path-schemes/#shell-actions","title":"Shell Actions","text":"<pre><code>[[actions]]\ntype = \"shell\"\ncommand = \"ls -la\"\nworking_directory = \"repository:///\"         # Execute in repository\n</code></pre>"},{"location":"path-schemes/#template-variables","title":"Template Variables","text":"<p>All path schemes support Jinja2 template variables:</p> <pre><code># Project-specific paths\ndestination = \"external:///exports/{{ imbi_project.slug }}/config.yaml\"\n\n# Conditional paths\nsource = \"workflow:///{{ imbi_project.project_type }}/template.j2\"\n\n# Dynamic naming\npath = \"repository:///output-{{ github_repository.default_branch }}.txt\"\n</code></pre> <p>URL Encoding: Template variables in schemes are automatically URL-decoded before rendering: - <code>%7B%7B</code> \u2192 <code>{{</code> - <code>%20</code> \u2192 space - Configuration values are stored URL-encoded, decoded at runtime</p>"},{"location":"path-schemes/#path-resolution","title":"Path Resolution","text":""},{"location":"path-schemes/#absolute-vs-relative","title":"Absolute vs Relative","text":"Scheme Resolution Example <code>repository:///</code> Relative to repo <code>repository:///src/main.py</code> \u2192 <code>{temp}/repository/src/main.py</code> <code>workflow:///</code> Relative to workflow <code>workflow:///files/config</code> \u2192 <code>{workflow-dir}/files/config</code> <code>extracted:///</code> Relative to extracted <code>extracted:///dist/app.js</code> \u2192 <code>{temp}/extracted/dist/app.js</code> <code>external:///</code> Absolute path <code>external:///tmp/data.json</code> \u2192 <code>/tmp/data.json</code> <code>file:///</code> Relative to working <code>file:///temp.txt</code> \u2192 <code>{temp}/temp.txt</code>"},{"location":"path-schemes/#directory-structure","title":"Directory Structure","text":"<p>During execution, the working directory structure looks like:</p> <pre><code>{temporary-directory}/\n\u251c\u2500\u2500 repository/        # Cloned git repository (repository:///)\n\u251c\u2500\u2500 workflow/          # Symlink to workflow directory (workflow:///)\n\u251c\u2500\u2500 extracted/         # Docker/git extracts (extracted:///)\n\u2514\u2500\u2500 temp-files         # Temporary files (file:///)\n</code></pre>"},{"location":"path-schemes/#best-practices","title":"Best Practices","text":""},{"location":"path-schemes/#1-use-appropriate-schemes","title":"1. Use Appropriate Schemes","text":"<pre><code># \u2713 Good - Clear intent\nsource = \"workflow:///templates/.gitignore\"\ndestination = \"repository:///.gitignore\"\n\n# \u2717 Avoid - Confusing relative paths\nsource = \"../workflow/templates/.gitignore\"\n</code></pre>"},{"location":"path-schemes/#2-set-committable-false-for-external-operations","title":"2. Set committable = false for External Operations","text":"<pre><code># \u2713 Good - Extract without committing\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///config.yaml\"\ndestination = \"external:///tmp/configs/{{ imbi_project.slug }}/config.yaml\"\ncommittable = false\n\n# \u2717 Bad - Will fail trying to commit external changes\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///config.yaml\"\ndestination = \"external:///tmp/configs/config.yaml\"\n# Missing: committable = false\n</code></pre>"},{"location":"path-schemes/#3-organize-workflow-files","title":"3. Organize Workflow Files","text":"<pre><code># \u2713 Good - Organized structure\nsource = \"workflow:///templates/backend/.gitignore\"\nsource = \"workflow:///templates/frontend/.gitignore\"\nsource = \"workflow:///scripts/setup.sh\"\n\n# \u2717 Avoid - Flat structure\nsource = \"workflow:///backend-gitignore\"\nsource = \"workflow:///frontend-gitignore\"\n</code></pre>"},{"location":"path-schemes/#4-use-glob-patterns-with-repository-scheme","title":"4. Use Glob Patterns with Repository Scheme","text":"<pre><code># \u2713 Good - Copy multiple files\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///configs/*.yaml\"\ndestination = \"repository:///config/\"\n\n# \u2713 Good - Recursive patterns\nsource = \"repository:///src/**/*.py\"\ndestination = \"extracted:///python-files/\"\n</code></pre>"},{"location":"path-schemes/#common-patterns","title":"Common Patterns","text":""},{"location":"path-schemes/#pattern-1-template-deployment","title":"Pattern 1: Template Deployment","text":"<pre><code>[[actions]]\nname = \"deploy-ci-template\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///ci-templates/python.yml\"\ndestination = \"repository:///.github/workflows/ci.yml\"\n</code></pre>"},{"location":"path-schemes/#pattern-2-docker-extract-and-copy","title":"Pattern 2: Docker Extract and Copy","text":"<pre><code>[[actions]]\nname = \"extract-build-artifacts\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"myapp:latest\"\nsource = \"/app/dist/\"\ndestination = \"extracted:///dist/\"\n\n[[actions]]\nname = \"copy-to-repo\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"extracted:///dist/\"\ndestination = \"repository:///public/\"\n</code></pre>"},{"location":"path-schemes/#pattern-3-export-for-analysis","title":"Pattern 3: Export for Analysis","text":"<pre><code>[[actions]]\nname = \"export-dependencies\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///requirements.txt\"\ndestination = \"external:///tmp/dependency-analysis/{{ imbi_project.slug }}/requirements.txt\"\ncommittable = false\n</code></pre>"},{"location":"path-schemes/#pattern-4-template-rendering","title":"Pattern 4: Template Rendering","text":"<pre><code>[[actions]]\nname = \"render-config\"\ntype = \"template\"\nsource_path = \"workflow:///templates/config.yaml.j2\"\ndestination_path = \"repository:///config/app.yaml\"\n</code></pre>"},{"location":"path-schemes/#troubleshooting","title":"Troubleshooting","text":""},{"location":"path-schemes/#issue-invalid-path-scheme","title":"Issue: \"Invalid path scheme\"","text":"<p>Error: <code>RuntimeError: Invalid path scheme: xyz</code></p> <p>Solution: Use one of the supported schemes: <code>repository</code>, <code>workflow</code>, <code>extracted</code>, <code>external</code>, <code>file</code></p> <pre><code># \u2717 Wrong\nsource = \"myscheme:///file.txt\"\n\n# \u2713 Correct\nsource = \"repository:///file.txt\"\n</code></pre>"},{"location":"path-schemes/#issue-template-variables-not-rendering","title":"Issue: Template variables not rendering","text":"<p>Error: Path contains literal <code>{{ imbi_project.slug }}</code> instead of actual slug</p> <p>Solution: Ensure the path is stored as a string in TOML, not pre-processed</p> <pre><code># \u2713 Correct - Will be rendered at runtime\ndestination = \"external:///tmp/{{ imbi_project.slug }}/config.yaml\"\n\n# \u2717 Wrong - Already URL-encoded won't render\n# (This shouldn't happen with proper configuration)\n</code></pre>"},{"location":"path-schemes/#issue-no-changes-to-commit-with-external-operations","title":"Issue: \"No changes to commit\" with external operations","text":"<p>Symptom: Workflow tries to create commits but no repository changes were made</p> <p>Solution: Add <code>committable = false</code> to actions using <code>external:///</code></p> <pre><code># \u2713 Correct\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///config.yaml\"\ndestination = \"external:///tmp/config.yaml\"\ncommittable = false  # Don't try to commit\n</code></pre>"},{"location":"path-schemes/#see-also","title":"See Also","text":"<ul> <li>File Actions - File manipulation with path schemes</li> <li>Template Actions - Template rendering with schemes</li> <li>Docker Actions - Docker operations and extracted files</li> <li>Templating - Using Jinja2 variables in paths</li> </ul>"},{"location":"templating/","title":"Jinja2 Templating System","text":"<p>Imbi Automations uses Jinja2 as its template engine to provide dynamic content generation across workflows, prompts, and file actions. This document describes the templating system, available context variables, and usage examples.</p>"},{"location":"templating/#overview","title":"Overview","text":"<p>The templating system enables:</p> <ul> <li>Dynamic workflow prompts with project-specific context</li> <li>Template-based file generation with full project metadata</li> <li>AI prompt customization using project facts and repository data</li> <li>Pull request and commit message generation</li> <li>Variable substitution in shell commands and Docker operations</li> </ul>"},{"location":"templating/#template-context","title":"Template Context","text":"<p>All templates receive a <code>WorkflowContext</code> object that provides access to:</p>"},{"location":"templating/#core-context-variables","title":"Core Context Variables","text":""},{"location":"templating/#workflow-workflow","title":"<code>workflow</code> (Workflow)","text":"<p>Complete workflow definition and configuration.</p> <p>Available fields:</p> <ul> <li><code>workflow.configuration.name</code> - Workflow name</li> <li><code>workflow.configuration.description</code> - Workflow description</li> <li><code>workflow.configuration.prompt</code> - Workflow-level prompt URL/path</li> <li><code>workflow.configuration.git.*</code> - Git configuration (checkout, depth, branch)</li> <li><code>workflow.configuration.github.*</code> - GitHub settings (create_pull_request)</li> <li><code>workflow.configuration.filter.*</code> - Workflow filter criteria</li> </ul> <p>Example: <pre><code># Workflow: {{ workflow.configuration.name }}\n{{ workflow.configuration.description }}\n</code></pre></p>"},{"location":"templating/#imbi_project-imbiproject","title":"<code>imbi_project</code> (ImbiProject)","text":"<p>Complete project metadata from Imbi project management system.</p> <p>Core fields:</p> <ul> <li><code>imbi_project.id</code> - Project ID (integer)</li> <li><code>imbi_project.name</code> - Human-readable project name</li> <li><code>imbi_project.slug</code> - URL-safe project identifier (kebab-case)</li> <li><code>imbi_project.description</code> - Project description (may be None)</li> <li><code>imbi_project.namespace</code> - Project namespace name</li> <li><code>imbi_project.namespace_slug</code> - Namespace slug</li> <li><code>imbi_project.project_type</code> - Human-readable project type</li> <li><code>imbi_project.project_type_slug</code> - Project type slug</li> <li><code>imbi_project.imbi_url</code> - URL to project in Imbi</li> </ul> <p>Project metadata:</p> <ul> <li><code>imbi_project.dependencies</code> - List of dependent project IDs</li> <li><code>imbi_project.environments</code> - List of environment names (e.g., <code>[\"development\", \"production\"]</code>)</li> <li><code>imbi_project.facts</code> - Dictionary of project facts (key-value pairs)</li> <li><code>imbi_project.identifiers</code> - External system identifiers (GitHub, GitLab, etc.)</li> <li><code>imbi_project.links</code> - Dictionary of external links</li> <li><code>imbi_project.urls</code> - Dictionary of project URLs</li> <li><code>imbi_project.project_score</code> - Project health score</li> </ul> <p>Example: <pre><code>Project: {{ imbi_project.name }}\nSlug: {{ imbi_project.slug }}\nType: {{ imbi_project.project_type }}\n\n{% if imbi_project.description %}\nDescription: {{ imbi_project.description }}\n{% endif %}\n\n{% if imbi_project.facts %}\nFacts:\n{% for key, value in imbi_project.facts.items() %}\n  - {{ key }}: {{ value }}\n{% endfor %}\n{% endif %}\n</code></pre></p>"},{"location":"templating/#github_repository-githubrepository-none","title":"<code>github_repository</code> (GitHubRepository | None)","text":"<p>GitHub repository metadata (only available when GitHub identifier exists).</p> <p>Core fields:</p> <ul> <li><code>github_repository.id</code> - Repository ID</li> <li><code>github_repository.name</code> - Repository name</li> <li><code>github_repository.full_name</code> - Full name (org/repo)</li> <li><code>github_repository.owner.login</code> - Owner username</li> <li><code>github_repository.private</code> - Boolean: is private</li> <li><code>github_repository.description</code> - Repository description</li> <li><code>github_repository.html_url</code> - GitHub web URL</li> <li><code>github_repository.ssh_url</code> - SSH clone URL</li> <li><code>github_repository.clone_url</code> - HTTPS clone URL</li> </ul> <p>Additional fields:</p> <ul> <li><code>github_repository.fork</code> - Boolean: is fork</li> <li><code>github_repository.created_at</code> - Creation timestamp</li> <li><code>github_repository.updated_at</code> - Last update timestamp</li> <li><code>github_repository.pushed_at</code> - Last push timestamp</li> <li><code>github_repository.size</code> - Repository size in KB</li> <li><code>github_repository.stargazers_count</code> - Star count</li> <li><code>github_repository.watchers_count</code> - Watcher count</li> <li><code>github_repository.language</code> - Primary language</li> <li><code>github_repository.has_issues</code> - Boolean: issues enabled</li> <li><code>github_repository.has_projects</code> - Boolean: projects enabled</li> <li><code>github_repository.has_wiki</code> - Boolean: wiki enabled</li> <li><code>github_repository.archived</code> - Boolean: is archived</li> <li><code>github_repository.disabled</code> - Boolean: is disabled</li> <li><code>github_repository.default_branch</code> - Default branch name</li> </ul> <p>Example: <pre><code>{% if github_repository %}\nRepository: {{ github_repository.full_name }}\nURL: {{ github_repository.html_url }}\nLanguage: {{ github_repository.language }}\nDefault Branch: {{ github_repository.default_branch }}\n{% endif %}\n</code></pre></p>"},{"location":"templating/#working_directory-pathlibpath-none","title":"<code>working_directory</code> (pathlib.Path | None)","text":"<p>Absolute path to the temporary working directory containing the cloned repository.</p> <p>Example: <pre><code>Working directory: {{ working_directory }}\nRepository location: {{ working_directory }}/repository\n</code></pre></p>"},{"location":"templating/#starting_commit-str-none","title":"<code>starting_commit</code> (str | None)","text":"<p>Git commit SHA of the repository HEAD when workflow execution started.</p> <p>Example: <pre><code>Starting commit: {{ starting_commit }}\n</code></pre></p>"},{"location":"templating/#pull_request-githubpullrequest-none","title":"<code>pull_request</code> (GitHubPullRequest | None)","text":"<p>Pull request information, available only in followup stage actions after PR creation.</p> <p>Available fields:</p> <ul> <li><code>pull_request.number</code> - PR number (integer)</li> <li><code>pull_request.html_url</code> - PR URL on GitHub</li> <li><code>pull_request.state</code> - PR state (\"open\", \"closed\", \"merged\")</li> <li><code>pull_request.title</code> - PR title</li> <li><code>pull_request.head.sha</code> - Head commit SHA</li> <li><code>pull_request.head.ref</code> - Head branch name</li> <li><code>pull_request.base.ref</code> - Base branch name</li> <li><code>pull_request.mergeable</code> - Whether PR can be merged (boolean or None)</li> <li><code>pull_request.mergeable_state</code> - Merge state (\"clean\", \"dirty\", \"blocked\", etc.)</li> </ul> <p>Example: <pre><code>{% if pull_request %}\nPR #{{ pull_request.number }}: {{ pull_request.html_url }}\nHead SHA: {{ pull_request.head.sha }}\nState: {{ pull_request.state }}\n{% endif %}\n</code></pre></p>"},{"location":"templating/#pr_branch-str-none","title":"<code>pr_branch</code> (str | None)","text":"<p>Branch name for the pull request, available only in followup stage actions.</p> <p>Example: <pre><code>{% if pr_branch %}\nPR Branch: {{ pr_branch }}\n{% endif %}\n</code></pre></p> <p>See Action Stages for followup stage documentation.</p>"},{"location":"templating/#custom-template-functions","title":"Custom Template Functions","text":"<p>The templating system provides custom functions accessible within templates:</p>"},{"location":"templating/#read_filefile_path","title":"<code>read_file(file_path)</code>","text":"<p>Reads the contents of a file and returns it as a string.</p> <p>Parameters:</p> <ul> <li><code>file_path</code> - Path to file (supports ResourceUrl schemes: <code>repository:///</code>, <code>workflow:///</code>, <code>extracted:///</code>, etc.)</li> </ul> <p>Returns: File contents as string</p> <p>Example: <pre><code>Description: {{ read_file('repository:///DESCRIPTION.txt').strip() }}\n</code></pre></p> <p>Usage in Imbi actions: <pre><code>[[actions]]\nname = \"update-from-generated-file\"\ntype = \"imbi\"\ncommand = \"update_project\"\nattributes = {\n    description = \"{{ read_file('repository:///GENERATED_DESCRIPTION.txt').strip() }}\"\n}\n</code></pre></p> <p>Use cases:</p> <ul> <li>Load AI-generated content from files</li> <li>Read README excerpts for descriptions</li> <li>Extract version strings from files</li> <li>Load configuration snippets</li> </ul> <p>Available in: Template actions, Imbi action fields, Claude prompts</p>"},{"location":"templating/#extract_image_from_dockerfiledockerfile_path","title":"<code>extract_image_from_dockerfile(dockerfile_path)</code>","text":"<p>Extracts the base Docker image from a Dockerfile.</p> <p>Parameters:</p> <ul> <li><code>dockerfile_path</code> - Path to Dockerfile (supports <code>repository:///</code> URL scheme)</li> </ul> <p>Returns: Base image name (e.g., <code>python:3.12-slim</code>)</p> <p>Example: <pre><code>Base image: {{ extract_image_from_dockerfile('repository:///Dockerfile') }}\n</code></pre></p> <p>Usage in workflow: <pre><code>[[actions]]\nname = \"extract-constraints\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"{{ extract_image_from_dockerfile('repository:///Dockerfile') }}\"\nsource = \"/tmp/constraints.txt\"\ndestination = \"extracted:///constraints.txt\"\n</code></pre></p>"},{"location":"templating/#compare_semvercurrent-target","title":"<code>compare_semver(current, target)</code>","text":"<p>Compares two semantic versions and returns a dict with comparison results.</p> <p>Parameters:</p> <ul> <li><code>current</code> - Current version string (e.g., \"18.2.0\", \"3.9.18-4\")</li> <li><code>target</code> - Target version string to compare against</li> </ul> <p>Returns: Dict with:</p> <ul> <li><code>is_older</code>: True if current &lt; target</li> <li><code>is_equal</code>: True if current == target</li> <li><code>is_newer</code>: True if current &gt; target</li> <li><code>comparison</code>: -1 (older), 0 (equal), or 1 (newer)</li> <li><code>current_major</code>, <code>current_minor</code>, <code>current_patch</code>, <code>current_build</code></li> <li><code>target_major</code>, <code>target_minor</code>, <code>target_patch</code>, <code>target_build</code></li> </ul> <p>Version handling:</p> <ul> <li>Strips prefixes like <code>v</code>, <code>^</code>, <code>~</code>, <code>&gt;=</code></li> <li>Handles partial versions (e.g., \"3.9\" \u2192 \"3.9.0\")</li> <li>Supports build numbers (e.g., \"3.9.18-4\")</li> </ul> <p>Example: <pre><code>{% set result = compare_semver('18.2.0', '19.0.0') %}\n{% if result.is_older %}\nCurrent version {{ result.current_version }} is older than {{ result.target_version }}\n{% endif %}\n</code></pre></p> <p>Available in: All templates, <code>when</code> conditions</p>"},{"location":"templating/#get_component_versionpath-component","title":"<code>get_component_version(path, component)</code>","text":"<p>Extracts a dependency version from a manifest file.</p> <p>Parameters:</p> <ul> <li><code>path</code> - ResourceUrl path to manifest file (e.g., \"repository:///package.json\")</li> <li><code>component</code> - Name of the dependency to extract</li> </ul> <p>Supported file types:</p> <ul> <li><code>package.json</code>: Searches dependencies, devDependencies, peerDependencies</li> <li><code>pyproject.toml</code>: Searches project.dependencies, optional-dependencies, Poetry dependencies</li> </ul> <p>Returns: Clean version string without prefixes</p> <p>Example: <pre><code>React version: {{ get_component_version('repository:///package.json', 'react') }}\nPydantic version: {{ get_component_version('repository:///pyproject.toml', 'pydantic') }}\n</code></pre></p> <p>Combined with compare_semver: <pre><code>{% set react_version = get_component_version('repository:///package.json', 'react') %}\n{% set comparison = compare_semver(react_version, '19.0.0') %}\n{% if comparison.is_older %}\nReact {{ react_version }} is older than 19.0.0 - upgrade recommended\n{% endif %}\n</code></pre></p> <p>Available in: All templates, <code>when</code> conditions</p>"},{"location":"templating/#template-usage","title":"Template Usage","text":""},{"location":"templating/#1-claude-action-prompts","title":"1. Claude Action Prompts","text":"<p>Claude actions use Jinja2 templates for AI prompts:</p> <pre><code>[[actions]]\nname = \"standardize-dunder-init\"\ntype = \"claude\"\nprompt = \"prompts/init.md.j2\"\nvalidation_prompt = \"prompts/validate-init.md.j2\"\n</code></pre> <p>Example prompt template (<code>prompts/init.md.j2</code>): <pre><code># Python Package __init__.py Version Standardization\n\nUpdate the package's `__init__.py` file to standardize version handling.\n\n## Context Variables\n- Project name: `{{ imbi_project.name }}`\n- Package name: `{{ imbi_project.slug }}`\n- Project description: `{{ imbi_project.description }}`\n\n## Current Facts\n{% if imbi_project.facts %}\n{% for key, value in imbi_project.facts.items() %}\n- {{ key }}: {{ value }}\n{% endfor %}\n{% endif %}\n\n## Repository Information\n{% if github_repository %}\n- Repository: {{ github_repository.full_name }}\n- Primary language: {{ github_repository.language }}\n{% endif %}\n</code></pre></p>"},{"location":"templating/#2-template-actions","title":"2. Template Actions","text":"<p>Template actions render entire files or directories:</p> <pre><code>[[actions]]\nname = \"render-config\"\ntype = \"template\"\nsource_path = \"templates/config.yaml.j2\"\ndestination_path = \"repository:///config/app.yaml\"\n</code></pre> <p>Example template file (<code>templates/config.yaml.j2</code>): <pre><code>application:\n  name: {{ imbi_project.name }}\n  slug: {{ imbi_project.slug }}\n  version: \"{{ imbi_project.facts.get('Version', '0.0.0') }}\"\n\n{% if imbi_project.environments %}\nenvironments:\n{% for env in imbi_project.environments %}\n  - {{ env }}\n{% endfor %}\n{% endif %}\n\n{% if github_repository %}\nrepository:\n  url: {{ github_repository.html_url }}\n  default_branch: {{ github_repository.default_branch }}\n{% endif %}\n</code></pre></p>"},{"location":"templating/#3-shell-command-templating","title":"3. Shell Command Templating","text":"<p>Shell commands support inline Jinja2 templating:</p> <pre><code>[[actions]]\nname = \"update-version\"\ntype = \"shell\"\ncommand = \"sed -i '' 's/version = .*/version = \\\"{{ imbi_project.facts.Version }}\\\"/' pyproject.toml\"\n</code></pre>"},{"location":"templating/#4-docker-image-extraction","title":"4. Docker Image Extraction","text":"<p>Use <code>extract_image_from_dockerfile()</code> in Docker actions:</p> <pre><code>[[actions]]\nname = \"extract-constraints\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"{{ extract_image_from_dockerfile('repository:///Dockerfile') }}\"\nsource = \"/tmp/constraints.txt\"\ndestination = \"extracted:///constraints.txt\"\n</code></pre>"},{"location":"templating/#5-pull-request-generation","title":"5. Pull Request Generation","text":"<p>Pull request summaries are generated from templates with commit context:</p> <p>Template (<code>prompts/pull-request-summary.md.j2</code>): <pre><code># {{ workflow.configuration.name }}\n\n{{ workflow.configuration.description }}\n\n## Project Details\n- **Project**: {{ imbi_project.name }}\n- **Type**: {{ imbi_project.project_type }}\n- **Imbi URL**: {{ imbi_project.imbi_url }}\n\n{% if github_repository %}\n## Repository\n- **Name**: {{ github_repository.full_name }}\n- **Language**: {{ github_repository.language }}\n{% endif %}\n\n## Changes Summary\n{{ summary }}\n</code></pre></p>"},{"location":"templating/#6-directory-templates","title":"6. Directory Templates","text":"<p>Template actions can render entire directories recursively:</p> <pre><code>[[actions]]\nname = \"enforce-ci-scripts\"\ntype = \"template\"\nsource_path = \"templates/ci\"\ndestination_path = \"repository:///ci/\"\n</code></pre> <p>All files in <code>templates/ci/</code> are rendered with full context and written to <code>repository:///ci/</code>.</p>"},{"location":"templating/#resource-url-schemes","title":"Resource URL Schemes","text":"<p>The templating system supports custom URL schemes for path resolution:</p> <ul> <li><code>repository:///</code> - Files in the cloned git repository</li> <li><code>workflow:///</code> - Files in the workflow directory</li> <li><code>extracted:///</code> - Files extracted during workflow execution</li> <li><code>file:///</code> - Absolute file system paths</li> </ul> <p>Example: <pre><code>[[actions]]\nname = \"copy-gitignore\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///.gitignore\"\ndestination = \"repository:///.gitignore\"\n</code></pre></p>"},{"location":"templating/#jinja2-configuration","title":"Jinja2 Configuration","text":"<p>The templating environment uses: - <code>autoescape=False</code> - No HTML escaping (templates are code, not HTML) - <code>undefined=jinja2.StrictUndefined</code> - Raises errors for undefined variables (fail fast)</p> <p>This ensures templates fail early if variables are missing rather than silently producing incorrect output.</p>"},{"location":"templating/#common-patterns","title":"Common Patterns","text":""},{"location":"templating/#conditional-sections","title":"Conditional Sections","text":"<pre><code>{% if imbi_project.facts.get('Framework') %}\nThis project uses {{ imbi_project.facts.Framework }}.\n{% endif %}\n\n{% if github_repository and github_repository.language == 'Python' %}\nPython-specific instructions...\n{% endif %}\n</code></pre>"},{"location":"templating/#iterating-over-collections","title":"Iterating Over Collections","text":"<pre><code>{% if imbi_project.environments %}\nEnvironments:\n{% for env in imbi_project.environments %}\n  - {{ env }}\n{% endfor %}\n{% endif %}\n\n{% if imbi_project.facts %}\nProject Facts:\n{% for key, value in imbi_project.facts.items() %}\n  {{ key }}: {{ value }}\n{% endfor %}\n{% endif %}\n</code></pre>"},{"location":"templating/#default-values","title":"Default Values","text":"<pre><code>Project: {{ imbi_project.name }}\nDescription: {{ imbi_project.description or \"No description available\" }}\nVersion: {{ imbi_project.facts.get('Version', '0.0.0') }}\n</code></pre>"},{"location":"templating/#multi-line-strings","title":"Multi-line Strings","text":"<pre><code>\"\"\"\n{{ imbi_project.name }}\n{{ \"=\" * imbi_project.name|length }}\n{{ imbi_project.description or \"No description\" }}\n\n\"\"\"\n</code></pre>"},{"location":"templating/#template-inheritance","title":"Template Inheritance","text":"<p>While not commonly used in this system, Jinja2 supports template inheritance:</p> <pre><code>{% extends \"base.md.j2\" %}\n\n{% block content %}\nProject-specific content here\n{% endblock %}\n</code></pre>"},{"location":"templating/#best-practices","title":"Best Practices","text":"<ol> <li>Use strict undefined checking - Let templates fail on missing variables</li> <li>Provide defaults - Use <code>or</code> operator or <code>get()</code> method for optional fields</li> <li>Check for None - Many fields can be <code>None</code>, always check before accessing</li> <li>Use descriptive variable names - Context is self-documenting</li> <li>Keep templates readable - Use whitespace and comments liberally</li> <li>Validate template output - Use validation prompts for Claude actions</li> <li>Test with multiple projects - Different project types have different facts</li> </ol>"},{"location":"templating/#debugging-templates","title":"Debugging Templates","text":""},{"location":"templating/#enable-verbose-logging","title":"Enable Verbose Logging","text":"<p>Run workflows with verbose flag to see rendered templates:</p> <pre><code>imbi-automations config.toml workflows/my-workflow --verbose --project my-project\n</code></pre>"},{"location":"templating/#check-template-syntax","title":"Check Template Syntax","text":"<p>Use <code>has_template_syntax()</code> to detect Jinja2 patterns:</p> <pre><code>from imbi_automations import prompts\n\nif prompts.has_template_syntax(command):\n    # Command contains {{ }}, {% %}, or {# #}\n    rendered = prompts.render(context, command, **context.model_dump())\n</code></pre>"},{"location":"templating/#common-errors","title":"Common Errors","text":"<p><code>UndefinedError: 'None' has no attribute 'name'</code> - Check if object exists before accessing attributes - Use conditional checks: <code>{% if github_repository %}...{% endif %}</code></p> <p><code>UndefinedError: 'dict object' has no attribute 'Programming_Language'</code> - Use <code>.get()</code> method for dictionary access: <code>imbi_project.facts.get('Programming Language')</code> - Facts use spaces, not underscores in keys</p> <p>Template renders empty string - Check that source file exists and is readable - Verify URL scheme is correct (<code>repository:///</code>, not <code>repository://</code>)</p>"},{"location":"templating/#examples","title":"Examples","text":""},{"location":"templating/#complete-claude-action-example","title":"Complete Claude Action Example","text":"<p>Workflow configuration: <pre><code>[[actions]]\nname = \"update-readme\"\ntype = \"claude\"\nprompt = \"prompts/update-readme.md.j2\"\n</code></pre></p> <p>Prompt template (<code>prompts/update-readme.md.j2</code>): <pre><code># README Update Task\n\nUpdate the README.md file for {{ imbi_project.name }}.\n\n## Project Information\n- **Name**: {{ imbi_project.name }}\n- **Type**: {{ imbi_project.project_type }}\n- **Description**: {{ imbi_project.description or \"No description available\" }}\n\n{% if imbi_project.facts %}\n## Project Facts\n{% for key, value in imbi_project.facts.items() %}\n- **{{ key }}**: {{ value }}\n{% endfor %}\n{% endif %}\n\n{% if github_repository %}\n## Repository\n- **URL**: {{ github_repository.html_url }}\n- **Language**: {{ github_repository.language }}\n- **Default Branch**: {{ github_repository.default_branch }}\n{% endif %}\n\n## Task\nUpdate the README.md to reflect the current project state, including:\n1. Project name and description\n2. Programming language and framework\n3. Build and test instructions\n4. Links to relevant documentation\n</code></pre></p>"},{"location":"templating/#complete-template-action-example","title":"Complete Template Action Example","text":"<p>Workflow configuration: <pre><code>[[actions]]\nname = \"render-compose\"\ntype = \"template\"\nsource_path = \"templates/compose.yaml.j2\"\ndestination_path = \"repository:///compose.yaml\"\n</code></pre></p> <p>Template file (<code>templates/compose.yaml.j2</code>): <pre><code>version: '3.8'\n\nservices:\n  {{ imbi_project.slug }}:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    image: {{ imbi_project.slug }}:latest\n    container_name: {{ imbi_project.slug }}\n\n    environment:\n      - APP_NAME={{ imbi_project.name }}\n      - APP_SLUG={{ imbi_project.slug }}\n      {% if imbi_project.facts.get('Framework') %}\n      - FRAMEWORK={{ imbi_project.facts.Framework }}\n      {% endif %}\n\n    {% if imbi_project.project_type_slug in ['apis', 'web-applications'] %}\n    ports:\n      - \"8080:8080\"\n    {% endif %}\n\n    {% if imbi_project.facts.get('Database') %}\n    depends_on:\n      - database\n    {% endif %}\n\n    volumes:\n      - .:/app\n\n    {% if imbi_project.environments %}\n    # Configured environments: {{ imbi_project.environments|join(', ') }}\n    {% endif %}\n\n{% if imbi_project.facts.get('Database') == 'PostgreSQL' %}\n  database:\n    image: postgres:15\n    environment:\n      - POSTGRES_DB={{ imbi_project.slug }}\n      - POSTGRES_USER=app\n      - POSTGRES_PASSWORD=secret\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n\nvolumes:\n  postgres-data:\n{% endif %}\n</code></pre></p>"},{"location":"templating/#see-also","title":"See Also","text":"<ul> <li>Jinja2 Documentation</li> <li>Workflow Configuration - Complete workflow configuration reference</li> <li>Actions Reference - Action implementations and usage</li> </ul>"},{"location":"workflow-conditions/","title":"Workflow Conditions","text":"<p>Conditions check repository state to determine if workflows or individual actions should execute. They provide fine-grained control over workflow execution based on file existence, file contents, and repository structure.</p>"},{"location":"workflow-conditions/#condition-levels","title":"Condition Levels","text":"<p>Conditions can be applied at two levels:</p>"},{"location":"workflow-conditions/#workflow-level-conditions","title":"Workflow-Level Conditions","text":"<p>Evaluated once per project before any actions execute. If conditions fail, the entire workflow is skipped.</p> <pre><code>[[conditions]]\nremote_file_exists = \"setup.cfg\"\n</code></pre>"},{"location":"workflow-conditions/#action-level-conditions","title":"Action-Level Conditions","text":"<p>Evaluated before each action executes. If conditions fail, only that specific action is skipped.</p> <pre><code>[[actions]]\nname = \"update-dockerfile\"\ntype = \"file\"\n\n[[actions.conditions]]\nfile_exists = \"Dockerfile\"\n</code></pre>"},{"location":"workflow-conditions/#condition-types","title":"Condition Types","text":""},{"location":"workflow-conditions/#remote-conditions-pre-clone","title":"Remote Conditions (Pre-Clone)","text":"<p>Remote conditions are checked via API before cloning the repository. They are faster and more efficient than local conditions.</p> <p>Advantages:</p> <ul> <li>\u26a1 No repository cloning required</li> <li>\ud83d\udcbe Saves bandwidth and disk space</li> <li>\ud83d\ude80 Faster workflow evaluation</li> <li>\u2705 Early filtering (fail fast)</li> </ul> <p>Limitations:</p> <ul> <li>Limited to single file content checks</li> <li>No glob pattern support for content matching</li> <li>API rate limits may apply</li> </ul>"},{"location":"workflow-conditions/#remote_file_exists","title":"remote_file_exists","text":"<p>Check if a file exists using the GitHub API.</p> <p>Type: <code>string</code> (file path or glob pattern)  </p> <pre><code>[[conditions]]\nremote_file_exists = \"setup.cfg\"\n</code></pre> <p>Glob pattern support: <pre><code>[[conditions]]\nremote_file_exists = \"**/*.tf\"  # Any Terraform file recursively\n</code></pre></p> <p>Real-world example: <pre><code>[[conditions]]\nremote_file_exists = \"setup.cfg\"\n</code></pre></p> <p>Why? Workflow migrates projects from setup.cfg to pyproject.toml, so it only runs on projects that still have setup.cfg.</p>"},{"location":"workflow-conditions/#remote_file_not_exists","title":"remote_file_not_exists","text":"<p>Check if a file does NOT exist using the GitHub API.</p> <p>Type: <code>string</code> (file path or glob pattern)  </p> <pre><code>[[conditions]]\nremote_file_not_exists = \"pyproject.toml\"\n</code></pre> <p>Real-world example: <pre><code>[[conditions]]\nremote_file_not_exists = \"pyproject.toml\"\n</code></pre></p> <p>Why? Combined with <code>remote_file_exists = \"setup.cfg\"</code>, this targets projects that haven't been migrated yet (have setup.cfg but no pyproject.toml).</p>"},{"location":"workflow-conditions/#remote_file_contains-remote_file","title":"remote_file_contains + remote_file","text":"<p>Check if a file contains specific text or matches a regex pattern.</p> <p>Type: <code>string</code> (pattern to search for)  </p> <p>Requires: <code>remote_file</code> field with target file path</p> <pre><code>[[conditions]]\nremote_file_contains = \"python.*3\\\\.9\"\nremote_file = \"setup.cfg\"\n</code></pre> <p>Pattern matching:</p> <ol> <li>String search first (fast)</li> <li>Falls back to regex if string not found</li> <li>Use regex escaping: <code>\\\\.</code> for literal <code>.</code>, <code>\\\\d</code> for digits</li> </ol> <p>Example - exact string: <pre><code>[[conditions]]\nremote_file_contains = \"FROM python:3.9\"\nremote_file = \"Dockerfile\"\n</code></pre></p> <p>Example - regex pattern: <pre><code>[[conditions]]\nremote_file_contains = \"python_requires.*=[\\\"']&gt;=3\\\\.(9|10)\"\nremote_file = \"setup.cfg\"\n</code></pre></p>"},{"location":"workflow-conditions/#remote_file_doesnt_contain-remote_file","title":"remote_file_doesnt_contain + remote_file","text":"<p>Check if a file does NOT contain a pattern.</p> <pre><code>[[conditions]]\nremote_file_doesnt_contain = \"python.*3\\\\.12\"\nremote_file = \"pyproject.toml\"\n</code></pre>"},{"location":"workflow-conditions/#remote_client","title":"remote_client","text":"<p>Specify which API client to use for remote checks.</p> <p>Type: <code>string</code></p> <p>Values: <code>\"github\"</code> (default)</p> <pre><code>[[conditions]]\nremote_client = \"github\"\nremote_file_exists = \".github/workflows/ci.yml\"\n</code></pre>"},{"location":"workflow-conditions/#local-conditions-post-clone","title":"Local Conditions (Post-Clone)","text":"<p>Local conditions are checked after cloning the repository. They have full filesystem access and support glob patterns.</p> <p>Advantages:</p> <ul> <li>\u2705 Full glob pattern support</li> <li>\u2705 Access to all files, even .gitignored</li> <li>\u2705 Complex pattern matching</li> <li>\u2705 Directory checks</li> </ul> <p>Disadvantages:</p> <ul> <li>\ud83d\udc0c Requires git clone first</li> <li>\ud83d\udcbe Uses bandwidth and disk space</li> <li>\u23f1\ufe0f Slower than remote conditions</li> </ul>"},{"location":"workflow-conditions/#file_exists","title":"file_exists","text":"<p>Check if a file or directory exists locally.</p> <p>Type: <code>ResourceUrl</code> (path relative to repository)</p> <p>Supports: Glob patterns</p> <pre><code>[[conditions]]\nfile_exists = \"Dockerfile\"\n</code></pre> <p>Glob patterns: <pre><code>[[conditions]]\nfile_exists = \"**/*.py\"  # Any Python file recursively\n\n[[conditions]]\nfile_exists = \"src/**/__init__.py\"  # __init__.py in any src subdirectory\n</code></pre></p> <p>Real-world example from example-workflow (action-level): <pre><code>[[actions]]\nname = \"extract-constraints\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"{{ extract_image_from_dockerfile('repository/Dockerfile') }}\"\nsource = \"/tmp/constraints.txt\"\ndestination = \"extracted:///constraints.txt\"\n\n[[actions.conditions]]\nfile_exists = \"Dockerfile\"\n</code></pre></p> <p>Why? Only extract Docker constraints if project has a Dockerfile.</p>"},{"location":"workflow-conditions/#file_not_exists","title":"file_not_exists","text":"<p>Check if a file or directory does NOT exist locally.</p> <pre><code>[[conditions]]\nfile_not_exists = \".travis.yml\"  # No legacy CI\n</code></pre> <p>Real-world example from example-workflow (action-level): <pre><code>[[actions]]\nname = \"extract-original-compose-yml\"\ntype = \"git\"\ncommand = \"extract\"\ncommit_keyword = \"migration\"\nsource = \"compose.yml\"\ndestination = \"extracted:///compose.original.yaml\"\n\n[[actions.conditions]]\nfile_not_exists = \"extracted:///compose.original.yaml\"\n</code></pre></p> <p>Why? Only attempt to extract compose.yml from git history if we haven't already extracted it from a previous attempt (compose.yaml).</p>"},{"location":"workflow-conditions/#file_contains-file","title":"file_contains + file","text":"<p>Check if a file contains specific text or matches a regex pattern.</p> <p>Type: <code>string</code> (pattern to search for)  </p> <p>Requires: <code>file</code> field with target file path</p> <pre><code>[[conditions]]\nfile_contains = \"FROM python:3\\\\.9\"\nfile = \"Dockerfile\"\n</code></pre> <p>Pattern matching:</p> <ol> <li>String search first (fast)</li> <li>Falls back to regex if string not found</li> <li>Use regex escaping: <code>\\\\.</code> for literal <code>.</code>, <code>\\\\d</code> for digits</li> </ol> <p>Example - Check Python version: <pre><code>[[conditions]]\nfile_contains = \"python.*3\\\\.(9|10|11)\"\nfile = \"pyproject.toml\"\n</code></pre></p> <p>Example - Check dependencies: <pre><code>[[conditions]]\nfile_contains = \"fastapi.*==.*0\\\\.\"\nfile = \"requirements.txt\"\n</code></pre></p>"},{"location":"workflow-conditions/#file_doesnt_contain-file","title":"file_doesnt_contain + file","text":"<p>Check if a file does NOT contain a pattern.</p> <pre><code>[[conditions]]\nfile_doesnt_contain = \"python.*2\\\\.\"\nfile = \"setup.py\"\n</code></pre>"},{"location":"workflow-conditions/#template-conditions-post-clone","title":"Template Conditions (Post-Clone)","text":"<p>Template conditions use Jinja2 expressions for complex logic. They have access to template functions like <code>compare_semver()</code> and <code>get_component_version()</code>.</p> <p>Advantages:</p> <ul> <li>\u2705 Complex conditional logic</li> <li>\u2705 Version comparison support</li> <li>\u2705 Access to workflow context</li> <li>\u2705 Dependency version extraction</li> </ul> <p>Disadvantages:</p> <ul> <li>\ud83d\udc0c Requires git clone first</li> <li>\u23f1\ufe0f Template evaluation overhead</li> </ul>"},{"location":"workflow-conditions/#when","title":"when","text":"<p>Evaluate a Jinja2 template expression. If the result is truthy, the condition passes.</p> <p>Type: <code>string</code> (Jinja2 template)  </p> <p>Truthiness evaluation:</p> <ul> <li>Truthy: <code>True</code>, <code>true</code>, <code>1</code>, <code>yes</code>, any non-empty string</li> <li>Falsy: <code>False</code>, <code>false</code>, <code>0</code>, <code>no</code>, <code>none</code>, empty string</li> </ul> <pre><code>[[conditions]]\nwhen = \"{{ compare_semver(get_component_version('repository:///package.json', 'react'), '19.0.0').is_older }}\"\n</code></pre> <p>Template functions available:</p> <ul> <li><code>compare_semver(current, target)</code> - Compare two semantic versions</li> <li><code>get_component_version(path, component)</code> - Extract dependency version from package.json or pyproject.toml</li> </ul>"},{"location":"workflow-conditions/#compare_semvercurrent-target","title":"compare_semver(current, target)","text":"<p>Compares two semantic versions and returns a dict with comparison results.</p> <p>Arguments:</p> <ul> <li><code>current</code>: Current version string (e.g., \"18.2.0\", \"3.9.18-4\")</li> <li><code>target</code>: Target version string to compare against</li> </ul> <p>Returns: Dict with:</p> <ul> <li><code>is_older</code>: True if current &lt; target</li> <li><code>is_equal</code>: True if current == target</li> <li><code>is_newer</code>: True if current &gt; target</li> <li><code>comparison</code>: -1 (older), 0 (equal), or 1 (newer)</li> <li><code>current_major</code>, <code>current_minor</code>, <code>current_patch</code>, <code>current_build</code></li> <li><code>target_major</code>, <code>target_minor</code>, <code>target_patch</code>, <code>target_build</code></li> </ul> <p>Version handling:</p> <ul> <li>Strips prefixes like <code>v</code>, <code>^</code>, <code>~</code>, <code>&gt;=</code></li> <li>Handles partial versions (e.g., \"3.9\" \u2192 \"3.9.0\")</li> <li>Supports build numbers (e.g., \"3.9.18-4\")</li> </ul> <pre><code># Check if React is older than 19.0.0\n[[conditions]]\nwhen = \"{{ compare_semver('18.2.0', '19.0.0').is_older }}\"\n\n# Check major version\n[[conditions]]\nwhen = \"{{ compare_semver(get_component_version('repository:///package.json', 'react'), '18.0.0').current_major &gt;= 17 }}\"\n</code></pre>"},{"location":"workflow-conditions/#get_component_versionpath-component","title":"get_component_version(path, component)","text":"<p>Extracts a dependency version from a manifest file.</p> <p>Arguments:</p> <ul> <li><code>path</code>: ResourceUrl path to manifest file (e.g., \"repository:///package.json\")</li> <li><code>component</code>: Name of the dependency to extract</li> </ul> <p>Supported file types:</p> <ul> <li><code>package.json</code>: Searches dependencies, devDependencies, peerDependencies</li> <li><code>pyproject.toml</code>: Searches project.dependencies, optional-dependencies, Poetry dependencies</li> </ul> <p>Returns: Clean version string without prefixes</p> <pre><code># Check React version in package.json\n[[conditions]]\nwhen = \"{{ compare_semver(get_component_version('repository:///package.json', 'react'), '19.0.0').is_older }}\"\n\n# Check Pydantic version in pyproject.toml\n[[conditions]]\nwhen = \"{{ compare_semver(get_component_version('repository:///pyproject.toml', 'pydantic'), '2.0.0').is_older }}\"\n</code></pre>"},{"location":"workflow-conditions/#combined-examples","title":"Combined examples","text":"<pre><code># Skip upgrade workflow if already on target version\n[[conditions]]\nwhen = \"{{ compare_semver(get_component_version('repository:///package.json', 'react'), '19.0.0').is_older }}\"\n\n# Complex negation\n[[conditions]]\nwhen = \"{{ not compare_semver(get_component_version('repository:///pyproject.toml', 'pydantic'), '2.0.0').is_newer }}\"\n\n# String checks on version\n[[conditions]]\nwhen = \"{{ get_component_version('repository:///pyproject.toml', 'python').startswith('3.9') }}\"\n\n# Access workflow context\n[[conditions]]\nwhen = \"{{ workflow.configuration.name == 'upgrade-react' }}\"\n</code></pre> <p>Note: Template conditions are skipped during remote checks (pre-clone) since they require filesystem access. Use remote conditions for pre-clone filtering.  </p>"},{"location":"workflow-conditions/#condition-evaluation","title":"Condition Evaluation","text":""},{"location":"workflow-conditions/#condition_type","title":"condition_type","text":"<p>Controls how multiple conditions are evaluated.</p> <p>Type: <code>string</code> </p> <p>Values: <code>\"all\"</code> (AND logic), <code>\"any\"</code> (OR logic)</p> <p>Default: <code>\"all\"</code> </p>"},{"location":"workflow-conditions/#and-logic-condition_type-all","title":"AND Logic (condition_type = \"all\")","text":"<p>ALL conditions must pass for execution to proceed.</p> <pre><code>condition_type = \"all\"  # All conditions must pass (default)\n\n[[conditions]]\nremote_file_exists = \"setup.cfg\"\n\n[[conditions]]\nremote_file_not_exists = \"pyproject.toml\"\n</code></pre> <p>Real-world example: <pre><code># Workflow level - targets un-migrated projects\n[[conditions]]\nremote_file_exists = \"setup.cfg\"\n\n[[conditions]]\nremote_file_not_exists = \"pyproject.toml\"\n</code></pre></p> <p>Result: Only processes projects that have setup.cfg AND don't have pyproject.toml (haven't been migrated yet).</p>"},{"location":"workflow-conditions/#or-logic-condition_type-any","title":"OR Logic (condition_type = \"any\")","text":"<p>ANY ONE condition passing is sufficient for execution.</p> <pre><code>condition_type = \"any\"  # Any condition passing is sufficient\n\n[[conditions]]\nremote_file_exists = \"requirements.txt\"\n\n[[conditions]]\nremote_file_exists = \"pyproject.toml\"\n\n[[conditions]]\nremote_file_exists = \"setup.py\"\n</code></pre> <p>Result: Executes if project has ANY Python configuration file.</p>"},{"location":"workflow-conditions/#real-world-examples","title":"Real-World Examples","text":""},{"location":"workflow-conditions/#example-1-workflow-level-conditions-example-workflow","title":"Example 1: Workflow-Level Conditions (example-workflow)","text":"<pre><code># Only target Python projects that still use setup.cfg\n[[conditions]]\nremote_file_exists = \"setup.cfg\"\n\n[[conditions]]\nremote_file_not_exists = \"pyproject.toml\"\n</code></pre> <p>What it does:</p> <ol> <li>\u2705 Project must have <code>setup.cfg</code> (old configuration)</li> <li>\u2705 Project must NOT have <code>pyproject.toml</code> (not yet migrated)</li> </ol> <p>Why remote conditions? These checks happen before cloning, so we avoid cloning projects that don't need migration. For 1000 projects, this might only clone 50 that need fixing.</p>"},{"location":"workflow-conditions/#example-2-action-level-conditions-conditional-docker-extraction","title":"Example 2: Action-Level Conditions (Conditional Docker Extraction)","text":"<pre><code>[[actions]]\nname = \"extract-constraints\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"{{ extract_image_from_dockerfile('repository/Dockerfile') }}\"\nsource = \"/tmp/constraints.txt\"\ndestination = \"extracted:///constraints.txt\"\n\n[[actions.conditions]]\nfile_exists = \"Dockerfile\"\n</code></pre> <p>What it does:</p> <ul> <li>Only extracts Docker constraints if project has a Dockerfile</li> <li>If no Dockerfile, action is skipped (not a failure)</li> </ul> <p>Why action-level? Not all Python projects use Docker, so this action should only run when applicable.</p>"},{"location":"workflow-conditions/#example-3-multiple-action-conditions-compose-file-variations","title":"Example 3: Multiple Action Conditions (Compose File Variations)","text":"<pre><code>[[actions]]\nname = \"extract-original-docker-compose-yml\"\ntype = \"git\"\ncommand = \"extract\"\ncommit_keyword = \"migration\"\nsource = \"docker-compose.yml\"\ndestination = \"extracted:///compose.original.yaml\"\nignore_errors = true\n\n[[actions.conditions]]\nfile_not_exists = \"extracted:///compose.original.yaml\"\n\n[[actions.conditions]]\nfile_exists = \"repository:///compose.yaml\"\n</code></pre> <p>What it does:</p> <ol> <li>\u2705 Only extract if we haven't already extracted a compose file</li> <li>\u2705 Only extract if project currently has compose.yaml</li> </ol> <p>Why both conditions? Projects might have compose.yaml, compose.yml, docker-compose.yaml, or docker-compose.yml. The workflow tries each variant in sequence, but stops once one succeeds.</p>"},{"location":"workflow-conditions/#example-4-conditional-dockerfile-update","title":"Example 4: Conditional Dockerfile Update","text":"<pre><code>[[actions]]\nname = \"generate-dockerfile\"\ntype = \"claude\"\nprompt = \"prompts/dockerfile.md.j2\"\nvalidation_prompt = \"prompts/validate-dockerfile.md.j2\"\n\n[[actions.conditions]]\nfile_exists = \"repository:///Dockerfile\"\n</code></pre> <p>What it does:</p> <ul> <li>Only runs Claude to update Dockerfile if project has one</li> <li>Projects without Docker are skipped gracefully</li> </ul> <p>Why ResourceUrl? The <code>repository:///</code> prefix ensures we're checking the cloned repository, not extracted files.</p>"},{"location":"workflow-conditions/#example-5-multiple-condition-fallbacks","title":"Example 5: Multiple Condition Fallbacks","text":"<p>This pattern from example-workflow tries multiple compose file names:</p> <pre><code># Try compose.yaml first\n[[actions]]\nname = \"extract-original-compose-yaml\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \"compose.yaml\"\ndestination = \"extracted:///compose.original.yaml\"\n\n# Try compose.yml if compose.yaml wasn't found\n[[actions]]\nname = \"extract-original-compose-yml\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \"compose.yml\"\ndestination = \"extracted:///compose.original.yaml\"\n\n[[actions.conditions]]\nfile_not_exists = \"extracted:///compose.original.yaml\"  # Only if previous failed\n\n# Try docker-compose.yaml\n[[actions]]\nname = \"extract-original-docker-compose-yaml\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \"docker-compose.yaml\"\ndestination = \"extracted:///compose.original.yaml\"\n\n[[actions.conditions]]\nfile_not_exists = \"extracted:///compose.original.yaml\"\n\n# Try docker-compose.yml\n[[actions]]\nname = \"extract-original-docker-compose-yml\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \"docker-compose.yml\"\ndestination = \"extracted:///compose.original.yaml\"\n\n[[actions.conditions]]\nfile_not_exists = \"extracted:///compose.original.yaml\"\n</code></pre> <p>What it does:</p> <ol> <li>Try <code>compose.yaml</code> (modern name)</li> <li>If that fails, try <code>compose.yml</code></li> <li>If that fails, try <code>docker-compose.yaml</code></li> <li>If that fails, try <code>docker-compose.yml</code></li> <li>Stop at first success</li> </ol> <p>Why this pattern? Docker Compose supports multiple filenames, and different projects use different conventions. This ensures we find the file regardless of naming.</p>"},{"location":"workflow-conditions/#best-practices","title":"Best Practices","text":""},{"location":"workflow-conditions/#1-use-remote-conditions-first","title":"1. Use Remote Conditions First","text":"<pre><code># \u2705 Good - check remotely before cloning\n[[conditions]]\nremote_file_exists = \"package.json\"\n\n[[conditions]]\nremote_file_contains = \"node.*18\"\nremote_file = \".nvmrc\"\n\n# \u274c Slower - clones every repository\n[[conditions]]\nfile_exists = \"package.json\"\n\n[[conditions]]\nfile_contains = \"node.*18\"\nfile = \".nvmrc\"\n</code></pre> <p>Performance impact: For 1000 projects, remote conditions might process 50, while local conditions require cloning all 1000 first.</p>"},{"location":"workflow-conditions/#2-combine-and-logic-for-precision","title":"2. Combine AND Logic for Precision","text":"<pre><code>condition_type = \"all\"  # All must pass (default)\n\n[[conditions]]\nremote_file_exists = \"Dockerfile\"\n\n[[conditions]]\nremote_file_contains = \"FROM python:3\\\\.9\"\nremote_file = \"Dockerfile\"\n\n[[conditions]]\nremote_file_not_exists = \"pyproject.toml\"\n</code></pre> <p>Result: Only Python 3.9 Docker projects without pyproject.toml.</p>"},{"location":"workflow-conditions/#3-use-or-logic-for-flexibility","title":"3. Use OR Logic for Flexibility","text":"<pre><code>condition_type = \"any\"  # Any one passing is sufficient\n\n[[conditions]]\nremote_file_exists = \"setup.py\"\n\n[[conditions]]\nremote_file_exists = \"setup.cfg\"\n\n[[conditions]]\nremote_file_exists = \"pyproject.toml\"\n</code></pre> <p>Result: Any Python project with configuration.</p>"},{"location":"workflow-conditions/#4-action-conditions-for-optional-steps","title":"4. Action Conditions for Optional Steps","text":"<pre><code>[[actions]]\nname = \"update-dockerfile\"\ntype = \"file\"\n\n[[actions.conditions]]\nfile_exists = \"Dockerfile\"  # Skip if no Docker\n\n[[actions]]\nname = \"run-tests\"\ntype = \"shell\"\ncommand = \"pytest tests/\"\n\n[[actions.conditions]]\nfile_exists = \"tests/\"  # Skip if no tests\n</code></pre> <p>Why? Not all projects need all actions. Conditions allow graceful degradation.</p>"},{"location":"workflow-conditions/#5-avoid-over-filtering","title":"5. Avoid Over-Filtering","text":"<pre><code># \u274c Too restrictive - might miss valid projects\n[[conditions]]\nremote_file_contains = \"python_requires.*=.*['\\\"]3\\\\.9['\\\"]\"\nremote_file = \"setup.cfg\"\n\n# \u2705 Better - allows variations\n[[conditions]]\nremote_file_contains = \"python.*3\\\\.9\"\nremote_file = \"setup.cfg\"\n</code></pre> <p>Why? The second pattern matches more variations in how version might be specified.</p>"},{"location":"workflow-conditions/#condition-vs-filter","title":"Condition vs Filter","text":"Feature Filters Remote Conditions Local Conditions When evaluated Before processing Before cloning After cloning Data source Imbi metadata GitHub API Local filesystem Speed \u26a1\u26a1\u26a1 Fastest \u26a1\u26a1 Fast \u26a1 Slower Use for Project metadata File existence/content Complex patterns Glob support No Limited Full Bandwidth None Minimal High <p>Best practice: Use all three in combination:</p> <ol> <li>Filters for broad technology targeting</li> <li>Remote conditions for file-based applicability</li> <li>Local conditions for complex repository checks</li> </ol>"},{"location":"workflow-conditions/#complete-example","title":"Complete Example","text":"<p>This is the actual condition strategy from example-workflow:</p> <pre><code># Filter: Broad targeting\n[filter]\nproject_types = [\"apis\", \"consumers\", ...]\nproject_facts = {\"programming_language\" = \"Python 3.9\"}\ngithub_identifier_required = true\ngithub_workflow_status_exclude = [\"success\"]\n\n# Workflow conditions: Migration applicability\n[[conditions]]\nremote_file_exists = \"setup.cfg\"\n\n[[conditions]]\nremote_file_not_exists = \"pyproject.toml\"\n\n# Action conditions: Optional steps\n[[actions]]\nname = \"extract-constraints\"\ntype = \"docker\"\n\n[[actions.conditions]]\nfile_exists = \"Dockerfile\"  # Only if Docker is used\n\n[[actions]]\nname = \"ensure-correct-pins\"\ntype = \"claude\"\n\n[[actions.conditions]]\nfile_exists = \"Dockerfile\"  # Only if Docker is used\n\n[[actions]]\nname = \"generate-dockerfile\"\ntype = \"claude\"\n\n[[actions.conditions]]\nfile_exists = \"repository:///Dockerfile\"  # Only if Dockerfile exists\n</code></pre> <p>Result:</p> <ol> <li>Filter reduces 1000 projects \u2192 50 Python 3.9 projects with failing builds</li> <li>Remote conditions reduce 50 projects \u2192 30 projects needing migration (have setup.cfg, no pyproject.toml)</li> <li>Action conditions skip Docker-related actions for non-Docker projects</li> </ol>"},{"location":"workflow-conditions/#see-also","title":"See Also","text":"<ul> <li>Workflow Filters - Pre-filtering projects by metadata</li> <li>Workflow Configuration - Complete configuration reference</li> <li>Workflows Overview - High-level concepts and best practices</li> </ul>"},{"location":"workflow-configuration/","title":"Workflow Configuration Reference","text":"<p>Complete field reference for workflow configuration files (<code>workflow.toml</code>) with detailed descriptions, types, defaults, and examples.</p> <p>Tip: Workflow configuration syntax is validated on startup</p>"},{"location":"workflow-configuration/#configuration-structure","title":"Configuration Structure","text":"<p>A complete workflow configuration includes:</p> <pre><code># Workflow Metadata\nname = \"workflow-name\"\ndescription = \"Optional description\"\nprompt = \"workflow:///prompts/base.md\"\n\n# Project Filtering\n[filter]\nproject_ids = [123, 456]\nproject_types = [\"api\"]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\ngithub_identifier_required = true\ngithub_workflow_status_exclude = [\"success\"]\n\n# Git Configuration\n[git]\nclone = true\ndepth = 1\nref = \"main\"\nstarting_branch = \"main\"\nci_skip_checks = false\nclone_type = \"ssh\"  # or \"http\"\n\n# GitHub Configuration\n[github]\ncreate_pull_request = true\nreplace_branch = false\n\n# Workflow-Level Conditions\ncondition_type = \"all\"  # or \"any\"\n\n[[conditions]]\nremote_file_exists = \"file.txt\"\n\n# Actions\n[[actions]]\nname = \"action-name\"\ntype = \"file\"\n# ... action-specific fields\n</code></pre>"},{"location":"workflow-configuration/#workflow-metadata","title":"Workflow Metadata","text":""},{"location":"workflow-configuration/#name-required","title":"name (required)","text":"<p>Workflow display name shown in logs, reports, and pull requests.</p> <p>Type: <code>string</code> </p> <pre><code>name = \"Update Python Dependencies\"\n</code></pre>"},{"location":"workflow-configuration/#description-optional","title":"description (optional)","text":"<p>Human-readable description of workflow purpose and goals.</p> <p>Type: <code>string</code> </p> <p>Default: None  </p> <pre><code>description = \"Updates Python dependencies to latest compatible versions while maintaining compatibility\"\n</code></pre>"},{"location":"workflow-configuration/#prompt-optional","title":"prompt (optional)","text":"<p>Base prompt file for Claude Code actions. This prompt is prepended to all Claude actions in the workflow unless they specify their own prompt.</p> <p>Type: <code>ResourceUrl</code> (path to prompt template file)</p> <p>Default: None  </p> <pre><code>prompt = \"workflow:///prompts/base-context.md\"\n</code></pre> <p>Usage: Provides shared context across all Claude actions in the workflow.</p>"},{"location":"workflow-configuration/#git-configuration","title":"Git Configuration","text":"<p>The <code>[git]</code> section controls repository cloning and commit behavior.</p>"},{"location":"workflow-configuration/#clone","title":"clone","text":"<p>Whether to clone the repository from the remote.</p> <p>Type: <code>boolean</code> </p> <p>Default: <code>true</code> </p> <pre><code>[git]\nclone = true\n</code></pre> <p>When to use <code>false</code>: API-only workflows that don't need repository access.</p>"},{"location":"workflow-configuration/#depth","title":"depth","text":"<p>Shallow clone depth (number of commits to fetch).</p> <p>Type: <code>integer</code> </p> <p>Default: <code>1</code> </p> <pre><code>[git]\ndepth = 1  # Shallow clone (fastest)\n\n# OR\n\n[git]\ndepth = 100  # More history available for git operations\n</code></pre> <p>Use cases:</p> <ul> <li><code>depth = 1</code>: Fastest, use for most workflows</li> <li><code>depth = 100+</code>: When extracting files from commit history</li> </ul>"},{"location":"workflow-configuration/#ref","title":"ref","text":"<p>Git reference (branch, tag, or commit SHA) to clone.</p> <p>Type: <code>string</code> </p> <p>Default: Repository's default branch  </p> <pre><code>[git]\nref = \"main\"\n\n# OR\n\n[git]\nref = \"v1.2.3\"  # Clone specific tag\n\n# OR\n\n[git]\nref = \"abc123\"  # Clone specific commit\n</code></pre>"},{"location":"workflow-configuration/#starting_branch","title":"starting_branch","text":"<p>Branch name to use as starting point for workflow branch.</p> <p>Type: <code>string</code> </p> <p>Default: Repository's default branch  </p> <pre><code>[git]\nstarting_branch = \"develop\"  # Branch from develop instead of main\n</code></pre>"},{"location":"workflow-configuration/#ci_skip_checks","title":"ci_skip_checks","text":"<p>Whether to skip CI/CD checks in commit messages.</p> <p>Type: <code>boolean</code> </p> <p>Default: <code>false</code> </p> <pre><code>[git]\nci_skip_checks = true  # Adds [skip ci] to commit messages\n</code></pre>"},{"location":"workflow-configuration/#clone_type","title":"clone_type","text":"<p>Protocol to use for cloning repositories.</p> <p>Type: <code>string</code> </p> <p>Values: <code>\"ssh\"</code> (default), <code>\"http\"</code></p> <pre><code>[git]\nclone_type = \"ssh\"  # Use SSH keys (default)\n\n# OR\n\n[git]\nclone_type = \"http\"  # Use HTTPS (requires token)\n</code></pre>"},{"location":"workflow-configuration/#github-configuration","title":"GitHub Configuration","text":"<p>The <code>[github]</code> section controls GitHub pull request creation and branch management.</p>"},{"location":"workflow-configuration/#create_pull_request","title":"create_pull_request","text":"<p>Whether to create a pull request after committing changes.</p> <p>Type: <code>boolean</code> </p> <p>Default: <code>true</code> </p> <pre><code>[github]\ncreate_pull_request = true\n</code></pre> <p>When to use <code>false</code>: Direct commits to main (not recommended), testing workflows.</p>"},{"location":"workflow-configuration/#replace_branch","title":"replace_branch","text":"<p>Delete and recreate remote branch if it already exists.</p> <p>Type: <code>boolean</code> </p> <p>Default: <code>false</code> </p> <pre><code>[github]\ncreate_pull_request = true\nreplace_branch = true  # Force-replace existing PR branch\n</code></pre> <p>Requirements: <code>create_pull_request</code> must be <code>true</code>.</p> <p>Use cases:</p> <ul> <li>Updating failed workflow runs</li> <li>Re-running workflows with fixes</li> <li>Forcing clean state</li> </ul> <p>Warning: Destroys existing PR branch and its history.</p>"},{"location":"workflow-configuration/#followup-stage-configuration","title":"Followup Stage Configuration","text":""},{"location":"workflow-configuration/#max_followup_cycles","title":"max_followup_cycles","text":"<p>Maximum number of cycles for followup stage execution.</p> <p>Type: <code>integer</code> </p> <p>Default: <code>5</code> </p> <pre><code>max_followup_cycles = 3\n</code></pre> <p>Behavior: </p> <ul> <li>Followup actions execute after PR creation</li> <li>If any followup action commits, the stage cycles again</li> <li>If no commits made during a cycle, followup is complete</li> <li>If max cycles reached without completion, workflow fails</li> </ul> <p>Use cases:</p> <ul> <li>Limit iterations when monitoring CI</li> <li>Control retry behavior for feedback loops</li> <li>Prevent infinite loops in automated fixes</li> </ul> <p>See Action Stages for complete followup stage documentation.</p>"},{"location":"workflow-configuration/#mcp-server-configuration","title":"MCP Server Configuration","text":"<p>The <code>[mcp_servers]</code> section allows configuring Model Context Protocol (MCP) servers that will be available to Claude actions during workflow execution. MCP servers provide Claude with access to external tools and data sources.</p>"},{"location":"workflow-configuration/#supported-transport-types","title":"Supported Transport Types","text":"<p>Three MCP transport types are supported, matching the Claude Agent SDK:</p>"},{"location":"workflow-configuration/#stdio-standard-io","title":"stdio (Standard I/O)","text":"<p>Launch a local MCP server process:</p> <pre><code>[mcp_servers.my-postgres]\ntype = \"stdio\"\ncommand = \"uvx\"\nargs = [\"mcp-server-postgres\", \"${DATABASE_URL}\"]\nenv = { DATABASE_URL = \"${DATABASE_URL}\" }\n</code></pre> <p>Fields:</p> Field Type Required Description <code>type</code> <code>\"stdio\"</code> Yes Transport type <code>command</code> <code>string</code> Yes Executable to run <code>args</code> <code>list[string]</code> No Command arguments (default: <code>[]</code>) <code>env</code> <code>dict[string, string]</code> No Environment variables (default: <code>{}</code>)"},{"location":"workflow-configuration/#http-http","title":"http (HTTP)","text":"<p>Connect to an HTTP-based MCP server:</p> <pre><code>[mcp_servers.my-api]\ntype = \"http\"\nurl = \"https://api.example.com/mcp\"\nheaders = { Authorization = \"Bearer ${API_TOKEN}\" }\n</code></pre> <p>Fields:</p> Field Type Required Description <code>type</code> <code>\"http\"</code> Yes Transport type <code>url</code> <code>string</code> Yes Server endpoint URL <code>headers</code> <code>dict[string, string]</code> No HTTP headers (default: <code>{}</code>)"},{"location":"workflow-configuration/#sse-server-sent-events","title":"sse (Server-Sent Events)","text":"<p>Connect to an SSE-based MCP server:</p> <pre><code>[mcp_servers.my-events]\ntype = \"sse\"\nurl = \"https://api.example.com/mcp/sse\"\nheaders = { Authorization = \"Bearer ${API_TOKEN}\" }\n</code></pre> <p>Fields:</p> Field Type Required Description <code>type</code> <code>\"sse\"</code> Yes Transport type <code>url</code> <code>string</code> Yes SSE endpoint URL <code>headers</code> <code>dict[string, string]</code> No HTTP headers (default: <code>{}</code>)"},{"location":"workflow-configuration/#environment-variable-expansion","title":"Environment Variable Expansion","text":"<p>MCP server configurations support shell-style environment variable expansion for secure credential injection:</p> <ul> <li><code>$VAR</code> - Basic expansion</li> <li><code>${VAR}</code> - Braced expansion (recommended)</li> </ul> <p>Environment variables are expanded at runtime when the Claude client is created, not at configuration parse time.</p> <p>Example:</p> <pre><code>[mcp_servers.production-db]\ntype = \"stdio\"\ncommand = \"uvx\"\nargs = [\"mcp-server-postgres\", \"${PROD_DATABASE_URL}\"]\n\n[mcp_servers.internal-api]\ntype = \"http\"\nurl = \"https://api.internal.example.com/mcp\"\nheaders = { Authorization = \"Bearer ${INTERNAL_API_TOKEN}\" }\n</code></pre> <p>Supported Locations:</p> <ul> <li><code>args</code> list values</li> <li><code>env</code> dict values</li> <li><code>url</code> string</li> <li><code>headers</code> dict values</li> </ul> <p>Error Handling:</p> <p>If a referenced environment variable is not set, a clear error is raised:</p> <pre><code>ValueError: Environment variable PROD_DATABASE_URL not set\n</code></pre>"},{"location":"workflow-configuration/#complete-example","title":"Complete Example","text":"<pre><code>name = \"Data Analysis Workflow\"\ndescription = \"Analyze project data using MCP-connected databases\"\n\n[mcp_servers.postgres]\ntype = \"stdio\"\ncommand = \"uvx\"\nargs = [\"mcp-server-postgres\", \"${DATABASE_URL}\"]\n\n[mcp_servers.clickhouse]\ntype = \"http\"\nurl = \"https://clickhouse.example.com/mcp\"\nheaders = { Authorization = \"Bearer ${CLICKHOUSE_TOKEN}\" }\n\n[mcp_servers.neo4j]\ntype = \"stdio\"\ncommand = \"uvx\"\nargs = [\"mcp-server-neo4j\"]\nenv = { NEO4J_URL = \"${NEO4J_URL}\", NEO4J_PASSWORD = \"${NEO4J_PASSWORD}\" }\n\n[[actions]]\nname = \"analyze-data\"\ntype = \"claude\"\ntask_prompt = \"prompts/analyze.md\"\n</code></pre> <p>In Claude actions, these MCP servers are available alongside the built-in <code>agent_tools</code> server that provides workflow submission functions.</p>"},{"location":"workflow-configuration/#claude-code-plugin-configuration","title":"Claude Code Plugin Configuration","text":"<p>The <code>[plugins]</code> section allows configuring Claude Code plugins and marketplaces at the workflow level. These settings are merged with the main configuration's <code>[claude_code.plugins]</code> settings.</p>"},{"location":"workflow-configuration/#merge-behavior","title":"Merge Behavior","text":"Setting Merge Behavior <code>enabled_plugins</code> Workflow values override main config <code>marketplaces</code> Workflow values override main config for same keys <code>local_plugins</code> Concatenated (duplicates removed by path)"},{"location":"workflow-configuration/#pluginsenabled_plugins","title":"[plugins].enabled_plugins","text":"<p>Enable or disable specific plugins for this workflow.</p> <p>Type: <code>dict[string, boolean]</code> </p> <pre><code>[plugins.enabled_plugins]\n\"workflow-specific-plugin@marketplace\" = true\n\"grafana-mcp@aweber-marketplace\" = true  # Override main config\n</code></pre>"},{"location":"workflow-configuration/#pluginsmarketplaces","title":"[plugins.marketplaces]","text":"<p>Add workflow-specific marketplace sources.</p> <p>Type: <code>dict[string, ClaudeMarketplace]</code> </p> <pre><code>[plugins.marketplaces.workflow-marketplace]\nsource = \"github\"\nrepo = \"org/workflow-specific-plugins\"\n\n[plugins.marketplaces.local-dev]\nsource = \"directory\"\npath = \"/path/to/dev/marketplace\"\n</code></pre>"},{"location":"workflow-configuration/#pluginslocal_plugins","title":"[[plugins.local_plugins]]","text":"<p>Add workflow-specific local plugins.</p> <p>Type: <code>list[ClaudeLocalPlugin]</code> </p> <pre><code>[[plugins.local_plugins]]\npath = \"/path/to/workflow/plugin\"\n</code></pre>"},{"location":"workflow-configuration/#complete-workflow-plugin-example","title":"Complete Workflow Plugin Example","text":"<pre><code>name = \"Data Analysis Workflow\"\ndescription = \"Analyze data using specialized plugins\"\n\n# Enable workflow-specific plugins\n[plugins.enabled_plugins]\n\"data-analyzer@analytics-marketplace\" = true\n\"grafana-mcp@aweber-marketplace\" = true  # Enable for this workflow\n\n# Add workflow-specific marketplace\n[plugins.marketplaces.analytics-marketplace]\nsource = \"github\"\nrepo = \"company/analytics-plugins\"\n\n# Add local development plugin\n[[plugins.local_plugins]]\npath = \"/home/user/data-analysis-plugin\"\n\n[[actions]]\nname = \"analyze-data\"\ntype = \"claude\"\ntask_prompt = \"prompts/analyze.md\"\n</code></pre>"},{"location":"workflow-configuration/#workflow-level-conditions","title":"Workflow-Level Conditions","text":"<p>Workflow conditions determine if the entire workflow should execute for a project. See Workflow Conditions for detailed documentation.</p>"},{"location":"workflow-configuration/#condition_type","title":"condition_type","text":"<p>How to evaluate multiple conditions.</p> <p>Type: <code>string</code> </p> <p>Values: <code>\"all\"</code> (AND logic), <code>\"any\"</code> (OR logic)</p> <p>Default: <code>\"all\"</code> </p> <pre><code>condition_type = \"all\"  # All conditions must pass\n\n[[conditions]]\nremote_file_exists = \"package.json\"\n\n[[conditions]]\nremote_file_contains = \"node.*18\"\nremote_file = \".nvmrc\"\n</code></pre> <p>With <code>condition_type = \"all\"</code>, workflow executes only if BOTH conditions pass.</p> <pre><code>condition_type = \"any\"  # Any one condition passing is sufficient\n\n[[conditions]]\nremote_file_exists = \"requirements.txt\"\n\n[[conditions]]\nremote_file_exists = \"pyproject.toml\"\n</code></pre> <p>With <code>condition_type = \"any\"</code>, workflow executes if EITHER file exists.</p>"},{"location":"workflow-configuration/#conditions","title":"[[conditions]]","text":"<p>Array of condition objects. See Workflow Conditions for complete condition types and examples.</p> <p>Condition Types:</p> <ul> <li>Remote conditions (checked via API before cloning)</li> <li><code>remote_file_exists</code> / <code>remote_file_not_exists</code></li> <li> <p><code>remote_file_contains</code> / <code>remote_file_doesnt_contain</code> + <code>remote_file</code></p> </li> <li> <p>Local conditions (checked after cloning)</p> </li> <li><code>file_exists</code> / <code>file_not_exists</code></li> <li> <p><code>file_contains</code> / <code>file_doesnt_contain</code> + <code>file</code></p> </li> <li> <p>Template conditions (checked after cloning)</p> </li> <li><code>when</code> - Jinja2 expression for complex logic</li> </ul> <p>Example: <pre><code>[[conditions]]\nremote_file_exists = \"Dockerfile\"\n\n[[conditions]]\nremote_file_contains = \"FROM python:3\"\nremote_file = \"Dockerfile\"\n\n[[conditions]]\nwhen = \"{{ compare_semver(get_component_version('repository:///package.json', 'react'), '19.0.0').is_older }}\"\n</code></pre></p>"},{"location":"workflow-configuration/#actions","title":"Actions","text":"<p>Actions define the operations to perform during workflow execution. Each action has common fields plus type-specific configuration.</p>"},{"location":"workflow-configuration/#common-action-fields","title":"Common Action Fields","text":"<p>All actions support these fields:</p>"},{"location":"workflow-configuration/#name-required_1","title":"name (required)","text":"<p>Action identifier for logging and error messages.</p> <p>Type: <code>string</code> </p> <pre><code>[[actions]]\nname = \"copy-gitignore\"\n</code></pre>"},{"location":"workflow-configuration/#type-required","title":"type (required)","text":"<p>Action type determines which operation to perform.</p> <p>Type: <code>string</code> </p> <p>Values: <code>callable</code>, <code>claude</code>, <code>docker</code>, <code>file</code>, <code>git</code>, <code>github</code>, <code>imbi</code>, <code>shell</code>, <code>template</code></p> <pre><code>[[actions]]\ntype = \"file\"\n</code></pre> <p>See Actions Reference for complete documentation of each action type.</p>"},{"location":"workflow-configuration/#stage-optional","title":"stage (optional)","text":"<p>Execution stage for this action.</p> <p>Type: <code>string</code> </p> <p>Values: <code>\"primary\"</code> (default), <code>\"followup\"</code></p> <pre><code>[[actions]]\nname = \"monitor-ci\"\ntype = \"claude\"\nstage = \"followup\"\ntask_prompt = \"prompts/monitor.md.j2\"\n</code></pre> <p>Stage behaviors:</p> <ul> <li><code>primary</code>: Executes before PR creation (default behavior)</li> <li><code>followup</code>: Executes after PR is created, with access to PR context</li> </ul> <p>Followup stage features:</p> <ul> <li>Receives <code>pull_request</code> and <code>pr_branch</code> in template context</li> <li>Can commit changes that push to PR branch</li> <li>Cycles if commits are made (up to <code>max_followup_cycles</code>)</li> </ul> <p>See Action Stages for detailed stage documentation.</p>"},{"location":"workflow-configuration/#ai_commit-optional","title":"ai_commit (optional)","text":"<p>Use AI to generate commit message for this action's changes.</p> <p>Type: <code>boolean</code> </p> <p>Default: <code>false</code> </p> <p>Requires: Anthropic API key configured</p> <pre><code>[[actions]]\nname = \"complex-refactor\"\ntype = \"claude\"\nai_commit = true  # AI-generated commit message\n</code></pre>"},{"location":"workflow-configuration/#commit_message-optional","title":"commit_message (optional)","text":"<p>Specify a custom commit message for this action's changes. Only valid when <code>ai_commit</code> is <code>false</code> (or unset) and <code>committable</code> is <code>true</code>.</p> <p>Type: <code>string</code> </p> <p>Default: <code>null</code> (uses auto-generated message)  </p> <p>Validation:</p> <ul> <li>Cannot be set when <code>ai_commit = true</code></li> <li>Cannot be set when <code>committable = false</code></li> </ul> <p>Auto-generated format when not specified:</p> <pre><code>imbi-automations: workflow-name - action-name\n\n\ud83e\udd16 Generated with [Imbi Automations](https://github.com/AWeber-Imbi/).\n</code></pre> <p>Custom message example:</p> <pre><code>[[actions]]\nname = \"update-dependencies\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///requirements.txt\"\ndestination = \"repository:///requirements.txt\"\ncommit_message = \"Update Python dependencies to latest versions\"\n</code></pre> <p>Use cases:</p> <ul> <li>Semantic commit messages for specific changes</li> <li>Conventional commit format enforcement</li> <li>Custom formatting for automated changelogs</li> <li>Descriptive messages for significant updates</li> </ul>"},{"location":"workflow-configuration/#committable-optional","title":"committable (optional)","text":"<p>Whether this action's changes should be included in git commits.</p> <p>Type: <code>boolean</code> </p> <p>Default: <code>true</code> </p> <pre><code>[[actions]]\nname = \"temporary-analysis\"\ntype = \"file\"\ncommand = \"write\"\ncommittable = false  # Don't commit this file\n</code></pre> <p>Use cases:</p> <ul> <li>Temporary files for other actions</li> <li>Diagnostic output files</li> <li>Intermediate processing artifacts</li> </ul>"},{"location":"workflow-configuration/#on_success-optional","title":"on_success (optional)","text":"<p>Action name to jump to if this action succeeds.</p> <p>Type: <code>string</code> (action name)  </p> <pre><code>[[actions]]\nname = \"try-fast-method\"\ntype = \"shell\"\ncommand = \"fast-operation\"\non_success = \"skip-slow-method\"\n\n[[actions]]\nname = \"slow-fallback\"\n# This will be skipped if fast method succeeds\n\n[[actions]]\nname = \"skip-slow-method\"\n# Execution resumes here\n</code></pre>"},{"location":"workflow-configuration/#on_failure-optional","title":"on_failure (optional)","text":"<p>Action name to restart from if this action fails after all retry cycles.</p> <p>Type: <code>string</code> (action name)  </p> <p>Max Retries: 3 per action</p> <pre><code>[[actions]]\nname = \"backup-files\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///src/\"\ndestination = \"extracted:///src.backup/\"\n\n[[actions]]\nname = \"risky-transformation\"\ntype = \"claude\"\nprompt = \"prompts/transform.md\"\non_failure = \"restore-backup\"\n\n[[actions]]\nname = \"restore-backup\"\ntype = \"file\"\ncommand = \"move\"\nsource = \"extracted:///src.backup/\"\ndestination = \"repository:///src/\"\n</code></pre>"},{"location":"workflow-configuration/#timeout-optional","title":"timeout (optional)","text":"<p>Maximum execution time for action in Go time.Duration format.</p> <p>Type: <code>string</code></p> <p>Default: <code>\"1h\"</code> (1 hour)</p> <p>Supported formats: - Minutes: <code>\"5m\"</code>, <code>\"30m\"</code> - Hours: <code>\"1h\"</code>, <code>\"2h30m\"</code> - Seconds: <code>\"90s\"</code> - Combined: <code>\"1h30m45s\"</code></p> <p>Behavior: - Claude actions: Timeout applies per-cycle (each planning/task/validation gets the full duration) - Shell/Docker actions: Timeout applies to single execution - On timeout: Process terminated gracefully (SIGTERM \u2192 SIGKILL), workflow fails with error</p> <pre><code>[[actions]]\nname = \"long-running-build\"\ntype = \"shell\"\ncommand = \"make build\"\ntimeout = \"2h\"  # 2 hours\n</code></pre>"},{"location":"workflow-configuration/#filter-optional","title":"filter (optional)","text":"<p>Project filter to apply for this specific action. Uses same filter format as workflow-level <code>[filter]</code>.</p> <p>Type: <code>WorkflowFilter</code> object</p> <pre><code>[[actions]]\nname = \"api-specific-update\"\ntype = \"file\"\n\n# Only execute this action for API projects\n[actions.filter]\nproject_types = [\"api\"]\n</code></pre>"},{"location":"workflow-configuration/#condition_type-optional","title":"condition_type (optional)","text":"<p>How to evaluate multiple action conditions.</p> <p>Type: <code>string</code> </p> <p>Values: <code>\"all\"</code> (default), <code>\"any\"</code></p> <pre><code>[[actions]]\nname = \"update-python-config\"\ntype = \"template\"\ncondition_type = \"any\"  # Execute if ANY config file exists\n\n[[actions.conditions]]\nfile_exists = \"setup.py\"\n\n[[actions.conditions]]\nfile_exists = \"pyproject.toml\"\n\n[[actions.conditions]]\nfile_exists = \"requirements.txt\"\n</code></pre>"},{"location":"workflow-configuration/#actionsconditions","title":"[[actions.conditions]]","text":"<p>Array of conditions that must pass for this action to execute. Same condition types as workflow-level conditions.</p> <p>Example: <pre><code>[[actions]]\nname = \"update-dockerfile\"\ntype = \"file\"\n\n[[actions.conditions]]\nfile_exists = \"Dockerfile\"\n\n[[actions.conditions]]\nfile_contains = \"FROM python:3\\\\.11\"\nfile = \"Dockerfile\"\n</code></pre></p> <p>See Workflow Conditions for detailed condition documentation.</p>"},{"location":"workflow-configuration/#data-optional","title":"data (optional)","text":"<p>Custom data dictionary for action-specific use.</p> <p>Type: <code>dict[string, any]</code> </p> <p>Default: <code>{}</code> </p> <pre><code>[[actions]]\nname = \"custom-action\"\ntype = \"callable\"\n\n[actions.data]\ncustom_field = \"value\"\nnested = { key = \"value\" }\n</code></pre>"},{"location":"workflow-configuration/#action-specific-fields","title":"Action-Specific Fields","text":"<p>Each action type has additional required and optional fields. See the Actions Reference for complete documentation:</p> <ul> <li>Callable Actions - <code>import</code>, <code>callable</code>, <code>args</code>, <code>kwargs</code></li> <li>Claude Actions - <code>prompt</code>, <code>validation_prompt</code>, <code>max_cycles</code></li> <li>Docker Actions - <code>command</code>, <code>image</code>, <code>tag</code>, <code>source</code>, <code>destination</code></li> <li>File Actions - <code>command</code>, <code>path</code>, <code>source</code>, <code>destination</code>, <code>content</code>, <code>pattern</code></li> <li>Git Actions - <code>command</code>, <code>source</code>, <code>destination</code>, <code>url</code>, <code>commit_keyword</code></li> <li>GitHub Actions - <code>command</code></li> <li>Imbi Actions - <code>command</code></li> <li>Shell Actions - <code>command</code>, <code>working_directory</code>, <code>ignore_errors</code></li> <li>Template Actions - <code>source_path</code>, <code>destination_path</code></li> </ul>"},{"location":"workflow-configuration/#complete-example_1","title":"Complete Example","text":"<pre><code>name = \"Python 3.12 Migration\"\ndescription = \"Migrate Python projects from 3.11 to 3.12\"\nprompt = \"workflow:///prompts/base-python.md\"\n\n[filter]\nproject_types = [\"api\", \"consumer\", \"daemon\"]\nproject_facts = {\"Programming Language\" = \"Python 3.11\"}\ngithub_identifier_required = true\ngithub_workflow_status_exclude = [\"success\"]\n\n[git]\nclone = true\ndepth = 100  # Need history for git extract actions\nstarting_branch = \"main\"\nclone_type = \"ssh\"\n\n[github]\ncreate_pull_request = true\nreplace_branch = true\n\ncondition_type = \"all\"\n\n[[conditions]]\nremote_file_exists = \"pyproject.toml\"\n\n[[conditions]]\nremote_file_contains = \"python.*3\\\\.11\"\nremote_file = \"pyproject.toml\"\n\n[[actions]]\nname = \"backup-pyproject\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///pyproject.toml\"\ndestination = \"extracted:///pyproject.toml.backup\"\ncommittable = false\n\n[[actions]]\nname = \"update-python-version\"\ntype = \"claude\"\nprompt = \"prompts/update-python-version.md\"\nvalidation_prompt = \"prompts/validate-python-version.md\"\nmax_cycles = 3\non_failure = \"restore-backup\"\nai_commit = true\n\n[[actions]]\nname = \"run-tests\"\ntype = \"shell\"\ncommand = \"pytest tests/ -v\"\nworking_directory = \"repository:///\"\ntimeout = \"10m\"\n\n[[actions.conditions]]\nfile_exists = \"tests/\"\n\n[[actions]]\nname = \"restore-backup\"\ntype = \"file\"\ncommand = \"move\"\nsource = \"extracted:///pyproject.toml.backup\"\ndestination = \"repository:///pyproject.toml\"\n</code></pre>"},{"location":"workflow-configuration/#see-also","title":"See Also","text":"<ul> <li>Workflow Filters - Detailed filter documentation with examples</li> <li>Workflow Conditions - Comprehensive condition types and patterns</li> <li>Actions Reference - Complete action types documentation</li> <li>Workflows Overview - High-level workflow concepts and best practices</li> </ul>"},{"location":"workflow-filters/","title":"Workflow Filters","text":"<p>Project filters reduce the scope of workflow execution by pre-filtering projects based on Imbi metadata before any workflow processing begins. This is the first and most efficient level of project selection.</p>"},{"location":"workflow-filters/#when-to-use-filters","title":"When to Use Filters","text":"<p>Use filters when you want to:</p> <ul> <li>Target specific project types (APIs, consumers, libraries, etc.)</li> <li>Select projects with specific technology stacks</li> <li>Require GitHub integration</li> <li>Exclude projects with passing builds (target only failing ones)</li> <li>Process only a specific subset of projects</li> </ul> <p>Performance benefit: Filtered-out projects are never processed, saving API calls, cloning, and condition evaluation.</p>"},{"location":"workflow-filters/#filter-configuration","title":"Filter Configuration","text":"<p>Filters are defined in the <code>[filter]</code> section of <code>config.toml</code>:</p> <pre><code>[filter]\nproject_ids = [123, 456, 789]\nproject_types = [\"api\", \"consumer\"]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\nproject_environments = [\"production\", \"staging\"]\ngithub_identifier_required = true\ngithub_workflow_status_exclude = [\"success\"]\n\n# New: Flexible field filtering\n[filter.project.description]\nis_empty = true\n\n[filter.project.name]\nregex = \"^api-.*\"\n</code></pre> <p>Filter Logic: ALL filter criteria must match (AND logic). A project must satisfy every filter to be included.</p>"},{"location":"workflow-filters/#filter-fields","title":"Filter Fields","text":""},{"location":"workflow-filters/#project_ids","title":"project_ids","text":"<p>Target specific projects by their Imbi project ID.</p> <p>Type: <code>list[int]</code> </p> <p>Default: <code>[]</code> (no ID filtering)  </p> <pre><code>[filter]\nproject_ids = [42, 108, 256]\n</code></pre> <p>Use cases:</p> <ul> <li>Testing workflows on specific projects</li> <li>Fixing issues in known problem projects</li> <li>Updating projects that failed in a previous run</li> </ul> <p>Example from real workflow: <pre><code># Test workflow on three projects before full rollout\n[filter]\nproject_ids = [123, 456, 789]\n</code></pre></p>"},{"location":"workflow-filters/#project_types","title":"project_types","text":"<p>Filter by project type slugs from Imbi.</p> <p>Type: <code>list[string]</code> </p> <p>Default: <code>[]</code> (no type filtering)  </p> <p>Common project types:</p> <ul> <li><code>api</code> / <code>apis</code> - REST APIs and web services</li> <li><code>backend-libraries</code> - Shared backend libraries</li> <li><code>bots</code> - Chat and automation bots</li> <li><code>cli</code> / <code>clis</code> - Command-line tools</li> <li><code>consumer</code> / <code>consumers</code> - Message queue consumers</li> <li><code>daemon</code> / <code>daemons</code> - Background services</li> <li><code>frontend</code> - Web frontends</li> <li><code>plugin</code> / <code>plugins</code> - Extension plugins</li> <li><code>scheduled-job</code> / <code>scheduled-jobs</code> - Cron-like tasks</li> </ul> <pre><code>[filter]\nproject_types = [\"api\", \"consumer\", \"daemon\"]\n</code></pre> <p>Real-world example: <pre><code>[filter]\nproject_types = [\n    \"apis\",\n    \"backend-libraries\",\n    \"bots\",\n    \"clis\",\n    \"consumers\",\n    \"daemons\",\n    \"plugin\",\n    \"scheduled-jobs\"\n]\n</code></pre></p> <p>Why this filter? Excludes frontend projects that don't use Python setup.cfg files.</p>"},{"location":"workflow-filters/#project_facts","title":"project_facts","text":"<p>Filter by exact Imbi project fact values.</p> <p>Type: <code>dict[string, string]</code> </p> <p>Default: <code>{}</code> (no fact filtering)  </p> <p>Fact matching:</p> <ul> <li>Keys are fact names (case-sensitive)</li> <li>Values must match exactly</li> <li>ALL specified facts must match (AND logic)</li> </ul> <pre><code>[filter]\nproject_facts = {\n    \"Programming Language\" = \"Python 3.12\",\n    \"Framework\" = \"FastAPI\"\n}\n</code></pre> <p>Only projects with BOTH <code>Programming Language = \"Python 3.12\"</code> AND <code>Framework = \"FastAPI\"</code> will be included.</p> <p>Real-world example: <pre><code>[filter]\nproject_facts = {\"programming_language\" = \"Python 3.9\"}\n</code></pre></p> <p>Why this filter? Targets only Python 3.9 projects that need updating.</p> <p>Common fact names:</p> <ul> <li><code>Programming Language</code> - e.g., \"Python 3.12\", \"TypeScript\", \"Go\"</li> <li><code>Framework</code> - e.g., \"FastAPI\", \"Flask\", \"Express\"</li> <li><code>Database</code> - e.g., \"PostgreSQL\", \"MongoDB\"</li> <li><code>Message Queue</code> - e.g., \"RabbitMQ\", \"SQS\"</li> <li><code>Deployment Platform</code> - e.g., \"Kubernetes\", \"ECS\"</li> </ul>"},{"location":"workflow-filters/#project_environments","title":"project_environments","text":"<p>Filter by Imbi project environments.</p> <p>Type: <code>list[string]</code> </p> <p>Default: <code>[]</code> (no environment filtering)  </p> <p>Environment matching:</p> <ul> <li>Supports both environment names (\"Production\") and slugs (\"production\")</li> <li>ALL specified environments must be present in project (AND logic)</li> <li>Matches against both <code>name</code> and <code>slug</code> fields of <code>ImbiEnvironment</code> objects</li> </ul> <pre><code>[filter]\nproject_environments = [\"production\", \"staging\"]\n</code></pre> <p>Only projects with BOTH production AND staging environments will be included.</p> <p>Real-world example: <pre><code>[filter]\nproject_environments = [\"Production\", \"Staging\", \"Development\"]\n</code></pre></p> <p>Why this filter? Target only projects with complete environment configurations for deployment workflows.</p> <p>Flexible matching: <pre><code># These are all equivalent:\nproject_environments = [\"Production\"]\nproject_environments = [\"production\"]\nproject_environments = [\"PRODUCTION\"]\n</code></pre></p> <p>The filter checks against both the original environment name and the auto-generated slug.</p>"},{"location":"workflow-filters/#github_identifier_required","title":"github_identifier_required","text":"<p>Require projects to have a GitHub repository identifier.</p> <p>Type: <code>boolean</code> </p> <p>Default: <code>false</code> </p> <pre><code>[filter]\ngithub_identifier_required = true\n</code></pre> <p>Use cases:</p> <ul> <li>GitHub-specific workflows (workflow fixes, PR automation)</li> <li>Projects that must have CI/CD</li> <li>Excluding archived projects without GitHub integration</li> </ul> <p>Real-world example: <pre><code>[filter]\ngithub_identifier_required = true\n</code></pre></p> <p>Why this filter? Workflow creates pull requests, so GitHub integration is required.</p>"},{"location":"workflow-filters/#project","title":"project","text":"<p>Filter projects based on arbitrary field conditions with flexible operators.</p> <p>Type: <code>dict[string, ProjectFieldFilter]</code> </p> <p>Default: <code>{}</code> (no field filtering)  </p> <p>Available operators:</p> <ul> <li><code>is_null</code> - Check if field is None</li> <li><code>is_not_null</code> - Check if field is not None</li> <li><code>is_empty</code> - Check if field is None OR empty string</li> <li><code>equals</code> - Exact value match</li> <li><code>not_equals</code> - Value must not match</li> <li><code>contains</code> - Substring search (strings only)</li> <li><code>regex</code> - Pattern matching (strings only)</li> </ul> <p>Key constraint: Only ONE operator per field filter.</p> <pre><code># Filter projects without descriptions\n[filter.project.description]\nis_empty = true\n\n# Filter projects by name pattern\n[filter.project.name]\nregex = \"^api-.*\"\n\n# Filter projects with specific archived status\n[filter.project.archived]\nequals = false\n</code></pre> <p>Common use cases:</p> <p>Find projects missing metadata: <pre><code>[filter.project.description]\nis_empty = true\n</code></pre></p> <p>Target projects by name pattern: <pre><code>[filter.project.name]\nregex = \"^(api|service)-\"\n</code></pre></p> <p>Exclude archived projects: <pre><code>[filter.project.archived]\nequals = false\n</code></pre></p> <p>Find projects with specific text: <pre><code>[filter.project.description]\ncontains = \"legacy\"\n</code></pre></p> <p>Available project fields:</p> <ul> <li><code>name</code> - Project name</li> <li><code>slug</code> - Project slug</li> <li><code>description</code> - Project description</li> <li><code>archived</code> - Whether project is archived</li> <li><code>project_type_name</code> - Project type name</li> <li><code>project_type_slug</code> - Project type slug</li> <li><code>namespace_slug</code> - Namespace slug</li> <li>Any custom fields on <code>ImbiProject</code> model</li> </ul> <p>Real-world example: <pre><code># Find Python projects without descriptions\n[filter]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\n\n[filter.project.description]\nis_empty = true\n</code></pre></p> <p>Performance: Field filters evaluate against cached Imbi data, making them very fast.</p> <p>Validation: Fields are checked for existence at runtime. Non-existent fields cause projects to be filtered out with a warning.</p>"},{"location":"workflow-filters/#github_workflow_status_exclude","title":"github_workflow_status_exclude","text":"<p>Exclude projects with specific GitHub Actions workflow statuses.</p> <p>Type: <code>list[string]</code></p> <p>Default: <code>[]</code> (no status filtering)</p> <p>Valid statuses:</p> <ul> <li><code>\"success\"</code> - All workflows passing</li> <li><code>\"failure\"</code> - At least one workflow failing</li> <li><code>\"pending\"</code> - Workflows currently running</li> <li><code>\"skipped\"</code> - Workflows skipped</li> </ul> <pre><code>[filter]\ngithub_workflow_status_exclude = [\"success\"]\n</code></pre> <p>Only projects with failing, pending, or no workflows will be processed.</p> <p>Real-world example: <pre><code>[filter]\ngithub_workflow_status_exclude = [\"success\"]\n</code></pre></p> <p>Why this filter? No need to process projects with passing builds - they don't need fixes.</p> <p>Common patterns: <pre><code># Only process failing builds\n[filter]\ngithub_workflow_status_exclude = [\"success\", \"pending\", \"skipped\"]\n\n# Exclude projects with active/passing workflows\n[filter]\ngithub_workflow_status_exclude = [\"success\", \"pending\"]\n\n# Only process completely broken projects\n[filter]\ngithub_workflow_status_exclude = [\"success\", \"pending\"]\n</code></pre></p>"},{"location":"workflow-filters/#exclude_open_workflow_prs","title":"exclude_open_workflow_prs","text":"<p>Exclude projects that already have open pull requests for a specific workflow.</p> <p>Type: <code>bool | string</code></p> <p>Default: <code>false</code> (no PR filtering)</p> <p>Behavior:</p> <ul> <li><code>false</code> - Filter disabled (default)</li> <li><code>true</code> - Exclude projects with open PRs for the current workflow</li> <li><code>\"workflow-slug\"</code> - Exclude projects with open PRs for the specified workflow</li> </ul> <p>PR states that cause exclusion:</p> <ul> <li>Open PRs (including drafts) - Work still in progress</li> <li>Closed unmerged PRs - Failed or abandoned changes</li> </ul> <p>Why exclude closed-unmerged PRs? They indicate issues or rejected changes that should be resolved before re-running the workflow.</p> <pre><code>[filter]\nexclude_open_workflow_prs = true\n</code></pre> <p>Projects with open PRs for this workflow will be skipped.</p> <p>Real-world examples:</p> <pre><code># Prevent duplicate PRs for same workflow\n[filter]\nproject_types = [\"api\", \"consumer\"]\ngithub_identifier_required = true\nexclude_open_workflow_prs = true  # Skip if PR already exists\n</code></pre> <pre><code># Cross-workflow dependency\nname = \"Secondary Workflow\"\n\n[filter]\n# Only run after primary workflow PR is merged\nexclude_open_workflow_prs = \"primary-workflow\"\n</code></pre> <pre><code># Combined with other filters\n[filter]\nproject_types = [\"api\"]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\ngithub_identifier_required = true\ngithub_workflow_status_exclude = [\"success\"]\nexclude_open_workflow_prs = true  # Skip projects with pending PRs\n</code></pre> <p>Why this filter? Prevents creating duplicate PRs when: - Projects haven't updated their Imbi facts yet - PRs haven't been reviewed or merged yet - Workflow re-runs before previous execution completes</p> <p>How it works:</p> <p>The filter checks for PRs with head branch matching <code>imbi-automations/{workflow-slug}</code>:</p> <ol> <li>Branch identification: Each workflow creates PRs on branch <code>imbi-automations/{slug}</code></li> <li>PR state check: Looks for open, draft, or closed-unmerged PRs</li> <li>Exclusion logic: If blocking PR found, skip the project</li> </ol> <p>Error handling:</p> <p>Uses fail-open approach: API failures or errors log warnings but allow the project through. This prevents transient GitHub API issues from blocking valid workflow executions.</p> <p>Performance note:</p> <p>This filter requires a GitHub API call per project, so it's placed after cheap filters (IDs, types, facts) but before repository cloning. Projects filtered out here avoid the expensive git clone operation.</p> <p>Use cases:</p> <ol> <li>Prevent duplicate work:</li> <li>Don't re-run if PR already exists</li> <li> <p>Wait for facts to update before next run</p> </li> <li> <p>Sequential workflows:</p> </li> <li>Workflow B waits for Workflow A's PR to merge</li> <li> <p>Cross-workflow orchestration</p> </li> <li> <p>Manual review workflows:</p> </li> <li>Create PR, wait for approval</li> <li>Don't create new PR until previous is handled</li> </ol> <p>Example workflow sequence:</p> <pre><code>Day 1: Workflow runs \u2192 Creates PR #42 \u2192 Left open for review\nDay 2: Workflow runs \u2192 Sees open PR #42 \u2192 Skips project\nDay 3: PR #42 merged \u2192 Facts updated \u2192 Workflow runs \u2192 Allowed\n</code></pre>"},{"location":"workflow-filters/#complete-real-world-example","title":"Complete Real-World Example","text":"<p>This is the actual filter from the example-workflow workflow:</p> <pre><code>[filter]\ngithub_identifier_required = true\ngithub_workflow_status_exclude = [\"success\"]\nproject_facts = {\"programming_language\" = \"Python 3.9\"}\nproject_types = [\n    \"apis\",\n    \"backend-libraries\",\n    \"bots\",\n    \"clis\",\n    \"consumers\",\n    \"daemons\",\n    \"plugin\",\n    \"scheduled-jobs\"\n]\n</code></pre> <p>What this filter does:</p> <ol> <li>\u2705 Must have GitHub (<code>github_identifier_required = true</code>)</li> <li>Excludes projects without GitHub integration</li> <li> <p>Ensures PR creation will work</p> </li> <li> <p>\u2705 Exclude passing builds (<code>github_workflow_status_exclude = [\"success\"]</code>)</p> </li> <li>Only processes projects with failing or missing workflows</li> <li> <p>Avoids unnecessary work on healthy projects</p> </li> <li> <p>\u2705 Python 3.9 only (<code>project_facts = {\"programming_language\" = \"Python 3.9\"}</code>)</p> </li> <li>Targets exactly Python 3.9 projects</li> <li> <p>Excludes Python 3.10, 3.11, 3.12, etc.</p> </li> <li> <p>\u2705 Backend projects only (<code>project_types = [...]</code>)</p> </li> <li>Includes APIs, libraries, CLIs, consumers, etc.</li> <li>Excludes frontend projects that don't have setup.cfg</li> </ol> <p>Result: From 1000 total projects \u2192 ~50 projects that need fixing</p>"},{"location":"workflow-filters/#filter-evaluation-flow","title":"Filter Evaluation Flow","text":"<pre><code>All Projects (1000)\n    \u2193\ngithub_identifier_required = true\n    \u2193 (excludes 200 projects without GitHub)\n800 projects remain\n    \u2193\ngithub_workflow_status_exclude = [\"success\"]\n    \u2193 (excludes 600 projects with passing builds)\n200 projects remain\n    \u2193\nproject_facts = {\"programming_language\" = \"Python 3.9\"}\n    \u2193 (excludes 120 non-Python-3.9 projects)\n80 projects remain\n    \u2193\nproject_types = [\"apis\", \"consumers\", ...]\n    \u2193 (excludes 30 frontend projects)\n50 projects match all filters\n</code></pre> <p>These 50 projects then proceed to workflow condition evaluation.</p>"},{"location":"workflow-filters/#common-filter-patterns","title":"Common Filter Patterns","text":""},{"location":"workflow-filters/#target-specific-technology-stack","title":"Target Specific Technology Stack","text":"<pre><code>[filter]\nproject_facts = {\n    \"Programming Language\" = \"Python 3.12\",\n    \"Framework\" = \"FastAPI\",\n    \"Database\" = \"PostgreSQL\"\n}\n</code></pre>"},{"location":"workflow-filters/#python-projects-with-failing-builds","title":"Python Projects with Failing Builds","text":"<pre><code>[filter]\nproject_types = [\"api\", \"consumer\", \"daemon\"]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\ngithub_identifier_required = true\ngithub_workflow_status_exclude = [\"success\"]\n</code></pre>"},{"location":"workflow-filters/#specific-project-type-without-github","title":"Specific Project Type Without GitHub","text":"<pre><code>[filter]\nproject_types = [\"backend-libraries\"]\n# No github_identifier_required - includes non-GitHub projects\n</code></pre>"},{"location":"workflow-filters/#testing-filter-small-subset","title":"Testing Filter (Small Subset)","text":"<pre><code>[filter]\nproject_ids = [42, 108, 256]  # Test on 3 projects first\n</code></pre>"},{"location":"workflow-filters/#all-python-projects","title":"All Python Projects","text":"<pre><code>[filter]\n# Use facts to match any Python version\nproject_facts = {\"Programming Language\" = \"Python\"}  # Won't work - needs exact match\n\n# Better: Use multiple workflows or no filter + conditions\n</code></pre> <p>Note: Fact filtering requires exact matches. For partial matching, use workflow conditions with regex.  </p>"},{"location":"workflow-filters/#projects-needing-github-actions","title":"Projects Needing GitHub Actions","text":"<pre><code>[filter]\ngithub_identifier_required = true\n# Then use conditions to check for specific workflow files\n</code></pre>"},{"location":"workflow-filters/#filter-performance","title":"Filter Performance","text":"<p>Filters are the most efficient project selection mechanism:</p> <ul> <li>\u2705 No API calls - Uses cached Imbi data</li> <li>\u2705 No git operations - No cloning or remote checks</li> <li>\u2705 Fast evaluation - Simple equality checks</li> <li>\u2705 Early elimination - Reduces downstream processing</li> </ul> <p>Performance comparison for 1000 projects:</p> Method Projects Processed API Calls Git Clones No filters 1000 1000+ 1000 With filters 50 50+ 50 <p>Best practice: Use filters to get close to your target set, then use workflow conditions for fine-grained selection.</p>"},{"location":"workflow-filters/#filter-vs-condition-vs-cli-argument","title":"Filter vs Condition vs CLI Argument","text":""},{"location":"workflow-filters/#cli-arguments","title":"CLI Arguments","text":"<p>Scope: Initial project selection Speed: \u26a1\u26a1\u26a1 Fastest Use for: One-off targeting, testing</p> <pre><code>--project-id 123\n--project-type api\n--all-projects\n</code></pre>"},{"location":"workflow-filters/#filters","title":"Filters","text":"<p>Scope: Workflow-level pre-filtering Speed: \u26a1\u26a1 Very fast Use for: Broad targeting, technology stack selection</p> <pre><code>[filter]\nproject_types = [\"api\"]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\n</code></pre>"},{"location":"workflow-filters/#workflow-conditions","title":"Workflow Conditions","text":"<p>Scope: Repository state checks Speed: \u26a1 Fast (remote) or \ud83d\udc0c Slow (local) Use for: File existence, content checking</p> <pre><code>[[conditions]]\nremote_file_exists = \"package.json\"\n</code></pre>"},{"location":"workflow-filters/#action-conditions","title":"Action Conditions","text":"<p>Scope: Per-action execution control Speed: \u26a1 Fast (already cloned) Use for: Conditional behavior within workflow</p> <pre><code>[[actions.conditions]]\nfile_exists = \"setup.py\"\n</code></pre>"},{"location":"workflow-filters/#combining-filters-with-other-mechanisms","title":"Combining Filters with Other Mechanisms","text":""},{"location":"workflow-filters/#filter-workflow-conditions","title":"Filter + Workflow Conditions","text":"<pre><code># Filter: Broad technology targeting\n[filter]\nproject_types = [\"api\"]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\n\n# Conditions: Specific repository requirements\n[[conditions]]\nremote_file_exists = \"pyproject.toml\"\n\n[[conditions]]\nremote_file_contains = \"fastapi\"\nremote_file = \"pyproject.toml\"\n</code></pre> <p>Result: FastAPI projects using Python 3.12 with pyproject.toml</p>"},{"location":"workflow-filters/#filter-cli-arguments","title":"Filter + CLI Arguments","text":"<pre><code># CLI: Specific project type\nimbi-automations config.toml workflows/update-python --project-type api\n\n# Workflow filter: Further refinement\n[filter]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\ngithub_identifier_required = true\n</code></pre> <p>Result: Python 3.12 APIs with GitHub integration</p>"},{"location":"workflow-filters/#filter-action-conditions","title":"Filter + Action Conditions","text":"<pre><code># Filter: Python projects\n[filter]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\n\n[[actions]]\nname = \"update-setup-py\"\ntype = \"file\"\n\n# Action condition: Only if setup.py exists\n[[actions.conditions]]\nfile_exists = \"setup.py\"\n\n[[actions]]\nname = \"update-pyproject\"\ntype = \"file\"\n\n# Action condition: Only if pyproject.toml exists\n[[actions.conditions]]\nfile_exists = \"pyproject.toml\"\n</code></pre> <p>Result: Python 3.12 projects, with different actions for setup.py vs pyproject.toml</p>"},{"location":"workflow-filters/#see-also","title":"See Also","text":"<ul> <li>Workflow Conditions - File existence and content checking</li> <li>Workflow Configuration - Complete configuration reference</li> <li>Workflows Overview - High-level concepts and best practices</li> </ul>"},{"location":"workflows/","title":"Workflows","text":"<p>Workflows are the core automation units in Imbi Automations. Each workflow defines a sequence of actions to execute across your project repositories, with powerful filtering and conditional execution capabilities.</p>"},{"location":"workflows/#what-is-a-workflow","title":"What is a Workflow?","text":"<p>A workflow is a directory containing a workflow configuration file that defines:</p> <ul> <li>Actions: Operations to perform (file manipulation, AI transformations, shell commands, etc.)</li> <li>Conditions: Repository state checks to determine if workflow/actions should run</li> <li>Filters: Project targeting criteria to select which projects to process</li> <li>Configuration: Git and GitHub behavior settings</li> </ul>"},{"location":"workflows/#workflow-structure","title":"Workflow Structure","text":"<pre><code>workflows/workflow-name/\n\u251c\u2500\u2500 workflow.toml        # Required - workflow configuration\n\u251c\u2500\u2500 prompts/             # Optional - Claude prompt templates\n\u2502   \u251c\u2500\u2500 task.md.j2\n\u2502   \u2514\u2500\u2500 validator.md.j2\n\u251c\u2500\u2500 templates/           # Optional - Jinja2 templates\n\u2502   \u251c\u2500\u2500 config.yaml.j2\n\u2502   \u2514\u2500\u2500 README.md.j2\n\u2514\u2500\u2500 files/               # Optional - static resources\n    \u251c\u2500\u2500 .gitignore\n    \u2514\u2500\u2500 .pre-commit-config.yaml\n</code></pre>"},{"location":"workflows/#minimal-example","title":"Minimal Example","text":"<p>The simplest workflow requires only a name and actions:</p> <pre><code>name = \"update-gitignore\"\n\n[[actions]]\nname = \"copy-gitignore\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///.gitignore\"\ndestination = \"repository:///.gitignore\"\n</code></pre> <p>This workflow copies a <code>.gitignore</code> file from the workflow directory to each repository.</p>"},{"location":"workflows/#three-levels-of-project-selection","title":"Three Levels of Project Selection","text":"<p>In addition to the <code>--project-id</code>, <code>--project-type</code>, and <code>--all-projects</code> command-line arguments, Imbi Automations provides three complementary mechanisms to control which projects to process and which actions execute:</p>"},{"location":"workflows/#1-project-filters-pre-filter-before-processing","title":"1. Project Filters - Pre-filter before processing","text":"<p>Target specific project subsets using Imbi metadata (project IDs, types, facts, GitHub requirements).</p> <p>When: Before any workflow processing begins</p> <p>Effect: Projects that don't match are never processed</p> <p>Use for: Broad targeting (e.g., \"only Python APIs\")</p>"},{"location":"workflows/#2-workflow-conditions-skip-entire-workflow","title":"2. Workflow Conditions - Skip entire workflow","text":"<p>Check repository state (remote or local) to determine if workflow should run.</p> <p>When: Once per project, before any actions execute</p> <p>Effect: If conditions fail, entire workflow is skipped for that project</p> <p>Use for: Workflow applicability (e.g., \"only if Dockerfile exists\")</p>"},{"location":"workflows/#3-action-conditions-skip-individual-actions","title":"3. Action Conditions - Skip individual actions","text":"<p>Check repository state before each action to conditionally execute.</p> <p>When: Before each action executes</p> <p>Effect: If conditions fail, only that specific action is skipped</p> <p>Use for: Conditional behavior (e.g., \"update setup.py only if it exists\")</p>"},{"location":"workflows/#evaluation-flow","title":"Evaluation Flow","text":"<pre><code>1. Apply project filters    \u2192 1000 projects \u2192 50 matching\n   [filter] section\n\n2. Check workflow conditions \u2192 50 projects \u2192 30 applicable\n   [[conditions]]\n\n3. Clone repository          \u2192 Working with 30 repositories\n\n4. For each action:          \u2192 Execute only when conditions pass\n   Check action conditions\n   [[actions.conditions]]\n</code></pre>"},{"location":"workflows/#key-capabilities","title":"Key Capabilities","text":""},{"location":"workflows/#action-types","title":"Action Types","text":"<p>Workflows support multiple action types for different operations:</p> <ul> <li>File Actions: Copy, move, delete, write files with glob pattern support</li> <li>Shell Actions: Execute commands with template variable substitution</li> <li>Template Actions: Render Jinja2 templates with full project context</li> <li>Claude Actions: AI-powered code transformations using Claude Code SDK</li> <li>Git Actions: Extract files from commit history, clone repositories</li> <li>Docker Actions: Extract files from containers, build images</li> <li>GitHub/Imbi Actions: API operations on project management platforms</li> </ul> <p>See the Actions Reference for complete documentation.</p>"},{"location":"workflows/#action-stages","title":"Action Stages","text":"<p>Actions can be organized into execution stages:</p> <ul> <li>Primary (default): Execute before PR creation - standard workflow actions</li> <li>Followup: Execute after PR creation - for monitoring CI, responding to feedback</li> </ul> <pre><code>[[actions]]\nname = \"update-deps\"\ntype = \"claude\"\n# stage = \"primary\"  # Default, can be omitted\ntask_prompt = \"prompts/update.md.j2\"\n\n[[actions]]\nname = \"monitor-ci\"\ntype = \"claude\"\nstage = \"followup\"\ntask_prompt = \"prompts/monitor.md.j2\"\ncommittable = true\n</code></pre> <p>Followup actions receive PR context (<code>pull_request.number</code>, <code>pull_request.html_url</code>, <code>pr_branch</code>) in templates. See Action Stages for detailed documentation.</p>"},{"location":"workflows/#conditional-execution","title":"Conditional Execution","text":"<p>Remote Conditions (checked via API before cloning): <pre><code>[[conditions]]\nremote_file_exists = \"package.json\"\n\n[[conditions]]\nremote_file_contains = \"\\\"node\\\": \\\"18\\\"\"\nremote_file = \"package.json\"\n</code></pre></p> <p>Local Conditions (checked after cloning): <pre><code>[[conditions]]\nfile_exists = \"**/*.tf\"  # Glob pattern support\n\n[[conditions]]\nfile_contains = \"python.*3\\\\.12\"\nfile = \"pyproject.toml\"\n</code></pre></p> <p>Action-Level Conditions: <pre><code>[[actions]]\nname = \"update-setup-py\"\ntype = \"file\"\ncommand = \"write\"\n\n[[actions.conditions]]\nfile_exists = \"setup.py\"  # Only execute if setup.py exists\n</code></pre></p>"},{"location":"workflows/#project-filtering","title":"Project Filtering","text":"<p>Target specific project subsets efficiently:</p> <pre><code>[filter]\nproject_types = [\"api\", \"consumer\"]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\ngithub_identifier_required = true\ngithub_workflow_status_exclude = [\"success\"]  # Only failing/missing workflows\n</code></pre>"},{"location":"workflows/#ai-powered-transformations","title":"AI-Powered Transformations","text":"<p>Use Claude Code for complex multi-file transformations:</p> <pre><code>[[actions]]\nname = \"migrate-to-pydantic-v2\"\ntype = \"claude\"\nprompt = \"workflow:///prompts/pydantic-migration.md\"\nmax_cycles = 5\nai_commit = true  # AI-generated commit messages\n</code></pre>"},{"location":"workflows/#pull-request-automation","title":"Pull Request Automation","text":"<p>Automatically create PRs for workflow changes:</p> <pre><code>[github]\ncreate_pull_request = true\nreplace_branch = true  # Force-replace existing PR branch\n</code></pre>"},{"location":"workflows/#example-workflows","title":"Example Workflows","text":""},{"location":"workflows/#simple-file-copy","title":"Simple File Copy","text":"<pre><code>name = \"Deploy Standard .gitignore\"\n\n[[conditions]]\nremote_file_exists = \".git\"\n\n[[actions]]\nname = \"copy-gitignore\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///.gitignore\"\ndestination = \"repository:///.gitignore\"\n</code></pre>"},{"location":"workflows/#ai-powered-migration","title":"AI-Powered Migration","text":"<pre><code>name = \"Migrate to Pydantic V2\"\n\n[filter]\nproject_types = [\"api\"]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\n\n[[conditions]]\nremote_file_contains = \"pydantic\"\nremote_file = \"pyproject.toml\"\n\n[[actions]]\nname = \"migrate-pydantic\"\ntype = \"claude\"\nprompt = \"workflow:///prompts/pydantic-v2.md\"\nmax_cycles = 5\non_failure = \"restore-backup\"\nai_commit = true\n</code></pre>"},{"location":"workflows/#conditional-updates","title":"Conditional Updates","text":"<pre><code>name = \"Update Python Files\"\n\n[[actions]]\nname = \"update-setup-py\"\ntype = \"template\"\nsource_path = \"workflow:///setup.py.j2\"\ndestination_path = \"repository:///setup.py\"\n\n[[actions.conditions]]\nfile_exists = \"setup.py\"\n\n[[actions]]\nname = \"update-pyproject\"\ntype = \"template\"\nsource_path = \"workflow:///pyproject.toml.j2\"\ndestination_path = \"repository:///pyproject.toml\"\n\n[[actions.conditions]]\nfile_exists = \"pyproject.toml\"\n</code></pre>"},{"location":"workflows/#running-workflows","title":"Running Workflows","text":"<p>Execute workflows across all your projects:</p> <pre><code># Run on all projects\nimbi-automations config.toml workflows/workflow-name --all-projects\n\n# Run on specific project types\nimbi-automations config.toml workflows/workflow-name --project-type api\n\n# Run on specific project\nimbi-automations config.toml workflows/workflow-name --project-id 123\n\n# Resume from specific project (useful for large batches)\nimbi-automations config.toml workflows/workflow-name --all-projects \\\n  --start-from-project my-project-slug\n</code></pre> <p>See the CLI Reference for complete command-line options.</p>"},{"location":"workflows/#included-workflows","title":"Included Workflows","text":"<p>Imbi Automations includes 25+ pre-built workflows for common tasks:</p> <p>Infrastructure &amp; Tooling:</p> <ul> <li>Docker image updates and health checks</li> <li>Terraform CI/CD pipelines</li> <li>Frontend build and deployment</li> <li>Compose configuration fixes</li> </ul> <p>Code Quality:</p> <ul> <li>CI/CD pipeline enforcement</li> <li>GitHub Actions workflow fixes</li> <li>SonarQube quality gate fixes</li> </ul> <p>Project Maintenance:</p> <ul> <li>Standard .gitignore deployment</li> <li>GitHub team synchronization</li> <li>Environment synchronization</li> <li>Project validation</li> </ul> <p>See the <code>workflows/</code> directory in the repository for all available workflows.</p>"},{"location":"workflows/#best-practices","title":"Best Practices","text":""},{"location":"workflows/#use-remote-conditions-first","title":"Use Remote Conditions First","text":"<p>Remote conditions are faster and avoid unnecessary cloning:</p> <pre><code># \u2705 Good - check remotely before cloning\n[[conditions]]\nremote_file_exists = \"package.json\"\n\n# \u274c Slower - clones every repository\n[[conditions]]\nfile_exists = \"package.json\"\n</code></pre>"},{"location":"workflows/#filter-early-filter-often","title":"Filter Early, Filter Often","text":"<p>Use workflow-level filters to reduce processing scope:</p> <pre><code># \u2705 Good - filter at workflow level\n[filter]\nproject_types = [\"api\"]\nproject_facts = {\"Programming Language\" = \"Python 3.12\"}\n\n# \u274c Less efficient - evaluates conditions on all projects\n[[conditions]]\n# checking conditions on 1000 projects instead of 50\n</code></pre>"},{"location":"workflows/#design-idempotent-workflows","title":"Design Idempotent Workflows","text":"<p>Make workflows safely re-runnable:</p> <pre><code>[[actions.conditions]]\nfile_not_exists = \"config/app.yaml\"  # Only create if missing\n</code></pre>"},{"location":"workflows/#use-action-conditions-for-variation","title":"Use Action Conditions for Variation","text":"<p>Different projects need different actions:</p> <pre><code>[[actions]]\nname = \"update-setup-py\"\n[[actions.conditions]]\nfile_exists = \"setup.py\"\n\n[[actions]]\nname = \"update-pyproject\"\n[[actions.conditions]]\nfile_exists = \"pyproject.toml\"\n</code></pre>"},{"location":"workflows/#learn-more","title":"Learn More","text":"<ul> <li>Workflow Configuration - Detailed configuration reference with all fields and options</li> <li>Action Stages - Primary and followup stage execution for CI monitoring</li> <li>Actions Reference - Complete action types documentation</li> <li>Debugging Workflows - Troubleshooting and debugging techniques</li> <li>CLI Reference - Command-line options and usage</li> </ul>"},{"location":"actions/","title":"About Actions","text":"<p>Workflow actions are the core building blocks of automation in Imbi Automations. Each action type provides specific capabilities for interacting with repositories, external services, and project files.</p>"},{"location":"actions/#action-stages","title":"Action Stages","text":"<p>Actions can specify a <code>stage</code> field to control when they execute:</p> Stage When Use Case <code>primary</code> (default) Before PR creation Standard workflow actions <code>followup</code> After PR creation CI monitoring, feedback response <pre><code>[[actions]]\nname = \"update-code\"\ntype = \"claude\"\n# stage = \"primary\"  # Default\ntask_prompt = \"prompts/update.md.j2\"\n\n[[actions]]\nname = \"monitor-ci\"\ntype = \"claude\"\nstage = \"followup\"\ntask_prompt = \"prompts/monitor.md.j2\"\ncommittable = true\n</code></pre> <p>See Action Stages for complete stage documentation.</p>"},{"location":"actions/#action-types-overview","title":"Action Types Overview","text":"Action Type Purpose Use Cases Callable Direct API method calls GitHub operations, Imbi updates Claude AI-powered transformations Complex code changes, intelligent analysis Docker Container operations Extract files from images, build images File File manipulation Copy, move, delete, append, write files Git Version control operations Extract commits, branch management GitHub GitHub-specific operations Environment sync, workflow management Imbi Imbi project management Update project facts and metadata Shell Command execution Run tests, build processes, scripts Template Jinja2 file generation Generate configs, documentation"},{"location":"actions/#resourceurl-path-system","title":"ResourceUrl Path System","text":"<p>All file and resource paths in actions use the <code>ResourceUrl</code> type, which supports multiple schemes for flexible file addressing:</p>"},{"location":"actions/#path-schemes","title":"Path Schemes","text":""},{"location":"actions/#file-relative-to-working-directory","title":"<code>file:///</code> - Relative to Working Directory","text":"<p>Default scheme for simple paths. Resolves relative to the workflow's working directory:</p> <pre><code>[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"file:///config.yaml\"      # Or just \"config.yaml\"\ndestination = \"file:///backup/config.yaml\"\n</code></pre> <p>Equivalent simplified syntax: <pre><code>source = \"config.yaml\"\ndestination = \"backup/config.yaml\"\n</code></pre></p>"},{"location":"actions/#repository-repository-files","title":"<code>repository:///</code> - Repository Files","text":"<p>Paths within the cloned Git repository:</p> <pre><code>[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///.github/workflows/ci.yml\"\ndestination = \"repository:///.github/workflows/ci-backup.yml\"\n</code></pre> <p>The <code>repository:///</code> prefix maps to <code>{working_directory}/repository/</code> where the actual repository is cloned.</p>"},{"location":"actions/#workflow-workflow-resources","title":"<code>workflow:///</code> - Workflow Resources","text":"<p>Paths to files bundled with the workflow itself:</p> <pre><code>[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///.gitignore\"           # From workflow directory\ndestination = \"repository:///.gitignore\"     # To repository\n</code></pre> <p>The <code>workflow:///</code> prefix maps to <code>{working_directory}/workflow/</code> where workflow resources are staged.</p>"},{"location":"actions/#extracted-extracted-files","title":"<code>extracted:///</code> - Extracted Files","text":"<p>Files extracted from Docker containers or Git repositories via git/docker actions:</p> <pre><code># Extract from Docker container\n[[actions]]\nname = \"extract-from-docker\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"myapp:latest\"\nsource = \"/app/config/\"\ndestination = \"extracted:///docker-configs/\"\n\n# Extract file from Git history\n[[actions]]\nname = \"extract-from-git\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \"config.yaml\"\ndestination = \"extracted:///old-config.yaml\"\ncommit_keyword = \"breaking change\"\nsearch_strategy = \"before_last_match\"\n\n# Use extracted files\n[[actions]]\nname = \"copy-extracted\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"extracted:///docker-configs/app.yaml\"\ndestination = \"repository:///config/app.yaml\"\n</code></pre> <p>The <code>extracted:///</code> prefix maps to <code>{working_directory}/extracted/</code> where extracted files from Docker containers and Git history are stored.</p>"},{"location":"actions/#path-resolution-examples","title":"Path Resolution Examples","text":"<pre><code># Example 1: Copy workflow template to repository\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///templates/README.md\"\ndestination = \"repository:///README.md\"\n\n# Example 2: Extract Docker config and use it\n[[actions]]\nname = \"extract-config\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"python:3.12\"\nsource = \"/usr/local/lib/python3.12/\"\ndestination = \"extracted:///python-libs/\"\n\n[[actions]]\nname = \"analyze-libs\"\ntype = \"shell\"\ncommand = \"ls -lah {{ working_directory }}/extracted/python-libs\"\n\n# Example 3: Multiple file operations\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///old-config.yaml\"\ndestination = \"repository:///backup/config.yaml\"\n\n[[actions]]\ntype = \"file\"\ncommand = \"write\"\npath = \"repository:///config.yaml\"\ncontent = \"new_config: true\"\n</code></pre>"},{"location":"actions/#working-directory-structure","title":"Working Directory Structure","text":"<p>During workflow execution, the working directory contains:</p> <pre><code>{working_directory}/\n\u251c\u2500\u2500 repository/          # Cloned Git repository\n\u2502   \u251c\u2500\u2500 .git/\n\u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 workflow/            # Workflow resources (templates, files)\n\u2502   \u251c\u2500\u2500 templates/\n\u2502   \u251c\u2500\u2500 .gitignore\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 extracted/           # Files extracted from Docker\n\u2502   \u2514\u2500\u2500 configs/\n\u2514\u2500\u2500 other files...       # Working files (logs, temp files)\n</code></pre>"},{"location":"actions/#case-sensitivity","title":"Case Sensitivity","text":"<p>Important: File paths preserve case sensitivity. The three-slash format (<code>file:///</code>) ensures paths are treated correctly on both case-sensitive (Linux) and case-insensitive (macOS/Windows) filesystems.</p> <pre><code># Correct - case is preserved\nsource = \"README.md\"              # Becomes file:///README.md\nsource = \"repository:///LICENSE\"  # Exact case maintained\n\n# Incorrect legacy format (deprecated)\nsource = \"file://readme.md\"       # Would lowercase on some systems\n</code></pre>"},{"location":"actions/#common-action-patterns","title":"Common Action Patterns","text":""},{"location":"actions/#sequential-file-operations","title":"Sequential File Operations","text":"<pre><code>[[actions]]\nname = \"backup-config\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///config.yaml\"\ndestination = \"repository:///config.yaml.bak\"\n\n[[actions]]\nname = \"update-config\"\ntype = \"file\"\ncommand = \"write\"\npath = \"repository:///config.yaml\"\ncontent = \"\"\"\nversion: 2\nupdated: true\n\"\"\"\n</code></pre>"},{"location":"actions/#template-generation-pipeline","title":"Template Generation Pipeline","text":"<pre><code>[[actions]]\nname = \"render-templates\"\ntype = \"template\"\nsource_path = \"workflow:///templates/\"\ndestination_path = \"repository:///config/\"\n\n[[actions]]\nname = \"validate-configs\"\ntype = \"shell\"\ncommand = \"python -m yamllint {{ working_directory }}/repository/config/\"\n</code></pre>"},{"location":"actions/#docker-extract-and-transform","title":"Docker Extract and Transform","text":"<pre><code>[[actions]]\nname = \"extract-from-base\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"base:latest\"\nsource = \"/app/\"\ndestination = \"extracted:///base-app/\"\n\n[[actions]]\nname = \"merge-with-repo\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"extracted:///base-app/config.json\"\ndestination = \"repository:///config/base.json\"\n</code></pre>"},{"location":"actions/#action-execution-context","title":"Action Execution Context","text":"<p>All actions execute with access to these context variables (via Jinja2 templating where supported):</p> <ul> <li><code>workflow</code>: Current workflow configuration</li> <li><code>imbi_project</code>: Imbi project data (ID, name, type, facts, etc.)</li> <li><code>github_repository</code>: GitHub repository data (if applicable)</li> <li><code>working_directory</code>: Temporary execution directory path</li> <li><code>starting_commit</code>: Initial Git commit SHA (for tracking changes)</li> </ul> <p>Followup stage actions also receive:</p> <ul> <li><code>pull_request</code>: GitHubPullRequest model (number, html_url, state, head.sha, etc.)</li> <li><code>pr_branch</code>: Branch name for the PR (e.g., <code>imbi-automations/workflow-slug</code>)</li> </ul> <p>See Action Stages for followup stage documentation.</p> <p>See individual action type documentation for specific configuration options and examples.</p>"},{"location":"actions/callable/","title":"Callable Actions","text":"<p>\u2705 IMPLEMENTED: Callable actions are fully implemented and tested.</p> <p>Callable actions invoke Python callable objects (functions, methods, coroutines) dynamically with flexible arguments. This enables direct execution of Python code from workflows, including client methods, utility functions, and custom callables.</p>"},{"location":"actions/callable/#configuration","title":"Configuration","text":"<pre><code>[[actions]]\nname = \"action-name\"\ntype = \"callable\"\ncallable = \"module.path:function_or_method_name\"\nargs = [1, \"string\", true]      # Optional positional arguments\nkwargs = {key = \"value\"}         # Optional keyword arguments\nai_commit = true                 # Optional, default: true\n</code></pre>"},{"location":"actions/callable/#fields","title":"Fields","text":""},{"location":"actions/callable/#callable-required","title":"callable (required)","text":"<p>Python import string specifying the callable to invoke. Uses Pydantic's <code>ImportString</code> format.</p> <p>Type: <code>string</code> (ImportString format: <code>\"module.path:callable_name\"</code>)  </p> <p>Format: <code>\"package.module:function\"</code> or <code>\"package.module.submodule:ClassName.method\"</code> </p> <p>Examples: <pre><code># Function from module\ncallable = \"os.path:join\"\n\n# Method from class\ncallable = \"imbi_automations.clients.github:GitHub.create_issue\"\n\n# Async function\ncallable = \"asyncio:sleep\"\n\n# Custom module\ncallable = \"my_package.utils:process_data\"\n</code></pre></p> <p>Import Resolution: </p> <ul> <li>The string before <code>:</code> is the module path to import</li> <li>The string after <code>:</code> is the attribute name to retrieve from the module</li> <li>Supports nested attributes (e.g., <code>Class.method</code>)</li> <li>Automatically detects and awaits async callables (coroutines)</li> </ul>"},{"location":"actions/callable/#args-optional","title":"args (optional)","text":"<p>Positional arguments to pass to the callable. Arguments are passed in order.</p> <p>Type: <code>list[Any]</code> </p> <p>Default: <code>[]</code> </p> <p>Supports:</p> <ul> <li>Primitive types (int, float, bool, string)</li> <li>Lists and dictionaries</li> <li>Jinja2 template strings (automatically rendered)</li> <li>Mixed types</li> </ul> <p>Template Rendering: <pre><code>args = [\n    42,                              # Literal integer\n    \"{{ imbi_project.name }}\",       # Template string (rendered)\n    true,                            # Literal boolean\n    \"literal-string\"                 # Literal string (no templates)\n]\n</code></pre></p> <p>Important: Positional argument order is preserved. Template strings are rendered before execution.</p>"},{"location":"actions/callable/#kwargs-optional","title":"kwargs (optional)","text":"<p>Keyword arguments to pass to the callable.</p> <p>Type: <code>dict[string, Any]</code> </p> <p>Default: <code>{}</code> </p> <p>Supports:</p> <ul> <li>Same types as <code>args</code></li> <li>Jinja2 template rendering in string values</li> <li>Nested structures</li> </ul> <p>Template Rendering: <pre><code>[actions.kwargs]\nproject_name = \"{{ imbi_project.name }}\"      # Template (rendered)\nproject_id = 123                               # Literal integer\nenabled = true                                 # Literal boolean\nconfig = {nested = \"value\"}                    # Nested dict\n</code></pre></p>"},{"location":"actions/callable/#ai_commit-optional","title":"ai_commit (optional)","text":"<p>Whether to use AI-generated commit messages for repository changes made by this action.</p> <p>Type: <code>boolean</code> </p> <p>Default: <code>true</code> </p> <p>Note: Only relevant if the callable makes repository changes and <code>committable = true</code>.  </p>"},{"location":"actions/callable/#template-context","title":"Template Context","text":"<p>String arguments support Jinja2 templating with full workflow context:</p> Variable Description Example <code>workflow</code> Workflow configuration <code>{{ workflow.slug }}</code> <code>imbi_project</code> Imbi project data <code>{{ imbi_project.name }}</code> <code>github_repository</code> GitHub repository (if present) <code>{{ github_repository.name }}</code> <code>working_directory</code> Execution directory path <code>{{ working_directory }}</code> <code>starting_commit</code> Initial commit SHA <code>{{ starting_commit }}</code> <p>Template Detection: </p> <ul> <li>Only <code>string</code> values are checked for templates</li> <li>Templates must contain <code>{{</code>, <code>{%</code>, or <code>{#</code> syntax</li> <li>Non-string types (int, bool, list, dict) pass through unchanged</li> <li>Strings without template syntax are not rendered</li> </ul>"},{"location":"actions/callable/#asyncsync-detection","title":"Async/Sync Detection","text":"<p>The action automatically detects whether the callable is synchronous or asynchronous using <code>asyncio.iscoroutinefunction()</code> and executes accordingly to maintain async safety.</p> <p>Async callables: <pre><code>async def my_async_function(arg1: int, arg2: str) -&gt; None:\n    await asyncio.sleep(1)\n    # ... async work\n</code></pre></p> <pre><code>[[actions]]\nname = \"call-async\"\ntype = \"callable\"\ncallable = \"my_module:my_async_function\"\nargs = [42, \"hello\"]\n# Automatically awaited with: await action.callable(*args, **kwargs)\n</code></pre> <p>Sync callables: <pre><code>def my_sync_function(arg1: int, arg2: str) -&gt; None:\n    # ... sync work (may be blocking)\n    time.sleep(1)\n</code></pre></p> <pre><code>[[actions]]\nname = \"call-sync\"\ntype = \"callable\"\ncallable = \"my_module:my_sync_function\"\nargs = [42, \"hello\"]\n# Executed in thread pool: await asyncio.to_thread(callable, *args, **kwargs)\n</code></pre> <p>Detection and Execution: </p> <ul> <li>Detection Method: Uses <code>asyncio.iscoroutinefunction()</code> to detect async callables</li> <li>Async Execution: Coroutines are directly awaited: <code>await callable(*args, **kwargs)</code></li> <li>Sync Execution: Regular functions run in thread pool via <code>asyncio.to_thread()</code> to prevent blocking the event loop</li> <li>Thread Pool Benefit: Sync callables can perform blocking I/O without freezing async workflows</li> </ul> <p>Recent Fix (commit dc48d25):</p> <ul> <li>Sync callables now properly use <code>asyncio.to_thread()</code> instead of direct execution</li> <li>Prevents blocking the event loop when sync callables perform blocking operations</li> <li>Maintains async safety across all callable types</li> </ul>"},{"location":"actions/callable/#examples","title":"Examples","text":""},{"location":"actions/callable/#call-standard-library-function","title":"Call Standard Library Function","text":"<pre><code>[[actions]]\nname = \"create-directory\"\ntype = \"callable\"\ncallable = \"os:makedirs\"\nargs = [\"{{ working_directory }}/output\"]\nkwargs = {exist_ok = true}\ncommittable = false\n</code></pre>"},{"location":"actions/callable/#call-github-client-method","title":"Call GitHub Client Method","text":"<pre><code>[[actions]]\nname = \"create-github-label\"\ntype = \"callable\"\ncallable = \"imbi_automations.clients.github:GitHub.create_label\"\nkwargs = {\n    name = \"automated\",\n    color = \"00ff00\",\n    description = \"Created by automation\"\n}\n</code></pre>"},{"location":"actions/callable/#call-utility-function-with-templates","title":"Call Utility Function with Templates","text":"<pre><code>[[actions]]\nname = \"process-project-data\"\ntype = \"callable\"\ncallable = \"my_utils:process_data\"\nargs = [\n    \"{{ imbi_project.slug }}\",\n    \"{{ imbi_project.project_type }}\",\n    \"{{ imbi_project.namespace }}\"\n]\nkwargs = {\n    output_dir = \"{{ working_directory }}/processed\",\n    verbose = true\n}\n</code></pre>"},{"location":"actions/callable/#call-method-with-mixed-arguments","title":"Call Method with Mixed Arguments","text":"<pre><code>[[actions]]\nname = \"update-project-fact\"\ntype = \"callable\"\ncallable = \"imbi_automations.clients.imbi:Imbi.set_project_fact\"\nargs = [\n    123,                             # project_id (literal)\n    \"{{ workflow.slug }}\",           # fact_name (template)\n    \"completed\"                      # fact_value (literal)\n]\n</code></pre>"},{"location":"actions/callable/#call-custom-function","title":"Call Custom Function","text":"<pre><code>[[actions]]\nname = \"validate-config\"\ntype = \"callable\"\ncallable = \"validators.config:validate_yaml\"\nargs = [\"{{ working_directory }}/repository/config.yaml\"]\nkwargs = {\n    schema = \"config-schema.json\",\n    strict = true\n}\nignore_errors = false\n</code></pre>"},{"location":"actions/callable/#async-function-call","title":"Async Function Call","text":"<pre><code>[[actions]]\nname = \"async-api-call\"\ntype = \"callable\"\ncallable = \"my_api.client:fetch_data\"\nargs = [\"https://api.example.com/data\"]\nkwargs = {\n    timeout = 30,\n    retry = 3\n}\n# Automatically awaited due to async detection\n</code></pre>"},{"location":"actions/callable/#advanced-usage","title":"Advanced Usage","text":""},{"location":"actions/callable/#complex-template-expressions","title":"Complex Template Expressions","text":"<pre><code>[[actions]]\nname = \"conditional-processing\"\ntype = \"callable\"\ncallable = \"processors:handle_project\"\nargs = [\n    \"{{ imbi_project.namespace }}/{{ imbi_project.name }}\",\n    \"{{ imbi_project.id | int }}\",\n    \"{% if imbi_project.id &gt; 100 %}large{% else %}small{% endif %}\"\n]\n</code></pre>"},{"location":"actions/callable/#non-string-template-values","title":"Non-String Template Values","text":"<pre><code>[[actions]]\nname = \"structured-data\"\ntype = \"callable\"\ncallable = \"handlers:process_metadata\"\nkwargs = {\n    project_name = \"{{ imbi_project.name }}\",  # Rendered template (string)\n    project_id = 123,                           # Literal integer (not rendered)\n    enabled = true,                             # Literal boolean (not rendered)\n    tags = [\"api\", \"production\"],               # Literal list (not rendered)\n    metadata = {\n        env = \"prod\",                           # Nested dict (not rendered)\n        region = \"us-east-1\"\n    }\n}\n</code></pre>"},{"location":"actions/callable/#error-handling-with-ignore_errors","title":"Error Handling with ignore_errors","text":"<pre><code>[[actions]]\nname = \"optional-operation\"\ntype = \"callable\"\ncallable = \"optional_tasks:try_operation\"\nargs = [\"{{ imbi_project.slug }}\"]\nignore_errors = true  # Continue workflow even if callable fails\n</code></pre>"},{"location":"actions/callable/#conditional-execution","title":"Conditional Execution","text":"<pre><code>[[actions]]\nname = \"python-only-task\"\ntype = \"callable\"\ncallable = \"python_utils:analyze_dependencies\"\nargs = [\"{{ working_directory }}/repository\"]\n\n# Only run for Python projects\n[[actions.conditions]]\nfile_exists = \"requirements.txt\"\n</code></pre>"},{"location":"actions/callable/#return-values","title":"Return Values","text":"<p>Important: Callable actions execute for side effects only. Return values are not captured or made available to subsequent actions.</p> <p>If you need to capture output: 1. Have the callable write to a file in the working directory 2. Use a subsequent file action to read the output 3. Use the <code>data</code> field to pass information between actions (if needed)</p> <p>Example: <pre><code>[[actions]]\nname = \"generate-report\"\ntype = \"callable\"\ncallable = \"reporters:generate_report\"\nkwargs = {\n    project = \"{{ imbi_project.slug }}\",\n    output_file = \"{{ working_directory }}/report.json\"\n}\n\n[[actions]]\nname = \"read-report\"\ntype = \"shell\"\ncommand = \"cat {{ working_directory }}/report.json\"\n</code></pre></p>"},{"location":"actions/callable/#error-handling","title":"Error Handling","text":""},{"location":"actions/callable/#exception-handling","title":"Exception Handling","text":"<p>All exceptions raised by callables are caught and wrapped in <code>RuntimeError</code>:</p> <pre><code># In callable\ndef my_function():\n    raise ValueError(\"Something went wrong\")\n\n# In workflow logs\n# RuntimeError: Something went wrong\n#   Caused by: ValueError: Something went wrong\n</code></pre> <p>The original exception is preserved via <code>__cause__</code> for debugging.</p>"},{"location":"actions/callable/#logging","title":"Logging","text":"<p>Debug logging: <pre><code>DEBUG: Executing my_module:my_function([1, 2], {'key': 'value'})\n</code></pre></p> <p>Exception logging: <pre><code>ERROR: Error invoking callable: Something went wrong\n&lt;full exception traceback&gt;\n</code></pre></p>"},{"location":"actions/callable/#ignore-errors","title":"Ignore Errors","text":"<pre><code>[[actions]]\nname = \"best-effort-task\"\ntype = \"callable\"\ncallable = \"optional:task\"\nignore_errors = true  # Continue workflow even if callable raises exception\n</code></pre>"},{"location":"actions/callable/#integration-with-other-actions","title":"Integration with Other Actions","text":""},{"location":"actions/callable/#sequential-callable-chain","title":"Sequential Callable Chain","text":"<pre><code>[[actions]]\nname = \"fetch-data\"\ntype = \"callable\"\ncallable = \"api.client:fetch_project_data\"\nargs = [\"{{ imbi_project.id }}\"]\n\n[[actions]]\nname = \"process-data\"\ntype = \"callable\"\ncallable = \"processors:transform_data\"\nargs = [\"{{ working_directory }}/data.json\"]\n\n[[actions]]\nname = \"upload-results\"\ntype = \"callable\"\ncallable = \"api.client:upload_results\"\nargs = [\"{{ working_directory }}/results.json\"]\n</code></pre>"},{"location":"actions/callable/#callable-shell-verification","title":"Callable + Shell (Verification)","text":"<pre><code>[[actions]]\nname = \"run-python-script\"\ntype = \"callable\"\ncallable = \"scripts.migration:run_migration\"\nkwargs = {db_url = \"{{ config.database_url }}\"}\n\n[[actions]]\nname = \"verify-migration\"\ntype = \"shell\"\ncommand = \"python scripts/verify.py\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/callable/#callable-file-data-processing","title":"Callable + File (Data Processing)","text":"<pre><code>[[actions]]\nname = \"generate-config\"\ntype = \"callable\"\ncallable = \"config_gen:create_config\"\nkwargs = {\n    project = \"{{ imbi_project.slug }}\",\n    output = \"{{ working_directory }}/config.yaml\"\n}\n\n[[actions]]\nname = \"copy-to-repo\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"{{ working_directory }}/config.yaml\"\ndestination = \"repository:///config/generated.yaml\"\n</code></pre>"},{"location":"actions/callable/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Import Time: First call imports the module (cached by Python thereafter)</li> <li>Execution Time: Depends on callable implementation</li> <li>Async Overhead: Minimal for properly async callables (directly awaited)</li> <li>Sync Thread Pool Overhead: Minor context switch cost for sync callables via <code>asyncio.to_thread()</code></li> <li>Template Rendering: Only performed for string arguments with template syntax (detected via regex)</li> <li>ResourceUrl Resolution: Path resolution performed for each ResourceUrl argument (cached by <code>pathlib.Path</code>)</li> </ul>"},{"location":"actions/callable/#security-considerations","title":"Security Considerations","text":"<ul> <li>Code Execution: Callables execute with full Python interpreter access</li> <li>Import Safety: Only import from trusted modules</li> <li>Argument Validation: Callables should validate input arguments</li> <li>Error Information: Exception messages may contain sensitive data</li> </ul>"},{"location":"actions/callable/#best-practices","title":"Best Practices","text":""},{"location":"actions/callable/#do","title":"\u2705 Do","text":"<ul> <li>Use callable actions for Python-native operations</li> <li>Validate arguments in your callable implementations</li> <li>Use templates for dynamic values</li> <li>Document expected callable signatures</li> <li>Handle exceptions gracefully in callables</li> <li>Write to files for persistent output</li> </ul>"},{"location":"actions/callable/#dont","title":"\u274c Don't","text":"<ul> <li>Don't rely on return values (they're not captured)</li> <li>Don't use for operations better suited to specialized actions (file, git, github)</li> <li>Don't pass sensitive data in literal arguments (use environment variables or config)</li> <li>Don't use blocking sync operations in async callables</li> </ul>"},{"location":"actions/callable/#implementation-details","title":"Implementation Details","text":"<ul> <li>Module: <code>src/imbi_automations/actions/callablea.py</code> (656 lines of implementation + tests)</li> <li>Model: <code>src/imbi_automations/models/workflow.py:WorkflowCallableAction</code></li> <li>Tests: <code>tests/actions/test_callable.py</code> (30 comprehensive test cases, full coverage)</li> <li>Import Format: Uses Pydantic's <code>ImportString</code> validator for safe dynamic imports</li> <li>Async Detection: Uses <code>asyncio.iscoroutinefunction()</code> to detect coroutines</li> <li>Sync Execution: Uses <code>asyncio.to_thread(callable, *args, **kwargs)</code> for thread pool execution</li> <li>Template Rendering: Uses <code>prompts.render()</code> with Jinja2, only for strings with <code>{{</code>, <code>{%</code>, or <code>{#</code></li> <li>Template Detection: Uses <code>prompts.has_template_syntax()</code> regex check</li> <li>ResourceUrl Resolution: Uses <code>utils.resolve_path()</code> for path scheme handling</li> <li>Error Wrapping: All exceptions wrapped in <code>RuntimeError</code> with original as <code>__cause__</code> for exception chaining</li> </ul>"},{"location":"actions/callable/#migration-from-shell-actions","title":"Migration from Shell Actions","text":"<p>If you were using shell actions to run Python code, consider migrating to callable actions:</p> <p>Before (shell action): <pre><code>[[actions]]\nname = \"run-python\"\ntype = \"shell\"\ncommand = \"python -c 'from mymodule import func; func(\\\"arg1\\\", \\\"arg2\\\")'\"\n</code></pre></p> <p>After (callable action): <pre><code>[[actions]]\nname = \"run-python\"\ntype = \"callable\"\ncallable = \"mymodule:func\"\nargs = [\"arg1\", \"arg2\"]\n</code></pre></p> <p>Benefits:</p> <ul> <li>Type safety and validation</li> <li>Better error messages</li> <li>No shell escaping issues</li> <li>Template support for arguments</li> <li>Async/await support</li> <li>Cleaner syntax</li> </ul>"},{"location":"actions/claude/","title":"Claude Actions","text":"<p>Claude actions leverage the Claude Agent SDK for AI-powered code transformations, enabling complex multi-file analysis and intelligent code modifications that would be difficult or error-prone with traditional approaches.</p>"},{"location":"actions/claude/#configuration","title":"Configuration","text":"<pre><code>[[actions]]\nname = \"action-name\"\ntype = \"claude\"\nplanning_prompt = \"prompts/planning.md\"         # Optional - enables planning phase\ntask_prompt = \"prompts/task.md\"                 # Required (formerly 'prompt')\nvalidation_prompt = \"prompts/validate.md\"       # Optional\nmax_cycles = 3                                  # Optional, default: 3\non_failure = \"cleanup-action\"                   # Optional\nai_commit = true                                # Optional, default: true\n</code></pre>"},{"location":"actions/claude/#fields","title":"Fields","text":""},{"location":"actions/claude/#planning_prompt-optional","title":"planning_prompt (optional)","text":"<p>Path to Jinja2 template file containing the planning prompt for the planning agent.</p> <p>Type: <code>string</code> (path relative to workflow directory)  </p> <p>Format: Jinja2 template (<code>.j2</code> extension) or plain markdown  </p> <p>Location: Relative to workflow directory (e.g., <code>prompts/planning.md</code>)  </p> <p>When Provided: </p> <ul> <li>Enables three-phase execution: Planning \u2192 Task \u2192 Validation</li> <li>Planning agent analyzes codebase before task agent makes changes</li> <li>Returns structured plan that gets injected into task prompt</li> <li>Plan regenerated fresh at start of each cycle</li> </ul> <p>Agent Tools: Read, Glob, Grep, Bash (read-only operations)  </p> <p>Response Format: <code>mcp__agent_tools__submit_planning_response(plan=[...], analysis=\"...\")</code> </p>"},{"location":"actions/claude/#task_prompt-required","title":"task_prompt (required)","text":"<p>Path to Jinja2 template file containing the task prompt for Claude (formerly named <code>prompt</code>).</p> <p>Type: <code>string</code> (path relative to workflow directory)  </p> <p>Format: Jinja2 template (<code>.j2</code> extension) or plain markdown  </p> <p>Location: Relative to workflow directory (e.g., <code>prompts/update-python.md</code>)  </p> <p>Working Directory: Claude SDK runs in <code>working_directory/repository/</code> subdirectory  </p> <p>Agent Tools: Read, Write, Edit, Bash (write operations allowed)  </p> <p>Response Format: <code>mcp__agent_tools__submit_task_response(message=\"...\")</code> </p>"},{"location":"actions/claude/#validation_prompt-optional","title":"validation_prompt (optional)","text":"<p>Path to validation prompt template. If provided, Claude will run a validation cycle after the task cycle.</p> <p>Type: <code>string</code> (path relative to workflow directory)  </p> <p>Format: Jinja2 template (<code>.j2</code> extension) or plain markdown  </p> <p>Agent Tools: Read, Bash (read-only verification)  </p> <p>Response Format: <code>mcp__agent_tools__submit_validation_response(validated=bool, errors=[])</code> </p> <p>When Provided: </p> <ul> <li>Validation agent checks task agent's work after each cycle</li> <li>Returns success (<code>validated=True</code>) or failure (<code>validated=False</code>) with error list</li> <li>Validation failures trigger retry with errors injected into next cycle's prompt</li> <li>Validation success completes the action</li> </ul>"},{"location":"actions/claude/#max_cycles-optional","title":"max_cycles (optional)","text":"<p>Maximum number of retry cycles if transformation fails validation.</p> <p>Type: <code>integer</code> </p> <p>Default: <code>3</code> </p> <p>Behavior: </p> <ul> <li>Each cycle runs: Planning (if enabled) \u2192 Task \u2192 Validation (if enabled)</li> <li>Logs warning at 60% of max cycles (e.g., \"Cycle 3 of 5, approaching max_cycles limit\")</li> <li>If all cycles exhausted, triggers <code>on_failure</code> action (if configured)</li> <li>Error context from validation failures passed to subsequent cycles</li> </ul>"},{"location":"actions/claude/#on_failure-optional","title":"on_failure (optional)","text":"<p>Action name to restart from if this action fails after all retry cycles.</p> <p>Type: <code>string</code> (action name)  </p>"},{"location":"actions/claude/#ai_commit-optional","title":"ai_commit (optional)","text":"<p>Whether to use AI-generated commit messages for changes made by this action.</p> <p>Type: <code>boolean</code> </p> <p>Default: <code>true</code> </p>"},{"location":"actions/claude/#planning-agent-feature","title":"Planning Agent Feature","text":"<p>The planning agent is an optional pre-execution analysis phase that explores the codebase before the task agent makes changes. This provides better context, structured execution, and improved success rates for complex transformations.</p>"},{"location":"actions/claude/#when-to-use-planning","title":"When to Use Planning","text":"<p>Use planning when: </p> <ul> <li>Transformation requires analysis of multiple files</li> <li>Dependencies or patterns need to be identified first</li> <li>Task complexity benefits from structured approach</li> <li>You want AI to explore before modifying</li> </ul> <p>Skip planning when: </p> <ul> <li>Simple, single-file modifications</li> <li>Task is straightforward and well-defined</li> <li>Speed is more important than thorough analysis</li> </ul>"},{"location":"actions/claude/#planning-workflow","title":"Planning Workflow","text":"<p>Per-Cycle Execution: </p> <ol> <li>Planning Phase (if <code>planning_prompt</code> configured):</li> <li>Planning agent uses read-only tools (Read, Glob, Grep, Bash)</li> <li>Analyzes codebase structure, dependencies, patterns</li> <li>Creates structured plan with specific, actionable task strings</li> <li>Returns <code>{plan: [...], analysis: \"...\"}</code></li> <li> <p>Plan cleared and regenerated at start of each cycle</p> </li> <li> <p>Task Phase:</p> </li> <li>Task agent receives plan injected into prompt via <code>with-plan.md.j2</code> template</li> <li>Follows numbered plan with full context from analysis</li> <li>Uses write tools (Read, Write, Edit, Bash)</li> <li>Works in <code>working_directory/repository/</code> directory</li> <li> <p>Can access <code>../workflow/</code> and <code>../extracted/</code> directories</p> </li> <li> <p>Validation Phase (if <code>validation_prompt</code> configured):</p> </li> <li>Validation agent verifies task agent's work</li> <li>Returns <code>{validated: bool, errors: [...]}</code></li> <li>Errors injected into next cycle if validation fails</li> </ol>"},{"location":"actions/claude/#planning-error-handling","title":"Planning Error Handling","text":"<p>When planning fails: Cycle aborts immediately (no task execution)  </p> <p>When validation fails: </p> <ul> <li>Planning agent receives <code>planning-with-errors.md.j2</code> template</li> <li>Explicitly instructed to create NEW PLAN (not fix errors directly)</li> <li>Re-analyzes with context of what failed previously</li> </ul> <p>Critical Fix (commit 561909f):</p> <ul> <li>Planning agent was incorrectly trying to fix errors itself</li> <li>Now properly re-plans based on validation failures</li> <li>Creates new strategy each cycle</li> </ul>"},{"location":"actions/claude/#example-with-planning","title":"Example with Planning","text":"<pre><code>[[actions]]\nname = \"migrate-to-pydantic-v2\"\ntype = \"claude\"\nplanning_prompt = \"prompts/planning.md.j2\"\ntask_prompt = \"prompts/task.md.j2\"\nvalidation_prompt = \"prompts/validate.md.j2\"\nmax_cycles = 5\n</code></pre> <p>Planning Prompt (<code>prompts/planning.md.j2</code>): <pre><code># Analyze Pydantic Usage\n\nAnalyze this codebase to identify all Pydantic v1 usage.\n\n## Analysis Tasks\n\n1. Find all files importing from `pydantic`\n2. Identify Pydantic models (classes inheriting BaseModel)\n3. Locate validators using `@validator`\n4. Find `.dict()` and `.json()` method calls\n5. Identify Config classes that need migration\n\n## Output\n\nReturn a structured plan with:\n- Specific files to update\n- Order of operations (dependencies first)\n- Potential breaking changes to watch for\n\nBe thorough in your analysis. Check recursively in all Python files.\n</code></pre></p> <p>Task Prompt (<code>prompts/task.md.j2</code>): <pre><code># Migrate to Pydantic V2\n\nFollow the plan provided to migrate this codebase from Pydantic v1 to v2.\n\nExecute each task in order, making the necessary changes.\n\nEnsure all imports, validators, and method calls are updated.\n</code></pre></p> <p>Validation Prompt (<code>prompts/validate.md.j2</code>): <pre><code># Validate Pydantic V2 Migration\n\nVerify the migration was successful:\n\n1. Check all imports use Pydantic v2 syntax\n2. Verify Config classes converted to model_config\n3. Confirm validators use field_validator\n4. Ensure .dict()/.json() replaced with .model_dump()/.model_dump_json()\n5. Run tests if they exist\n\nReturn validated=true if all checks pass, otherwise list specific errors.\n</code></pre></p>"},{"location":"actions/claude/#prompt-context","title":"Prompt Context","text":"<p>Prompts have access to all workflow context variables:</p> Variable Description <code>workflow</code> Workflow configuration <code>imbi_project</code> Imbi project data <code>github_repository</code> GitHub repository (if applicable) <code>working_directory</code> Execution directory path (task agent runs in <code>repository/</code> subdirectory) <code>starting_commit</code> Initial commit SHA <code>commit_author</code> Git commit author string (e.g., \"Name \") <code>commit_author_name</code> Git author name (from <code>git.user_name</code>) <code>commit_author_address</code> Git author email (from <code>git.user_email</code>) <code>workflow_name</code> Current workflow name"},{"location":"actions/claude/#examples","title":"Examples","text":""},{"location":"actions/claude/#basic-code-transformation-without-planning","title":"Basic Code Transformation (Without Planning)","text":"<p>Workflow config: <pre><code>[[actions]]\nname = \"update-python-version\"\ntype = \"claude\"\ntask_prompt = \"prompts/update-python.md\"\n</code></pre></p> <p>Prompt (<code>prompts/update-python.md</code>): <pre><code># Update Python Version to 3.12\n\nUpdate all Python version references in this repository to Python 3.12.\n\n## Files to Update\n\n1. `pyproject.toml` - Update `requires-python` field\n2. `.github/workflows/*.yml` - Update GitHub Actions Python version\n3. `Dockerfile` - Update base image to python:3.12\n4. `README.md` - Update installation instructions if they mention Python version\n\n## Requirements\n\n- Maintain backwards compatibility where possible\n- Update all version strings consistently\n- Preserve existing configuration structure\n- Do not modify other unrelated settings\n\n## Project Context\n\n- **Project**: {{ imbi_project.name }}\n- **Type**: {{ imbi_project.project_type }}\n- **Current Python**: {{ imbi_project.facts.get('Programming Language', 'unknown') }}\n\n## Success Criteria\n\nCreate a commit with all Python version references updated to 3.12.\n\n## Failure Indication\n\nIf you cannot complete this task, return failure with details about what prevented completion.\n</code></pre></p>"},{"location":"actions/claude/#multi-cycle-transformation-with-retry","title":"Multi-Cycle Transformation with Retry","text":"<p>Workflow config: <pre><code>[[actions]]\nname = \"refactor-codebase\"\ntype = \"claude\"\ntask_prompt = \"prompts/refactor.md\"\nmax_cycles = 5\non_failure = \"create-issue\"  # Create GitHub issue if fails\n</code></pre></p>"},{"location":"actions/claude/#with-validator-no-planning","title":"With Validator (No Planning)","text":"<p>Workflow config: <pre><code>[[actions]]\nname = \"update-dependencies\"\ntype = \"claude\"\ntask_prompt = \"prompts/update-deps.md\"\nvalidation_prompt = \"prompts/validate-deps.md\"\n</code></pre></p> <p>Validator prompt: <pre><code># Validate Dependency Updates\n\nVerify that the dependency updates were successful:\n\n1. Check that `requirements.txt` or `pyproject.toml` has been updated\n2. Verify no breaking changes were introduced\n3. Confirm all imports still resolve correctly\n4. Check that version constraints are reasonable\n\nReturn success if validation passes, failure otherwise with specific errors.\n</code></pre></p>"},{"location":"actions/claude/#complex-transformation-without-planning","title":"Complex Transformation (Without Planning)","text":"<p>Workflow config: <pre><code>[[actions]]\nname = \"migrate-to-pydantic-v2\"\ntype = \"claude\"\ntask_prompt = \"prompts/pydantic-migration.md\"\nmax_cycles = 10\n</code></pre></p> <p>Task Prompt: <pre><code># Migrate to Pydantic V2\n\nMigrate this codebase from Pydantic v1 to Pydantic v2.\n\n## Migration Steps\n\n1. **Update imports**: Change `pydantic` imports to v2 syntax\n2. **Config classes**: Convert `Config` class to `model_config` dict\n3. **Validators**: Update `@validator` to `@field_validator`\n4. **Field definitions**: Update `Field(...)` syntax changes\n5. **JSON methods**: Replace `.dict()` with `.model_dump()`, `.json()` with `.model_dump_json()`\n\n## Files to Process\n\nScan the repository for Python files containing:\n- `from pydantic import`\n- `class.*\\\\(.*BaseModel\\\\)`\n- `@validator`\n- `.dict()` or `.json()` calls on Pydantic models\n\n## Testing\n\nAfter making changes:\n1. Run tests if they exist: `pytest tests/`\n2. Check for import errors\n3. Verify all models still validate correctly\n\n## Commit Message\n\n````\nMigrate from Pydantic v1 to v2\n\n- Update imports to v2 syntax\n- Convert Config classes to model_config\n- Update validators to field_validator\n- Replace .dict()/.json() with .model_dump()/.model_dump_json()\n\nProject: {{ imbi_project.name }}\n````\n\n## Failure Conditions\n\nReturn failure if:\n- Unable to identify Pydantic usage patterns\n- Migration would break existing functionality\n- Tests fail after migration\n- Manual intervention required\n\nInclude specific error details and affected files in the failure response.\n</code></pre></p>"},{"location":"actions/claude/#prompt-best-practices","title":"Prompt Best Practices","text":""},{"location":"actions/claude/#clear-objectives","title":"Clear Objectives","text":"<pre><code># Update Docker Base Image\n\n**Goal**: Update the Dockerfile to use python:3.12-slim as the base image.\n\n**Files**: `Dockerfile`, `docker-compose.yml`\n\n**Requirements**:\n- Change base image in all Dockerfiles\n- Maintain multi-stage build structure if present\n- Update docker-compose.yml references\n- Keep existing COPY, RUN, CMD instructions\n</code></pre>"},{"location":"actions/claude/#specific-instructions","title":"Specific Instructions","text":"<pre><code>## Step-by-Step Process\n\n1. Locate all Dockerfile* files in the repository\n2. For each Dockerfile:\n   a. Find the `FROM` instruction\n   b. Replace with `FROM python:3.12-slim`\n   c. Keep any `AS builder` or stage names\n3. Update docker-compose.yml if it hardcodes Python version\n4. Commit changes with message: \"Update Python base image to 3.12\"\n</code></pre>"},{"location":"actions/claude/#successfailure-criteria","title":"Success/Failure Criteria","text":"<pre><code>## Success Criteria\n\nYou must:\n\u2713 Update all Dockerfiles  \n\u2713 Maintain working configuration  \n\u2713 Create a git commit  \n\u2713 Include descriptive commit message  \n\n## Failure Indication\n\nReturn failure if:\n- No Dockerfile found in repository\n- Unable to parse existing Dockerfile syntax\n- Changes would break the build process\n- Multiple conflicting Dockerfile versions exist\n\nInclude the specific error and list of files examined in the failure response.\n</code></pre>"},{"location":"actions/claude/#project-context-usage","title":"Project Context Usage","text":"<pre><code>## Project-Specific Considerations\n\n- **Project**: {{ imbi_project.name }}\n- **Type**: {{ imbi_project.project_type }}\n- **Namespace**: {{ imbi_project.namespace }}\n\n{% if imbi_project.project_type == 'api' %}\nThis is an API project - ensure uvicorn/fastapi configurations are preserved.\n{% elif imbi_project.project_type == 'consumer' %}\nThis is a consumer - ensure message handling configurations are intact.\n{% endif %}\n\n{% if imbi_project.facts %}\n## Known Facts\n{% for key, value in imbi_project.facts.items() %}\n- **{{ key }}**: {{ value }}\n{% endfor %}\n{% endif %}\n</code></pre>"},{"location":"actions/claude/#failure-handling","title":"Failure Handling","text":""},{"location":"actions/claude/#failure-files","title":"Failure Files","text":"<p>Claude actions detect failure through specific files created in the working directory:</p> File Name Meaning <code>ACTION_FAILED</code> Generic action failure <code>{ACTION_NAME}_FAILED</code> Specific action failure Custom names Custom failure indicators <p>Prompt instructions for failure: <pre><code>## Failure Indication\n\nIf you cannot complete this task, return failure with:\n\n1. **Reason**: Why the task failed\n2. **Files Examined**: List of files you checked\n3. **Errors Encountered**: Specific error messages\n4. **Manual Steps**: What a human would need to do\n5. **Context**: Any relevant information for debugging\n\nExample failure response:\n````\nUnable to parse pyproject.toml due to syntax error\n\nFiles examined: pyproject.toml, requirements.txt\nError: toml.decoder.TomlDecodeError at line 15\nManual steps: Fix toml syntax error in pyproject.toml line 15\n````\n</code></pre></p>"},{"location":"actions/claude/#retry-mechanism","title":"Retry Mechanism","text":"<pre><code>[[actions]]\nname = \"fragile-transformation\"\ntype = \"claude\"\nprompt = \"prompts/transform.md\"\nmax_cycles = 5        # Try up to 5 times\non_failure = \"cleanup\" # Run cleanup action if all cycles fail\n</code></pre> <p>Cycle behavior: </p> <ol> <li>Execute transformation</li> <li>Check for failure files</li> <li>If failure detected and cycles remaining, retry</li> <li>If all cycles exhausted, trigger <code>on_failure</code> action</li> <li>Pass error context to retry attempts</li> </ol>"},{"location":"actions/claude/#error-context-in-retries","title":"Error Context in Retries","text":"<p>On retry, the prompt receives additional context:</p> <pre><code># Appended to prompt automatically:\n\"\"\"\n---\nYou need to fix problems identified from a previous run.\nThe errors for context are:\n\n{\n  \"result\": \"failure\",\n  \"message\": \"Unable to update dependencies\",\n  \"errors\": [\"Package X not found\", \"Version conflict with Y\"]\n}\n\"\"\"\n</code></pre>"},{"location":"actions/claude/#advanced-usage","title":"Advanced Usage","text":""},{"location":"actions/claude/#conditional-prompts","title":"Conditional Prompts","text":"<p>Workflow: <pre><code>[[actions]]\nname = \"language-specific-update\"\ntype = \"claude\"\ntask_prompt = \"prompts/{{ imbi_project.facts.get('Programming Language', 'unknown') | lower }}-update.md\"\n</code></pre></p>"},{"location":"actions/claude/#multi-stage-transformations","title":"Multi-Stage Transformations","text":"<pre><code>[[actions]]\nname = \"stage1-refactor\"\ntype = \"claude\"\ntask_prompt = \"prompts/stage1.md\"\n\n[[actions]]\nname = \"stage2-optimize\"\ntype = \"claude\"\ntask_prompt = \"prompts/stage2.md\"\n\n[[actions]]\nname = \"stage3-document\"\ntype = \"claude\"\ntask_prompt = \"prompts/stage3.md\"\n</code></pre>"},{"location":"actions/claude/#with-prepost-actions","title":"With Pre/Post Actions","text":"<pre><code>[[actions]]\nname = \"backup-files\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///src/\"\ndestination = \"repository:///src.backup/\"\n\n[[actions]]\nname = \"ai-refactor\"\ntype = \"claude\"\ntask_prompt = \"prompts/refactor.md\"\non_failure = \"restore-backup\"\n\n[[actions]]\nname = \"run-tests\"\ntype = \"shell\"\ncommand = \"pytest tests/\"\nworking_directory = \"repository:///\"\n\n[[actions]]\nname = \"restore-backup\"\ntype = \"file\"\ncommand = \"move\"\nsource = \"repository:///src.backup/\"\ndestination = \"repository:///src/\"\n</code></pre>"},{"location":"actions/claude/#integration-with-other-actions","title":"Integration with Other Actions","text":""},{"location":"actions/claude/#claude-shell-test-verification","title":"Claude + Shell (Test Verification)","text":"<pre><code>[[actions]]\nname = \"ai-code-update\"\ntype = \"claude\"\ntask_prompt = \"prompts/update.md\"\n\n[[actions]]\nname = \"verify-tests\"\ntype = \"shell\"\ncommand = \"pytest tests/ -v\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/claude/#claude-file-template-application","title":"Claude + File (Template Application)","text":"<pre><code>[[actions]]\nname = \"generate-base-config\"\ntype = \"template\"\nsource_path = \"config.yaml.j2\"\ndestination_path = \"repository:///config.yaml\"\n\n[[actions]]\nname = \"customize-config\"\ntype = \"claude\"\ntask_prompt = \"prompts/customize-config.md\"\n</code></pre>"},{"location":"actions/claude/#claude-git-commit-verification","title":"Claude + Git (Commit Verification)","text":"<pre><code>[[actions]]\nname = \"ai-transformation\"\ntype = \"claude\"\ntask_prompt = \"prompts/transform.md\"\n\n[[actions]]\nname = \"verify-commit\"\ntype = \"shell\"\ncommand = \"git log -1 --pretty=%B\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/claude/#mcp-servers","title":"MCP Servers","text":"<p>Claude actions automatically have access to MCP (Model Context Protocol) servers configured at the workflow level. These servers provide Claude with tools to access external data sources and APIs during task execution.</p>"},{"location":"actions/claude/#configuration_1","title":"Configuration","text":"<p>MCP servers are configured in the workflow's <code>config.toml</code> file under the <code>[mcp_servers]</code> section. See MCP Server Configuration for full documentation.</p>"},{"location":"actions/claude/#available-servers","title":"Available Servers","text":"<p>During Claude action execution, the following MCP servers are available:</p> <ol> <li><code>agent_tools</code> (built-in): Provides workflow submission functions:</li> <li><code>mcp__agent_tools__submit_planning_response()</code> - For planning agents</li> <li><code>mcp__agent_tools__submit_task_response()</code> - For task agents</li> <li> <p><code>mcp__agent_tools__submit_validation_response()</code> - For validation agents</p> </li> <li> <p>Workflow-configured servers: Any MCP servers defined in <code>[mcp_servers.*]</code> sections</p> </li> </ol>"},{"location":"actions/claude/#example-database-access","title":"Example: Database Access","text":"<pre><code># Workflow config.toml\n[mcp_servers.postgres]\ntype = \"stdio\"\ncommand = \"uvx\"\nargs = [\"mcp-server-postgres\", \"${DATABASE_URL}\"]\n\n[[actions]]\nname = \"analyze-schema\"\ntype = \"claude\"\ntask_prompt = \"prompts/analyze-schema.md\"\n</code></pre> <p>Prompt (<code>prompts/analyze-schema.md</code>): <pre><code># Analyze Database Schema\n\nUse the postgres MCP server to analyze the database schema.\n\n1. List all tables in the database\n2. Identify relationships between tables\n3. Generate a summary of the schema structure\n\nUse the `mcp__postgres__*` tools to query the database.\n</code></pre></p>"},{"location":"actions/claude/#environment-variables-in-mcp-configs","title":"Environment Variables in MCP Configs","text":"<p>MCP server configurations support shell-style environment variable expansion (<code>$VAR</code> or <code>${VAR}</code>) for secure credential injection. Variables are expanded at runtime when the Claude client is created.</p> <pre><code>[mcp_servers.secure-api]\ntype = \"http\"\nurl = \"https://api.example.com/mcp\"\nheaders = { Authorization = \"Bearer ${API_TOKEN}\" }\n</code></pre> <p>If a referenced environment variable is not set, a clear error is raised before execution begins.</p>"},{"location":"actions/claude/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>API Costs: Each cycle makes Claude API calls</li> <li>Execution Time: Complex transformations can take several minutes</li> <li>Context Size: Large repositories may hit context limits</li> <li>Rate Limiting: Respect Anthropic API rate limits</li> </ul>"},{"location":"actions/claude/#security-considerations","title":"Security Considerations","text":"<ul> <li>Code Execution: Claude can execute arbitrary code in the repository context</li> <li>Sensitive Data: Prompts and code are sent to Anthropic API</li> <li>API Keys: Ensure API keys are properly secured</li> <li>Verification: Always verify AI-generated changes before merging</li> </ul>"},{"location":"actions/claude/#implementation-notes","title":"Implementation Notes","text":"<ul> <li>Module: <code>src/imbi_automations/actions/claude.py</code> and <code>src/imbi_automations/claude.py</code></li> <li>Models: <code>src/imbi_automations/models/claude.py</code> (agent types, response models)</li> <li>Tests: <code>tests/test_claude.py</code> and <code>tests/actions/test_claude.py</code> (376 passing tests)</li> <li>Working Directory: Task agent runs in <code>working_directory/repository/</code> subdirectory</li> <li>Agent Locations: <code>claude-code/agents/{planning,task,validation}.md.j2</code></li> <li>Prompt Templates: <code>actions/prompts/{with-plan,planning-with-errors,last-error}.md.j2</code></li> <li>Tool Submission: Agents use MCP agent_tools for structured responses</li> <li>Automatic Cleanup: Working directories cleaned on success or failure</li> <li>Full Logging: Claude API interactions logged at DEBUG level</li> <li>Cycle Warning: Warning logged at 60% of max_cycles (e.g., cycle 3 of 5)</li> <li>Error Categorization: Failures categorized as dependency_unavailable, constraint_conflict, prohibited_action, test_failure, or unknown</li> </ul> <p>Recent Critical Fixes (October 2025): 1. Planning Agent Error Handling (commit 561909f): Fixed planning agent to create NEW PLAN instead of fixing errors directly when validation fails 2. Claude SDK CWD Fix (commit 561909f): Changed working directory from root to <code>repository/</code> subdirectory for correct file operations 3. preserve_on_error Fix (commit 561909f): Fixed unreachable preservation code, now properly saves error states 4. Test Suite Update (commit 561909f): Fixed 28 broken tests, all 376 tests now passing</p>"},{"location":"actions/docker/","title":"Docker Actions","text":"<p>Docker actions provide container operations for extracting files from Docker images.</p>"},{"location":"actions/docker/#configuration","title":"Configuration","text":"<pre><code>[[actions]]\nname = \"action-name\"\ntype = \"docker\"\ncommand = \"extract\"     # Only extract is currently implemented\nimage = \"image:tag\"     # Required\n# Command-specific fields below\n</code></pre>"},{"location":"actions/docker/#commands","title":"Commands","text":""},{"location":"actions/docker/#extract","title":"extract","text":"<p>Extract files from a Docker container image.</p> <p>Status: \u2705 Implemented  </p> <p>Required Fields: </p> <ul> <li><code>image</code> (string): Docker image name (tag can be separate or in format <code>image:tag</code>)</li> <li><code>source</code> (pathlib.Path): Path inside container to extract from</li> <li><code>destination</code> (<code>ResourceUrl</code>): Local path to extract to (typically <code>extracted:///</code>)</li> </ul> <p>Optional Fields: </p> <ul> <li><code>tag</code> (string): Image tag (default: <code>latest</code>) - only used if image doesn't contain <code>:tag</code></li> </ul> <p>Example: <pre><code>[[actions]]\nname = \"extract-python-libs\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"python\"\ntag = \"3.12-slim\"\nsource = \"/usr/local/lib/python3.12/\"\ndestination = \"extracted:///python-libs/\"\n</code></pre></p> <p>Behavior: </p> <ol> <li>Pulls the image if not available locally (<code>docker pull</code>)</li> <li>Creates temporary container from image (<code>docker create</code>)</li> <li>Copies files from container to local filesystem (<code>docker cp</code>)</li> <li>Stores in <code>extracted:///</code> directory (resolves to <code>{working_directory}/extracted/</code>)</li> <li>Automatically cleans up container (<code>docker rm</code>)</li> </ol>"},{"location":"actions/docker/#build","title":"build","text":"<p>Status: \u274c Not yet implemented (raises NotImplementedError)  </p> <p>Build a Docker image from a Dockerfile.</p> <p>Required Fields: </p> <ul> <li><code>image</code>: Image name to create</li> <li><code>path</code>: Path to Dockerfile directory (<code>ResourceUrl</code>)</li> </ul> <p>Optional Fields: </p> <ul> <li><code>tag</code>: Image tag (default: <code>latest</code>)</li> </ul>"},{"location":"actions/docker/#pull","title":"pull","text":"<p>Status: \u274c Not yet implemented (raises NotImplementedError)  </p> <p>Pull a Docker image from registry.</p> <p>Required Fields: </p> <ul> <li><code>image</code>: Image name to pull</li> </ul> <p>Optional Fields: </p> <ul> <li><code>tag</code>: Image tag (default: <code>latest</code>)</li> </ul>"},{"location":"actions/docker/#push","title":"push","text":"<p>Status: \u274c Not yet implemented (raises NotImplementedError)  </p> <p>Push a Docker image to registry.</p> <p>Required Fields: </p> <ul> <li><code>image</code>: Image name to push</li> </ul> <p>Optional Fields: </p> <ul> <li><code>tag</code>: Image tag (default: <code>latest</code>)</li> </ul>"},{"location":"actions/docker/#common-use-cases","title":"Common Use Cases","text":""},{"location":"actions/docker/#extract-configuration-files","title":"Extract Configuration Files","text":"<pre><code>[[actions]]\nname = \"extract-nginx-config\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"nginx\"\ntag = \"latest\"\nsource = \"/etc/nginx/\"\ndestination = \"extracted:///nginx-config/\"\n\n[[actions]]\nname = \"copy-to-repo\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"extracted:///nginx-config/nginx.conf\"\ndestination = \"repository:///config/nginx.conf\"\n</code></pre>"},{"location":"actions/docker/#extract-python-packages","title":"Extract Python Packages","text":"<pre><code>[[actions]]\nname = \"extract-site-packages\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"myapp\"\ntag = \"latest\"\nsource = \"/usr/local/lib/python3.12/site-packages/\"\ndestination = \"extracted:///packages/\"\n</code></pre>"},{"location":"actions/docker/#extract-multiple-directories","title":"Extract Multiple Directories","text":"<pre><code>[[actions]]\nname = \"extract-app-dir\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"myapp\"\ntag = \"latest\"\nsource = \"/app/\"\ndestination = \"extracted:///app/\"\n\n[[actions]]\nname = \"extract-config-dir\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"myapp\"\ntag = \"latest\"\nsource = \"/etc/myapp/\"\ndestination = \"extracted:///config/\"\n</code></pre>"},{"location":"actions/docker/#implementation-notes","title":"Implementation Notes","text":""},{"location":"actions/docker/#extract-command","title":"Extract Command","text":"<ul> <li>Requires Docker daemon running locally</li> <li>Uses <code>docker</code> CLI commands (<code>pull</code>, <code>create</code>, <code>cp</code>, <code>rm</code>)</li> <li>Temporary containers automatically cleaned up after extraction</li> <li>Extracted files preserve permissions from container</li> <li>Container name format: <code>imbi-extract-{id}</code></li> <li>Pulls image automatically if not available locally</li> <li>Image names support Jinja2 templating: <code>image = \"{{ project_name }}\"</code></li> </ul>"},{"location":"actions/docker/#not-implemented-commands","title":"Not Implemented Commands","text":"<p>The following commands are defined but not yet implemented: - <code>build</code>: Would build Docker images from Dockerfiles - <code>pull</code>: Would pull images from registry (extract does this automatically) - <code>push</code>: Would push images to registry</p> <p>Attempting to use these commands will raise <code>NotImplementedError</code>.</p>"},{"location":"actions/docker/#error-handling","title":"Error Handling","text":"<ul> <li>Docker command failures raise <code>RuntimeError</code> with exit code and output</li> <li>Missing Docker CLI raises helpful error: \"Docker command not found - is Docker installed and in PATH?\"</li> <li>Container cleanup failures are logged but don't fail the action</li> <li>Image pull failures propagate as RuntimeError</li> </ul>"},{"location":"actions/docker/#integration-with-other-actions","title":"Integration with Other Actions","text":""},{"location":"actions/docker/#docker-extract-file-copy-pattern","title":"Docker Extract + File Copy Pattern","text":"<pre><code># Extract from container\n[[actions]]\nname = \"extract-config\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"nginx\"\ntag = \"alpine\"\nsource = \"/etc/nginx/nginx.conf\"\ndestination = \"extracted:///nginx.conf\"\n\n# Copy to repository\n[[actions]]\nname = \"use-extracted-config\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"extracted:///nginx.conf\"\ndestination = \"repository:///config/nginx.conf\"\n</code></pre>"},{"location":"actions/docker/#docker-extract-claude-analysis","title":"Docker Extract + Claude Analysis","text":"<pre><code># Extract application code\n[[actions]]\nname = \"extract-app-code\"\ntype = \"docker\"\ncommand = \"extract\"\nimage = \"production-app\"\ntag = \"latest\"\nsource = \"/app/src/\"\ndestination = \"extracted:///prod-code/\"\n\n# Analyze with Claude\n[[actions]]\nname = \"analyze-differences\"\ntype = \"claude\"\nprompt = \"prompts/analyze-prod-vs-repo.md\"\n# Prompt can reference both extracted:///prod-code/ and repository:///\n</code></pre>"},{"location":"actions/file/","title":"File Actions","text":"<p>File actions provide comprehensive file manipulation capabilities including copying, moving, deleting, appending, and writing files with support for glob patterns and multiple encoding options.</p>"},{"location":"actions/file/#configuration","title":"Configuration","text":"<pre><code>[[actions]]\nname = \"action-name\"\ntype = \"file\"\ncommand = \"copy|move|rename|delete|append|write\"\n# Command-specific fields documented below\n</code></pre>"},{"location":"actions/file/#commands","title":"Commands","text":""},{"location":"actions/file/#copy","title":"copy","text":"<p>Copy files or directories with glob pattern support.</p> <p>Required Fields: </p> <ul> <li><code>source</code>: Source file/directory path or glob pattern</li> <li><code>destination</code>: Destination path</li> </ul> <p>Examples: </p> <pre><code># Copy single file\n[[actions]]\nname = \"copy-readme\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///README.md\"\ndestination = \"repository:///README.md\"\n\n# Copy with glob pattern\n[[actions]]\nname = \"copy-yaml-files\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///configs/*.yaml\"\ndestination = \"repository:///config/\"\n\n# Copy directory\n[[actions]]\nname = \"copy-templates\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///templates/\"\ndestination = \"repository:///.github/templates/\"\n\n# Recursive glob pattern\n[[actions]]\nname = \"copy-all-python\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///**/*.py\"\ndestination = \"repository:///scripts/\"\n</code></pre> <p>Glob Pattern Support: </p> <ul> <li><code>*</code> - Matches any characters within a filename</li> <li><code>?</code> - Matches single character</li> <li><code>[...]</code> - Matches character ranges</li> <li><code>**/</code> - Recursive directory matching</li> </ul> <p>Behavior: </p> <ul> <li>Creates destination parent directories automatically</li> <li>For glob patterns, destination must be a directory</li> <li>Preserves file metadata (timestamps, permissions)</li> <li>For directories, uses recursive copy</li> </ul>"},{"location":"actions/file/#move","title":"move","text":"<p>Move (rename across directories) files or directories.</p> <p>Required Fields: </p> <ul> <li><code>source</code>: Source file/directory path</li> <li><code>destination</code>: Destination path</li> </ul> <p>Examples: </p> <pre><code># Move file to different directory\n[[actions]]\nname = \"relocate-config\"\ntype = \"file\"\ncommand = \"move\"\nsource = \"repository:///old-location/config.yaml\"\ndestination = \"repository:///config/app.yaml\"\n\n# Reorganize directory structure\n[[actions]]\nname = \"move-tests\"\ntype = \"file\"\ncommand = \"move\"\nsource = \"repository:///old_tests/\"\ndestination = \"repository:///tests/\"\n</code></pre> <p>Behavior: </p> <ul> <li>Source file/directory is removed after move</li> <li>Creates destination parent directories automatically</li> <li>Fails if source doesn't exist</li> </ul>"},{"location":"actions/file/#rename","title":"rename","text":"<p>Rename files within the same directory or move to different location.</p> <p>Required Fields: </p> <ul> <li><code>source</code>: Source file path</li> <li><code>destination</code>: Destination file path</li> </ul> <p>Examples: </p> <pre><code># Simple rename\n[[actions]]\nname = \"rename-config\"\ntype = \"file\"\ncommand = \"rename\"\nsource = \"repository:///config.yml\"\ndestination = \"repository:///config.yaml\"\n\n# Rename with path change\n[[actions]]\nname = \"rename-and-move\"\ntype = \"file\"\ncommand = \"rename\"\nsource = \"repository:///src/old_module.py\"\ndestination = \"repository:///src/new_module.py\"\n</code></pre> <p>Behavior: </p> <ul> <li>Similar to <code>move</code> but semantically for file renaming</li> <li>Creates destination parent directories automatically</li> </ul>"},{"location":"actions/file/#delete","title":"delete","text":"<p>Delete files or directories, with regex pattern matching support.</p> <p>Required Fields: One of:  </p> <ul> <li><code>path</code>: Specific file/directory path</li> <li><code>pattern</code>: Regex pattern for matching files</li> </ul> <p>Examples: </p> <pre><code># Delete specific file\n[[actions]]\nname = \"remove-old-config\"\ntype = \"file\"\ncommand = \"delete\"\npath = \"repository:///old-config.yaml\"\n\n# Delete directory\n[[actions]]\nname = \"remove-cache\"\ntype = \"file\"\ncommand = \"delete\"\npath = \"repository:///__pycache__/\"\n\n# Delete with regex pattern\n[[actions]]\nname = \"remove-pyc-files\"\ntype = \"file\"\ncommand = \"delete\"\npattern = \".*\\\\.pyc$\"\n\n# Delete temporary files\n[[actions]]\nname = \"cleanup-temps\"\ntype = \"file\"\ncommand = \"delete\"\npattern = \".*\\\\.(tmp|bak|swp)$\"\n</code></pre> <p>Behavior: </p> <ul> <li>For <code>path</code>: Deletes specific file or directory (recursive)</li> <li>For <code>pattern</code>: Searches recursively and deletes all matching files</li> <li>Does not error if path doesn't exist</li> <li>Pattern matching uses Python regex syntax (string in TOML, compiled at runtime)</li> </ul>"},{"location":"actions/file/#append","title":"append","text":"<p>Append content to existing files or create new files.</p> <p>Required Fields: </p> <ul> <li><code>path</code>: Target file path</li> <li><code>content</code>: Content to append (string or bytes)</li> </ul> <p>Optional Fields: </p> <ul> <li><code>encoding</code>: Character encoding (default: <code>utf-8</code>)</li> </ul> <p>Examples: </p> <pre><code># Append text to existing file\n[[actions]]\nname = \"add-to-gitignore\"\ntype = \"file\"\ncommand = \"append\"\npath = \"repository:///.gitignore\"\ncontent = \"\"\"\n\n# Added by automation\n*.log\n__pycache__/\n.env\n\"\"\"\n\n# Create or append to file\n[[actions]]\nname = \"add-config-section\"\ntype = \"file\"\ncommand = \"append\"\npath = \"repository:///config.ini\"\ncontent = \"\"\"\n[new_section]\noption = value\n\"\"\"\n\n# Append with custom encoding\n[[actions]]\nname = \"append-unicode\"\ntype = \"file\"\ncommand = \"append\"\npath = \"repository:///unicode.txt\"\ncontent = \"Hello \u4e16\u754c\\n\"\nencoding = \"utf-16\"\n</code></pre> <p>Behavior: </p> <ul> <li>Creates file if it doesn't exist</li> <li>Creates parent directories automatically</li> <li>Appends to end of existing files</li> <li>Text mode only (bytes are decoded using specified encoding)</li> </ul>"},{"location":"actions/file/#write","title":"write","text":"<p>Write content to files, overwriting if they exist.</p> <p>Required Fields: </p> <ul> <li><code>path</code>: Target file path</li> <li><code>content</code>: Content to write (string or bytes)</li> </ul> <p>Optional Fields: </p> <ul> <li><code>encoding</code>: Character encoding (default: <code>utf-8</code>)</li> </ul> <p>Examples: </p> <pre><code># Write text file\n[[actions]]\nname = \"create-readme\"\ntype = \"file\"\ncommand = \"write\"\npath = \"repository:///README.md\"\ncontent = \"\"\"\n# My Project\n\nDescription here\n\n## Installation\n\n````bash\npip install my-project\n````\n\"\"\"\n\n# Write JSON configuration\n[[actions]]\nname = \"write-config\"\ntype = \"file\"\ncommand = \"write\"\npath = \"repository:///config.json\"\ncontent = \"\"\"\n{\n  \"name\": \"my-project\",\n  \"version\": \"1.0.0\",\n  \"type\": \"library\"\n}\n\"\"\"\n\n# Write with custom encoding\n[[actions]]\nname = \"write-utf16\"\ntype = \"file\"\ncommand = \"write\"\npath = \"repository:///data.txt\"\ncontent = \"Unicode content: \u4f60\u597d\"\nencoding = \"utf-16\"\n</code></pre> <p>Behavior: </p> <ul> <li>Overwrites existing files</li> <li>Creates file if it doesn't exist</li> <li>Creates parent directories automatically</li> <li>Text mode (string) or binary mode (bytes) - detected automatically</li> <li>Does NOT support Jinja2 templating (use <code>template</code> action instead)</li> </ul>"},{"location":"actions/file/#path-resolution","title":"Path Resolution","text":"<p>Comprehensive Path Schemes Documentation</p> <p>For detailed information about all path schemes, including usage patterns, best practices, and troubleshooting, see the Path Schemes guide.</p> <p>File actions support all ResourceUrl schemes:</p> Scheme Base Directory Use Case <code>file:///</code> or no scheme Working directory Temporary files <code>repository:///</code> Cloned repository Repository files <code>workflow:///</code> Workflow resources Template files <code>extracted:///</code> Docker extracts Extracted files <code>external:///</code> Absolute path Files outside working directory <p>Examples: </p> <pre><code># Repository to repository\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///README.md\"\ndestination = \"repository:///docs/README.md\"\n\n# Workflow to repository\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///templates/.gitignore\"\ndestination = \"repository:///.gitignore\"\n\n# Extracted to repository\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"extracted:///configs/app.yaml\"\ndestination = \"repository:///config/app.yaml\"\n\n# Repository to external location (extract/export files)\n[[actions]]\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///config.yaml\"\ndestination = \"external:///tmp/project-configs/{{ imbi_project.slug }}/config.yaml\"\ncommittable = false\n\n# Simple paths (relative to working directory)\n[[actions]]\ntype = \"file\"\ncommand = \"write\"\npath = \"temp-file.txt\"  # Same as file:///temp-file.txt\ncontent = \"temporary data\"\n</code></pre> <p>Note: The <code>external:///</code> scheme allows writing files to absolute paths outside the temporary working directory. This is useful for:  </p> <ul> <li>Extracting configuration files for analysis</li> <li>Exporting reports or artifacts</li> <li>Creating backups in known locations</li> <li>Building collections of files from multiple repositories</li> </ul> <p>When using <code>external:///</code>, set <code>committable = false</code> as these operations don't modify the repository.</p>"},{"location":"actions/file/#common-patterns","title":"Common Patterns","text":""},{"location":"actions/file/#backup-and-replace-pattern","title":"Backup and Replace Pattern","text":"<pre><code>[[actions]]\nname = \"backup-original\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"repository:///config.yaml\"\ndestination = \"repository:///config.yaml.bak\"\n\n[[actions]]\nname = \"write-new-config\"\ntype = \"file\"\ncommand = \"write\"\npath = \"repository:///config.yaml\"\ncontent = \"\"\"\ndatabase:\n  host: localhost\n  port: 5432\n\"\"\"\n</code></pre>"},{"location":"actions/file/#template-deployment-pattern","title":"Template Deployment Pattern","text":"<pre><code>[[actions]]\nname = \"copy-gitignore\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///.gitignore\"\ndestination = \"repository:///.gitignore\"\n\n[[actions]]\nname = \"copy-pre-commit\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///.pre-commit-config.yaml\"\ndestination = \"repository:///.pre-commit-config.yaml\"\n</code></pre>"},{"location":"actions/file/#cleanup-pattern","title":"Cleanup Pattern","text":"<pre><code>[[actions]]\nname = \"remove-legacy-configs\"\ntype = \"file\"\ncommand = \"delete\"\npattern = \".*\\\\.legacy\\\\.yaml$\"\n\n[[actions]]\nname = \"remove-cache-dirs\"\ntype = \"file\"\ncommand = \"delete\"\npath = \"repository:///__pycache__/\"\n</code></pre>"},{"location":"actions/file/#glob-copy-pattern","title":"Glob Copy Pattern","text":"<pre><code>[[actions]]\nname = \"copy-all-workflows\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///.github/workflows/*.yml\"\ndestination = \"repository:///.github/workflows/\"\n\n[[actions]]\nname = \"copy-python-modules\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///src/**/*.py\"\ndestination = \"repository:///src/\"\n</code></pre>"},{"location":"actions/file/#error-handling","title":"Error Handling","text":"<p>File actions raise <code>RuntimeError</code> in these situations:</p> <ul> <li><code>copy</code>/<code>move</code>/<code>rename</code>: Source file doesn't exist</li> <li><code>delete</code>: No errors (gracefully handles missing files)</li> <li><code>append</code>/<code>write</code>: I/O errors, permission denied</li> </ul>"},{"location":"actions/file/#implementation-notes","title":"Implementation Notes","text":"<ul> <li>All operations create parent directories automatically</li> <li>File metadata (permissions, timestamps) preserved in copy operations via <code>shutil.copy2</code></li> <li>Glob patterns resolved relative to source base directory</li> <li>Empty glob results raise <code>RuntimeError</code></li> <li>Binary content detected automatically (bytes vs string) in <code>write</code> command</li> <li><code>append</code> command converts bytes to text using encoding (text mode only)</li> <li>Encoding applies only to text operations (default: <code>utf-8</code>)</li> <li>Pattern field accepts regex strings in TOML, compiled to <code>re.Pattern</code> at runtime</li> <li>Content does NOT support Jinja2 templating - use <code>template</code> action type for that</li> </ul>"},{"location":"actions/git/","title":"Git Actions","text":"<p>Git actions provide version control operations for extracting files from Git history and cloning repositories.</p>"},{"location":"actions/git/#configuration","title":"Configuration","text":"<pre><code>[[actions]]\nname = \"action-name\"\ntype = \"git\"\ncommand = \"extract\"  # or \"clone\"\n# Command-specific fields below\n</code></pre>"},{"location":"actions/git/#commands","title":"Commands","text":""},{"location":"actions/git/#extract","title":"extract","text":"<p>Extract a specific file from Git commit history. Useful for retrieving old versions of files from before certain changes were made.</p> <p>Required Fields: </p> <ul> <li><code>source</code> (pathlib.Path): Path to the file in the repository</li> <li><code>destination</code> (<code>ResourceUrl</code>): Where to write the extracted file</li> </ul> <p>Optional Fields: </p> <ul> <li><code>commit_keyword</code> (string): Keyword to search for in commit messages. If not provided, extracts from current HEAD (default: None)</li> <li><code>search_strategy</code> (string): How to find the commit - <code>before_first_match</code> or <code>before_last_match</code>. Only used when <code>commit_keyword</code> is provided (default: <code>before_last_match</code>)</li> <li><code>ignore_errors</code> (bool): Continue if extraction fails instead of raising RuntimeError (default: false)</li> </ul> <p>Example: <pre><code>[[actions]]\nname = \"extract-old-config\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \"config.yaml\"\ndestination = \"extracted:///old-config.yaml\"\ncommit_keyword = \"update config\"\nsearch_strategy = \"before_last_match\"\n</code></pre></p> <p>Search Strategies: </p> <ul> <li><code>before_first_match</code>: Extract file from commit before the first match of keyword</li> <li><code>before_last_match</code> (default): Extract file from commit before the last match of keyword</li> </ul>"},{"location":"actions/git/#clone","title":"clone","text":"<p>Clone a Git repository to a specific location.</p> <p>Required Fields: </p> <ul> <li><code>url</code> (string): Git repository URL to clone</li> <li><code>destination</code> (<code>ResourceUrl</code>): Where to clone the repository</li> </ul> <p>Optional Fields: </p> <ul> <li><code>branch</code> (string): Specific branch to clone</li> <li><code>depth</code> (int): Shallow clone depth (for faster clones)</li> </ul> <p>Example: <pre><code>[[actions]]\nname = \"clone-external-repo\"\ntype = \"git\"\ncommand = \"clone\"\nurl = \"https://github.com/example/repo.git\"\ndestination = \"extracted:///external-repo/\"\nbranch = \"main\"\ndepth = 1\n</code></pre></p>"},{"location":"actions/git/#common-use-cases","title":"Common Use Cases","text":""},{"location":"actions/git/#extract-file-before-breaking-change","title":"Extract File Before Breaking Change","text":"<pre><code>[[actions]]\nname = \"get-old-dockerfile\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \"Dockerfile\"\ndestination = \"extracted:///Dockerfile.old\"\ncommit_keyword = \"breaking\"\nsearch_strategy = \"before_last_match\"\nignore_errors = true\n</code></pre>"},{"location":"actions/git/#extract-config-from-before-migration","title":"Extract Config from Before Migration","text":"<pre><code>[[actions]]\nname = \"backup-old-config\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \"config/settings.yaml\"\ndestination = \"extracted:///settings.yaml.backup\"\ncommit_keyword = \"migrate to new config\"\nsearch_strategy = \"before_first_match\"\n\n[[actions]]\nname = \"merge-configs\"\ntype = \"shell\"\ncommand = \"python scripts/merge-configs.py\"\nworking_directory = \"{{ working_directory }}\"\n</code></pre>"},{"location":"actions/git/#clone-template-repository","title":"Clone Template Repository","text":"<pre><code>[[actions]]\nname = \"clone-template\"\ntype = \"git\"\ncommand = \"clone\"\nurl = \"https://github.com/myorg/project-template.git\"\ndestination = \"extracted:///template/\"\nbranch = \"main\"\ndepth = 1\n\n[[actions]]\nname = \"copy-template-files\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"extracted:///template/configs/*.yaml\"\ndestination = \"repository:///configs/\"\n</code></pre>"},{"location":"actions/git/#extract-multiple-historical-files","title":"Extract Multiple Historical Files","text":"<pre><code>[[actions]]\nname = \"extract-old-requirements\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \"requirements.txt\"\ndestination = \"extracted:///requirements.old.txt\"\ncommit_keyword = \"update dependencies\"\nsearch_strategy = \"before_last_match\"\n\n[[actions]]\nname = \"extract-old-dockerfile\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \"Dockerfile\"\ndestination = \"extracted:///Dockerfile.old\"\ncommit_keyword = \"update base image\"\nsearch_strategy = \"before_last_match\"\n\n[[actions]]\nname = \"compare-versions\"\ntype = \"shell\"\ncommand = \"diff -u extracted/requirements.old.txt repository/requirements.txt || true\"\nworking_directory = \"{{ working_directory }}\"\n</code></pre>"},{"location":"actions/git/#integration-with-other-actions","title":"Integration with Other Actions","text":""},{"location":"actions/git/#git-extract-file-copy-pattern","title":"Git Extract + File Copy Pattern","text":"<pre><code># Extract old version from git history\n[[actions]]\nname = \"get-legacy-config\"\ntype = \"git\"\ncommand = \"extract\"\nsource = \".github/workflows/ci.yml\"\ndestination = \"extracted:///ci.yml.legacy\"\ncommit_keyword = \"migrate to v2\"\nsearch_strategy = \"before_first_match\"\n\n# Copy to repository for comparison\n[[actions]]\nname = \"save-for-reference\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"extracted:///ci.yml.legacy\"\ndestination = \"repository:///.github/workflows/ci.yml.legacy\"\n</code></pre>"},{"location":"actions/git/#git-clone-template-pattern","title":"Git Clone + Template Pattern","text":"<pre><code># Clone shared configuration repo\n[[actions]]\nname = \"clone-shared-configs\"\ntype = \"git\"\ncommand = \"clone\"\nurl = \"https://github.com/myorg/shared-configs.git\"\ndestination = \"extracted:///shared/\"\nbranch = \"main\"\n\n# Render templates from cloned repo\n[[actions]]\nname = \"render-config\"\ntype = \"template\"\nsource_path = \"extracted:///shared/templates/\"\ndestination_path = \"repository:///config/\"\n</code></pre>"},{"location":"actions/git/#implementation-notes","title":"Implementation Notes","text":"<p>Extract command:</p> <ul> <li>If <code>commit_keyword</code> provided: Searches git log for commits matching keyword and extracts from the commit before the match</li> <li>If no <code>commit_keyword</code>: Extracts file from current HEAD</li> <li>Uses <code>git show COMMIT:PATH</code> to retrieve file contents</li> <li>Returns false if file or commit not found (unless <code>ignore_errors</code> is true)</li> <li>Works within the cloned repository directory (<code>{working_directory}/repository/</code>)</li> <li>File must exist at the target commit (raises RuntimeError if not found)</li> </ul> <p>Clone command:</p> <ul> <li>Uses <code>git clone</code> with optional branch and depth parameters</li> <li>Shallow clones (<code>depth=1</code>) are faster for large repositories</li> <li>Cloned repository placed at destination path</li> <li>Full git history available unless depth is specified</li> </ul> <p>Search strategies:</p> <ul> <li><code>before_first_match</code>: Useful for finding original version before any changes</li> <li><code>before_last_match</code>: Useful for finding most recent version before latest change</li> </ul> <p>Path resolution:</p> <ul> <li><code>source</code> paths are relative to repository root</li> <li><code>destination</code> supports all <code>ResourceUrl</code> schemes (<code>extracted:///</code>, <code>repository:///</code>, etc.)</li> <li>Destination directories created automatically if needed</li> </ul>"},{"location":"actions/github/","title":"GitHub Actions","text":"<p>GitHub actions provide GitHub-specific operations like environment synchronization and workflow management.</p>"},{"location":"actions/github/#configuration","title":"Configuration","text":"<pre><code>[[actions]]\nname = \"action-name\"\ntype = \"github\"\ncommand = \"sync_environments\"\n# Command-specific fields\n</code></pre>"},{"location":"actions/github/#commands","title":"Commands","text":""},{"location":"actions/github/#sync_environments","title":"sync_environments","text":"<p>Synchronize GitHub repository environments with Imbi project environments.</p> <p>Example: <pre><code>[[actions]]\nname = \"sync-github-envs\"\ntype = \"github\"\ncommand = \"sync_environments\"\n</code></pre></p> <p>Behavior: </p> <ul> <li>Reads environment data from Imbi project (<code>imbi_project.environments: list[ImbiEnvironment]</code>)</li> <li>Extracts slugs directly from <code>ImbiEnvironment</code> objects (provided by Imbi API)</li> <li>Compares with existing GitHub repository environments</li> <li>Creates missing environments in GitHub</li> <li>Deletes extra environments from GitHub (not in Imbi)</li> <li>Operations sorted alphabetically for deterministic behavior</li> <li>Logs all operations (created, deleted, errors)</li> <li>Raises error if sync fails</li> </ul> <p>Environment Slugs: </p> <ul> <li>Slugs are provided by the Imbi API (no local transformation)</li> <li>The <code>ImbiEnvironment</code> model contains both <code>name</code> and <code>slug</code> fields</li> <li>Slug format is controlled by Imbi (typically lowercase with hyphens)</li> </ul>"},{"location":"actions/github/#common-use-cases","title":"Common Use Cases","text":""},{"location":"actions/github/#environment-synchronization","title":"Environment Synchronization","text":"<pre><code>[[conditions]]\nremote_file_exists = \".github/workflows/deploy.yml\"\n\n[[actions]]\nname = \"ensure-environments\"\ntype = \"github\"\ncommand = \"sync_environments\"\n</code></pre>"},{"location":"actions/github/#post-deployment-updates","title":"Post-Deployment Updates","text":"<pre><code>[[actions]]\nname = \"deploy-code\"\ntype = \"shell\"\ncommand = \"deploy.sh\"\n\n[[actions]]\nname = \"update-environments\"\ntype = \"github\"\ncommand = \"sync_environments\"\n</code></pre>"},{"location":"actions/github/#implementation-notes","title":"Implementation Notes","text":"<p>The GitHub action implementation:</p> <ul> <li>Requires GitHub API access with environment management permissions</li> <li>Uses authenticated GitHub client from workflow configuration</li> <li>Respects GitHub API rate limits</li> <li>Provides idempotent operations (safe to re-run)</li> <li>Integrates with Imbi project environment configuration</li> <li>No repository cloning needed (API-only operations)</li> <li>Skips projects with no environments defined in Imbi</li> </ul> <p>Type Safety: </p> <ul> <li>Uses <code>ImbiEnvironment</code> model objects (not plain strings) for type-safe environment handling</li> <li>Each environment has <code>name</code>, <code>slug</code>, <code>icon_class</code>, and optional <code>description</code> fields</li> <li>Slugs provided directly by Imbi API (no local transformation)</li> <li>Imbi client creates <code>ImbiEnvironment</code> objects from API response data</li> </ul> <p>Filter Support: </p> <ul> <li>Workflow filters can target specific environments using <code>project_environments</code> field</li> <li>Supports both environment names (\"Production\") and slugs (\"production\")</li> <li>Filter checks against both <code>name</code> and <code>slug</code> fields for flexibility</li> <li>Example: <code>project_environments = [\"production\", \"staging\"]</code> in workflow config</li> </ul>"},{"location":"actions/imbi/","title":"Imbi Actions","text":"<p>Imbi actions provide integration with the Imbi project management system, enabling workflows to interact with and update project metadata, facts, and configurations.</p>"},{"location":"actions/imbi/#configuration","title":"Configuration","text":"<pre><code>[[actions]]\nname = \"action-name\"\ntype = \"imbi\"\ncommand = \"set_project_fact\"  # Required\n</code></pre>"},{"location":"actions/imbi/#available-commands","title":"Available Commands","text":""},{"location":"actions/imbi/#set_environments","title":"set_environments","text":"<p>Updates the list of environments for the current project in Imbi.</p> <p>Configuration: <pre><code>[[actions]]\nname = \"set-environments\"\ntype = \"imbi\"\ncommand = \"set_environments\"\nvalues = [\"testing\", \"staging\", \"production\"]\n</code></pre></p> <p>Fields:</p> <ul> <li><code>values</code> (list of strings, required): List of environment names or slugs to set for the project</li> </ul> <p>Features: </p> <ul> <li>Flexible Input: Accepts both environment names (e.g., \"Testing\") and slugs (e.g., \"testing\")</li> <li>Smart Updates: Only makes API calls when environments actually differ from current state</li> <li>Automatic Translation: Converts environment slugs to names using ImbiMetadataCache</li> <li>Non-Committable: Does not create git commits (modifies Imbi state only)</li> </ul> <p>Use Cases: </p> <ul> <li>Standardize environments across projects</li> <li>Sync environment configuration after infrastructure changes</li> <li>Set up new projects with standard environment set</li> <li>Update environments as part of deployment pipeline setup</li> </ul> <p>Example:</p> <pre><code>[[actions]]\nname = \"set-standard-environments\"\ntype = \"imbi\"\ncommand = \"set_environments\"\nvalues = [\"testing\", \"staging\", \"production\"]\n\n[[actions]]\nname = \"sync-to-github\"\ntype = \"github\"\ncommand = \"sync_environments\"\n</code></pre>"},{"location":"actions/imbi/#update_project","title":"update_project","text":"<p>Updates one or more project attributes in Imbi using a generic, flexible approach.</p> <p>Configuration: <pre><code>[[actions]]\nname = \"update-project-metadata\"\ntype = \"imbi\"\ncommand = \"update_project\"\nattributes = {\n    description = \"REST API for user authentication and profile management\",\n    name = \"{{ imbi_project.name }} v2\"\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>attributes</code> (dict, required): Dictionary of attribute names to new values. Keys should match ImbiProject model fields (e.g., <code>description</code>, <code>name</code>, <code>namespace</code>, etc.). String values support Jinja2 templates.</li> </ul> <p>Features: </p> <ul> <li>Generic Updates: Update any project attribute in a single action</li> <li>Template Support: String values support full Jinja2 templating with workflow context</li> <li>Smart Updates: Only sends PATCH requests for attributes that have changed</li> <li>Batch Operations: Update multiple attributes in a single API call</li> <li>HTTP 304 Handling: Properly handles \"Not Modified\" responses</li> <li>Non-Committable: Does not create git commits (modifies Imbi state only)</li> </ul> <p>Available Attributes:</p> <p>Project attributes that can be updated: - <code>description</code> - Project description text - <code>name</code> - Project display name - Any other writable field on the ImbiProject model</p> <p>Use Cases: </p> <ul> <li>Update project metadata after repository analysis</li> <li>Sync project information with repository changes</li> <li>Standardize project attributes across organization</li> <li>Update multiple fields atomically</li> <li>Generate descriptions using AI (Claude actions)</li> </ul> <p>Basic Example: <pre><code>[[actions]]\nname = \"update-description\"\ntype = \"imbi\"\ncommand = \"update_project\"\nattributes = {\n    description = \"Python API for {{ imbi_project.name }}\"\n}\n</code></pre></p> <p>With File Reading: <pre><code>[[actions]]\nname = \"generate-description-with-ai\"\ntype = \"claude\"\ntask_prompt = \"prompts/generate-description.md\"\ncommittable = false\n\n[[actions]]\nname = \"update-from-generated-file\"\ntype = \"imbi\"\ncommand = \"update_project\"\nattributes = {\n    description = \"{{ read_file('repository:///GENERATED_DESCRIPTION.txt').strip() }}\"\n}\n\n[[actions.conditions]]\nfile_exists = \"repository:///GENERATED_DESCRIPTION.txt\"\n</code></pre></p> <p>From README: <pre><code>[[actions]]\nname = \"sync-metadata-from-repo\"\ntype = \"imbi\"\ncommand = \"update_project\"\nattributes = {\n    description = \"{{ read_file('repository:///README.md').split('\\\\n')[2] }}\",\n    name = \"{{ imbi_project.namespace }} / {{ imbi_project.slug }}\"\n}\n</code></pre></p> <p>Multiple Attributes: <pre><code>[[actions]]\nname = \"update-project-info\"\ntype = \"imbi\"\ncommand = \"update_project\"\nattributes = {\n    description = \"{{ imbi_project.description | default('No description') }}\",\n    name = \"{{ imbi_project.name }} (Production Ready)\"\n}\n</code></pre></p>"},{"location":"actions/imbi/#set_project_fact","title":"set_project_fact","text":"<p>Updates or creates a fact for the current project in Imbi.</p> <p>Configuration: <pre><code>[[actions]]\nname = \"update-python-version\"\ntype = \"imbi\"\ncommand = \"set_project_fact\"\nfact_name = \"Python Version\"\nvalue = \"3.12\"\n</code></pre></p> <p>Fields:</p> <ul> <li><code>fact_name</code> (string, required): Name of the fact to set</li> <li><code>value</code> (string|number|boolean, required): Value to assign to the fact</li> <li><code>skip_validations</code> (boolean, optional): Skip fact validation (default: false)</li> </ul> <p>Use Cases:</p> <ul> <li>Update project metadata after automated changes</li> <li>Track migration status across projects</li> <li>Record version upgrades or dependency changes</li> <li>Maintain synchronization between repository state and Imbi</li> </ul>"},{"location":"actions/imbi/#get_project_fact","title":"get_project_fact","text":"<p>Retrieves a fact value from the current project and optionally stores it in a workflow variable for use in subsequent actions.</p> <p>Configuration: <pre><code>[[actions]]\nname = \"get-language\"\ntype = \"imbi\"\ncommand = \"get_project_fact\"\nfact_name = \"Programming Language\"\nvariable_name = \"current_language\"  # Optional\n</code></pre></p> <p>Fields:</p> <ul> <li><code>fact_name</code> (string, required): Name of the fact to retrieve</li> <li><code>variable_name</code> (string, optional): Variable name to store the result for use in templates</li> </ul> <p>Use Cases:</p> <ul> <li>Retrieve current fact values for conditional logic</li> <li>Store fact values for use in subsequent action templates</li> <li>Log or audit current project state before making changes</li> </ul> <p>Example with Variable: <pre><code>[[actions]]\nname = \"get-current-version\"\ntype = \"imbi\"\ncommand = \"get_project_fact\"\nfact_name = \"Python Version\"\nvariable_name = \"old_version\"\n\n[[actions]]\nname = \"log-upgrade\"\ntype = \"shell\"\ncommand = \"echo 'Upgrading from {{ variables.old_version }} to 3.12'\"\n</code></pre></p>"},{"location":"actions/imbi/#delete_project_fact","title":"delete_project_fact","text":"<p>Removes a fact from the current project.</p> <p>Configuration: <pre><code>[[actions]]\nname = \"remove-obsolete-fact\"\ntype = \"imbi\"\ncommand = \"delete_project_fact\"\nfact_name = \"Legacy Framework\"\n</code></pre></p> <p>Fields:</p> <ul> <li><code>fact_name</code> (string, required): Name of the fact to delete</li> <li><code>skip_validations</code> (boolean, optional): Skip validation (default: false)</li> </ul> <p>Use Cases:</p> <ul> <li>Remove obsolete facts after migrations</li> <li>Clean up deprecated metadata</li> <li>Reset project facts before re-analysis</li> </ul> <p>Note: If the fact doesn't exist, the action completes successfully without error.</p>"},{"location":"actions/imbi/#add_project_link","title":"add_project_link","text":"<p>Adds an external link to the current project.</p> <p>Configuration: <pre><code>[[actions]]\nname = \"add-docs-link\"\ntype = \"imbi\"\ncommand = \"add_project_link\"\nlink_type = \"Documentation\"\nurl = \"https://docs.example.com/{{ imbi_project.slug }}\"\n</code></pre></p> <p>Fields:</p> <ul> <li><code>link_type</code> (string, required): Type of link (e.g., \"Documentation\", \"Repository\", \"Dashboard\")</li> <li><code>url</code> (string, required): URL for the link (supports Jinja2 templates)</li> </ul> <p>Use Cases:</p> <ul> <li>Add documentation links after generating docs</li> <li>Link to monitoring dashboards</li> <li>Add repository links for new projects</li> <li>Connect to external services (PagerDuty, Datadog, etc.)</li> </ul> <p>Example: <pre><code>[[actions]]\nname = \"add-github-link\"\ntype = \"imbi\"\ncommand = \"add_project_link\"\nlink_type = \"Repository\"\nurl = \"https://github.com/{{ github_repository.full_name }}\"\n</code></pre></p>"},{"location":"actions/imbi/#update_project_type","title":"update_project_type","text":"<p>Changes the project type classification.</p> <p>Configuration: <pre><code>[[actions]]\nname = \"reclassify-project\"\ntype = \"imbi\"\ncommand = \"update_project_type\"\nproject_type = \"consumer\"\n</code></pre></p> <p>Fields:</p> <ul> <li><code>project_type</code> (string, required): Slug of the new project type</li> </ul> <p>Use Cases:</p> <ul> <li>Reclassify projects after architecture changes</li> <li>Correct project type errors</li> <li>Migrate projects between categories</li> </ul> <p>Note: If the project is already the specified type, the action completes without making changes.</p>"},{"location":"actions/imbi/#batch_update_facts","title":"batch_update_facts","text":"<p>Updates multiple project facts in a single operation.</p> <p>Configuration: <pre><code>[[actions]]\nname = \"update-all-facts\"\ntype = \"imbi\"\ncommand = \"batch_update_facts\"\nfacts = {\n    \"Python Version\" = \"3.12\",\n    \"Framework\" = \"FastAPI\",\n    \"Test Coverage\" = 85\n}\n</code></pre></p> <p>Fields:</p> <ul> <li><code>facts</code> (dict, required): Dictionary mapping fact names to values</li> <li><code>skip_validations</code> (boolean, optional): Skip validation for all facts (default: false)</li> </ul> <p>Use Cases:</p> <ul> <li>Update multiple related facts after a migration</li> <li>Set initial facts for new projects</li> <li>Bulk update facts based on automated analysis</li> </ul> <p>Example: <pre><code>[[actions]]\nname = \"record-analysis-results\"\ntype = \"imbi\"\ncommand = \"batch_update_facts\"\nfacts = {\n    \"Programming Language\" = \"Python 3.12\",\n    \"Has Tests\" = true,\n    \"Code Quality Score\" = 87,\n    \"Last Analyzed\" = \"2024-01-15\"\n}\n</code></pre></p>"},{"location":"actions/imbi/#context-access","title":"Context Access","text":"<p>Imbi actions have access to the current project data through the workflow context:</p> <pre><code>context.imbi_project.id           # Project ID\ncontext.imbi_project.name         # Project name\ncontext.imbi_project.namespace    # Project namespace\ncontext.imbi_project.project_type # Project type\ncontext.imbi_project.facts        # Current project facts\n</code></pre>"},{"location":"actions/imbi/#examples","title":"Examples","text":""},{"location":"actions/imbi/#set-standard-environments","title":"Set Standard Environments","text":"<pre><code># Standardize environments across all frontend projects\n[filter]\nproject_types = [\"frontend-applications\"]\ngithub_identifier_required = true\n\n[[actions]]\nname = \"set-environments\"\ntype = \"imbi\"\ncommand = \"set_environments\"\nvalues = [\"testing\", \"staging\", \"production\"]\n\n[[actions]]\nname = \"sync-to-github\"\ntype = \"github\"\ncommand = \"sync_environments\"\n</code></pre>"},{"location":"actions/imbi/#update-python-version-fact","title":"Update Python Version Fact","text":"<pre><code>[[actions]]\nname = \"upgrade-python\"\ntype = \"claude\"\nprompt = \"workflow:///prompts/upgrade-python.md\"\n\n[[actions]]\nname = \"record-python-version\"\ntype = \"imbi\"\ncommand = \"set_project_fact\"\nfact_name = \"Programming Language\"\nfact_value = \"Python 3.12\"\n</code></pre>"},{"location":"actions/imbi/#track-migration-status","title":"Track Migration Status","text":"<pre><code>[[actions]]\nname = \"migrate-config\"\ntype = \"file\"\ncommand = \"copy\"\nsource = \"workflow:///new-config.yaml\"\ndestination = \"repository:///config.yaml\"\n\n[[actions]]\nname = \"mark-migration-complete\"\ntype = \"imbi\"\ncommand = \"set_project_fact\"\nfact_name = \"Config Migration Status\"\nfact_value = \"Completed\"\n</code></pre>"},{"location":"actions/imbi/#record-docker-image-version","title":"Record Docker Image Version","text":"<pre><code>[[actions]]\nname = \"update-dockerfile\"\ntype = \"claude\"\nprompt = \"workflow:///prompts/update-docker.md\"\n\n[[actions]]\nname = \"record-base-image\"\ntype = \"imbi\"\ncommand = \"set_project_fact\"\nfact_name = \"Docker Base Image\"\nfact_value = \"python:3.12-slim\"\n</code></pre>"},{"location":"actions/imbi/#common-patterns","title":"Common Patterns","text":""},{"location":"actions/imbi/#post-migration-tracking","title":"Post-Migration Tracking","text":"<pre><code># Perform migration\n[[actions]]\nname = \"migrate-to-new-framework\"\ntype = \"claude\"\nprompt = \"workflow:///prompts/framework-migration.md\"\n\n# Record successful migration\n[[actions]]\nname = \"update-framework-fact\"\ntype = \"imbi\"\ncommand = \"set_project_fact\"\nfact_name = \"Framework\"\nfact_value = \"FastAPI 0.110\"\n</code></pre>"},{"location":"actions/imbi/#conditional-updates-based-on-facts","title":"Conditional Updates Based on Facts","text":"<p>Use workflow filters to target projects by existing facts, then update after transformation:</p> <pre><code># In workflow config.toml\n[filter]\nproject_facts = {\"Framework\" = \"Flask\"}\n\n# Actions update to FastAPI and record change\n[[actions]]\nname = \"migrate-flask-to-fastapi\"\ntype = \"claude\"\nprompt = \"workflow:///prompts/flask-to-fastapi.md\"\n\n[[actions]]\nname = \"update-framework-fact\"\ntype = \"imbi\"\ncommand = \"set_project_fact\"\nfact_name = \"Framework\"\nfact_value = \"FastAPI\"\n</code></pre>"},{"location":"actions/imbi/#available-commands-summary","title":"Available Commands Summary","text":"Command Description <code>add_project_link</code> Add external links to projects <code>batch_update_facts</code> Update multiple facts in a single operation <code>delete_project_fact</code> Remove obsolete project facts <code>get_project_fact</code> Retrieve fact values for conditional logic <code>set_environments</code> Update project environments with smart validation <code>set_project_fact</code> Update or create project facts with validation <code>update_project</code> Update any project attributes with template support <code>update_project_type</code> Change project classification"},{"location":"actions/imbi/#integration-with-other-actions","title":"Integration with Other Actions","text":""},{"location":"actions/imbi/#with-claude-actions","title":"With Claude Actions","text":"<pre><code>[[actions]]\nname = \"ai-dependency-update\"\ntype = \"claude\"\nprompt = \"workflow:///prompts/update-deps.md\"\n\n[[actions]]\nname = \"record-dependency-version\"\ntype = \"imbi\"\ncommand = \"set_project_fact\"\nfact_name = \"Primary Dependencies\"\nfact_value = \"httpx&gt;=0.27, pydantic&gt;=2.0\"\n</code></pre>"},{"location":"actions/imbi/#with-shell-actions","title":"With Shell Actions","text":"<pre><code>[[actions]]\nname = \"detect-python-version\"\ntype = \"shell\"\ncommand = \"python --version | cut -d' ' -f2\"\nworking_directory = \"repository:///\"\n\n[[actions]]\nname = \"record-detected-version\"\ntype = \"imbi\"\ncommand = \"set_project_fact\"\nfact_name = \"Python Version\"\nfact_value = \"{{ shell_output }}\"  # From previous action\n</code></pre>"},{"location":"actions/imbi/#best-practices","title":"Best Practices","text":"<ol> <li>Use After Transformations: Record changes after successful transformations</li> <li>Semantic Fact Names: Use clear, descriptive fact names that match Imbi's schema</li> <li>Version Tracking: Record version numbers for dependencies and tools</li> <li>Status Tracking: Use facts to track migration/upgrade status across projects</li> <li>Conditional Execution: Combine with workflow filters to target specific project states</li> </ol>"},{"location":"actions/imbi/#see-also","title":"See Also","text":"<ul> <li>Callable Actions - Direct Imbi API method calls (alternative approach)</li> <li>Workflow Configuration - Using project facts in filters</li> </ul>"},{"location":"actions/shell/","title":"Shell Actions","text":"<p>Shell actions execute arbitrary commands with full Jinja2 template support for dynamic command construction and access to workflow context variables.</p>"},{"location":"actions/shell/#configuration","title":"Configuration","text":"<pre><code>[[actions]]\nname = \"action-name\"\ntype = \"shell\"\ncommand = \"command to execute\"\nworking_directory = \"path\"  # Optional, default: repository:///\nignore_errors = false       # Optional, default: false\n</code></pre>"},{"location":"actions/shell/#fields","title":"Fields","text":""},{"location":"actions/shell/#command-required","title":"command (required)","text":"<p>The shell command to execute. Supports full Jinja2 template syntax for variable substitution.</p> <p>Type: <code>string</code> </p> <p>Template Variables Available: </p> <ul> <li><code>workflow</code>: Workflow configuration object</li> <li><code>imbi_project</code>: Complete Imbi project data</li> <li><code>github_repository</code>: GitHub repository object (if applicable)</li> <li><code>working_directory</code>: Path to workflow working directory</li> <li><code>starting_commit</code>: Initial Git commit SHA</li> </ul>"},{"location":"actions/shell/#working_directory-optional","title":"working_directory (optional)","text":"<p>Directory to execute the command in.</p> <p>Type: <code>ResourceUrl</code> (string path)</p> <p>Default: <code>repository:///</code> (the cloned repository directory)  </p>"},{"location":"actions/shell/#ignore_errors-optional","title":"ignore_errors (optional)","text":"<p>Whether to continue workflow execution if the command fails (non-zero exit code).</p> <p>Type: <code>boolean</code> </p> <p>Default: <code>false</code> </p>"},{"location":"actions/shell/#examples","title":"Examples","text":""},{"location":"actions/shell/#basic-command-execution","title":"Basic Command Execution","text":"<pre><code>[[actions]]\nname = \"run-tests\"\ntype = \"shell\"\ncommand = \"pytest tests/ -v\"\n</code></pre>"},{"location":"actions/shell/#command-with-working-directory","title":"Command with Working Directory","text":"<pre><code>[[actions]]\nname = \"build-project\"\ntype = \"shell\"\ncommand = \"python setup.py build\"\nworking_directory = \"{{ working_directory }}/repository\"\n</code></pre>"},{"location":"actions/shell/#template-variable-usage","title":"Template Variable Usage","text":"<pre><code>[[actions]]\nname = \"create-tag\"\ntype = \"shell\"\ncommand = \"git tag -a v{{ version }} -m 'Release {{ version }} for {{ imbi_project.name }}'\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/shell/#multi-step-script-execution","title":"Multi-Step Script Execution","text":"<p>Note: Shell actions execute commands directly without a shell, so shell operators like <code>&amp;&amp;</code>, <code>||</code>, <code>;</code>, and <code>|</code> do not work. For multi-step operations, use a shell wrapper:  </p> <pre><code>[[actions]]\nname = \"setup-and-test\"\ntype = \"shell\"\ncommand = \"\"\"\nbash -c 'python -m venv .venv &amp;&amp; source .venv/bin/activate &amp;&amp; pip install -e .[dev] &amp;&amp; pytest tests/ --cov={{ imbi_project.slug }}'\n\"\"\"\nworking_directory = \"{{ working_directory }}/repository\"\n</code></pre>"},{"location":"actions/shell/#conditional-execution-with-shell","title":"Conditional Execution with Shell","text":"<pre><code>[[actions]]\nname = \"npm-install-if-needed\"\ntype = \"shell\"\ncommand = \"bash -c 'if [ -f package.json ]; then npm install; fi'\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/shell/#ignore-errors","title":"Ignore Errors","text":"<pre><code>[[actions]]\nname = \"optional-linting\"\ntype = \"shell\"\ncommand = \"ruff check src/\"\nworking_directory = \"repository:///\"\nignore_errors = true  # Don't fail workflow if linting fails\n</code></pre>"},{"location":"actions/shell/#common-use-cases","title":"Common Use Cases","text":""},{"location":"actions/shell/#running-tests","title":"Running Tests","text":"<pre><code>[[actions]]\nname = \"run-python-tests\"\ntype = \"shell\"\ncommand = \"pytest tests/ -v --tb=short\"\nworking_directory = \"{{ working_directory }}/repository\"\n\n[[actions]]\nname = \"run-javascript-tests\"\ntype = \"shell\"\ncommand = \"npm test\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/shell/#building-artifacts","title":"Building Artifacts","text":"<pre><code>[[actions]]\nname = \"build-python-package\"\ntype = \"shell\"\ncommand = \"python -m build\"\nworking_directory = \"{{ working_directory }}/repository\"\n\n[[actions]]\nname = \"build-docker-image\"\ntype = \"shell\"\ncommand = \"docker build -t {{ imbi_project.slug }}:latest .\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/shell/#code-quality-tools","title":"Code Quality Tools","text":"<pre><code>[[actions]]\nname = \"run-linter\"\ntype = \"shell\"\ncommand = \"ruff check --fix src/\"\nworking_directory = \"repository:///\"\n\n[[actions]]\nname = \"format-code\"\ntype = \"shell\"\ncommand = \"ruff format src/ tests/\"\nworking_directory = \"repository:///\"\n\n[[actions]]\nname = \"type-check\"\ntype = \"shell\"\ncommand = \"mypy src/\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/shell/#git-operations","title":"Git Operations","text":"<pre><code>[[actions]]\nname = \"get-current-version\"\ntype = \"shell\"\ncommand = \"git describe --tags --abbrev=0\"\nworking_directory = \"repository:///\"\n\n[[actions]]\nname = \"list-changed-files\"\ntype = \"shell\"\ncommand = \"git diff --name-only {{ starting_commit }} HEAD\"\nworking_directory = \"{{ working_directory }}/repository\"\n</code></pre>"},{"location":"actions/shell/#environment-setup","title":"Environment Setup","text":"<pre><code>[[actions]]\nname = \"setup-python-env\"\ntype = \"shell\"\ncommand = \"\"\"\npython -m venv .venv &amp;&amp; \\\n.venv/bin/pip install --upgrade pip setuptools wheel\n\"\"\"\nworking_directory = \"repository:///\"\n\n[[actions]]\nname = \"setup-node-env\"\ntype = \"shell\"\ncommand = \"npm ci\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/shell/#advanced-template-examples","title":"Advanced Template Examples","text":""},{"location":"actions/shell/#using-imbi-project-data","title":"Using Imbi Project Data","text":"<pre><code>[[actions]]\nname = \"project-specific-command\"\ntype = \"shell\"\ncommand = \"\"\"\necho \"Processing {{ imbi_project.name }}\"\necho \"Type: {{ imbi_project.project_type }}\"\necho \"Namespace: {{ imbi_project.namespace }}\"\n\"\"\"\n</code></pre>"},{"location":"actions/shell/#conditional-logic-with-jinja2","title":"Conditional Logic with Jinja2","text":"<pre><code>[[actions]]\nname = \"environment-specific-deploy\"\ntype = \"shell\"\ncommand = \"\"\"\n{% if imbi_project.project_type == 'api' %}\n  python deploy_api.py\n{% elif imbi_project.project_type == 'consumer' %}\n  python deploy_consumer.py\n{% else %}\n  echo \"Unknown project type\"\n{% endif %}\n\"\"\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/shell/#using-project-facts","title":"Using Project Facts","text":"<pre><code>[[actions]]\nname = \"language-specific-test\"\ntype = \"shell\"\ncommand = \"\"\"\n{% if imbi_project.facts.get('Programming Language') == 'Python 3.12' %}\n  pytest tests/ --python=3.12\n{% elif imbi_project.facts.get('Programming Language') == 'Python 3.11' %}\n  pytest tests/ --python=3.11\n{% endif %}\n\"\"\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/shell/#iterating-over-lists","title":"Iterating Over Lists","text":"<pre><code>[[actions]]\nname = \"install-dependencies\"\ntype = \"shell\"\ncommand = \"\"\"\n{% for dep in dependencies %}\npip install {{ dep }}\n{% endfor %}\n\"\"\"\nworking_directory = \"repository:///\"\n</code></pre>"},{"location":"actions/shell/#path-resolution","title":"Path Resolution","text":"<p>Working directory supports all ResourceUrl schemes:</p> <pre><code># Repository directory\n[[actions]]\ntype = \"shell\"\ncommand = \"ls -la\"\nworking_directory = \"repository:///\"\n\n# Workflow directory\n[[actions]]\ntype = \"shell\"\ncommand = \"cat templates/README.md\"\nworking_directory = \"workflow:///\"\n\n# Extracted files directory\n[[actions]]\ntype = \"shell\"\ncommand = \"find . -name '*.conf'\"\nworking_directory = \"extracted:///\"\n\n# Explicit working directory path\n[[actions]]\ntype = \"shell\"\ncommand = \"pwd\"\nworking_directory = \"{{ working_directory }}/repository\"\n</code></pre>"},{"location":"actions/shell/#command-output","title":"Command Output","text":""},{"location":"actions/shell/#captured-output","title":"Captured Output","text":"<ul> <li>stdout: Logged at DEBUG level</li> <li>stderr: Logged at DEBUG level</li> <li>Exit Code: Non-zero exit codes cause workflow failure (unless <code>ignore_failure = true</code>)</li> </ul>"},{"location":"actions/shell/#output-in-logs","title":"Output in Logs","text":"<pre><code># Logger output example:\nDEBUG: Executing shell command: pytest tests/ -v\nDEBUG: Command stdout: ===== test session starts =====\nDEBUG: Command stderr:\nDEBUG: Command exit code: 0\n</code></pre>"},{"location":"actions/shell/#error-handling","title":"Error Handling","text":""},{"location":"actions/shell/#exit-code-handling","title":"Exit Code Handling","text":"<pre><code># Fail workflow on error (default)\n[[actions]]\nname = \"critical-command\"\ntype = \"shell\"\ncommand = \"important-operation\"\n# Fails workflow if exit code != 0\n\n# Continue on error\n[[actions]]\nname = \"optional-command\"\ntype = \"shell\"\ncommand = \"optional-operation\"\nignore_errors = true  # Continues even if exit code != 0\n</code></pre>"},{"location":"actions/shell/#command-not-found","title":"Command Not Found","text":"<pre><code>[[actions]]\nname = \"missing-command\"\ntype = \"shell\"\ncommand = \"nonexistent-command\"\n# Raises FileNotFoundError: Command not found: nonexistent-command\n</code></pre>"},{"location":"actions/shell/#security-considerations","title":"Security Considerations","text":""},{"location":"actions/shell/#command-injection-prevention","title":"Command Injection Prevention","text":"<p>Template variables are NOT shell-escaped automatically. Be cautious with user-provided data:</p> <pre><code># UNSAFE - if imbi_project.name contains shell metacharacters\n[[actions]]\ntype = \"shell\"\ncommand = \"echo {{ imbi_project.name }}\"\n\n# SAFER - use quotes\n[[actions]]\ntype = \"shell\"\ncommand = \"echo '{{ imbi_project.name }}'\"\n\n# SAFEST - avoid untrusted input in shell commands\n</code></pre>"},{"location":"actions/shell/#environment-variables","title":"Environment Variables","text":"<p>Commands execute with the same environment as the workflow process. Note that environment variables in the command string itself are NOT expanded (no shell):</p> <pre><code>[[actions]]\nname = \"use-env-var\"\ntype = \"shell\"\ncommand = \"bash -c 'echo $HOME &amp;&amp; echo $USER'\"  # Need bash -c for shell features\n</code></pre>"},{"location":"actions/shell/#performance-tips","title":"Performance Tips","text":""},{"location":"actions/shell/#chaining-commands","title":"Chaining Commands","text":"<p>Important: Shell operators require wrapping the command in <code>bash -c</code> or <code>sh -c</code>:</p> <pre><code># Use &amp;&amp; for dependent commands (fail fast):\n[[actions]]\ntype = \"shell\"\ncommand = \"bash -c 'cd repository &amp;&amp; make build &amp;&amp; make test'\"\n\n# Use ; for independent commands (always run all):\n[[actions]]\ntype = \"shell\"\ncommand = \"bash -c 'make clean; make build; make test'\"\n</code></pre>"},{"location":"actions/shell/#background-processes","title":"Background Processes","text":"<p>Not recommended - commands block until completion. For long-running operations, consider using Docker actions instead.</p>"},{"location":"actions/shell/#implementation-notes","title":"Implementation Notes","text":"<ul> <li>Commands execute in a subprocess using <code>asyncio.create_subprocess_exec</code></li> <li>No shell by default: Commands are parsed with <code>shlex.split()</code> and executed directly</li> <li>Shell features require explicit shell: Use <code>bash -c '...'</code> or <code>sh -c '...'</code> for:</li> <li>Pipes (<code>|</code>), redirects (<code>&gt;</code>, <code>&lt;</code>), wildcards (<code>*</code>)</li> <li>Command chaining (<code>&amp;&amp;</code>, <code>||</code>, <code>;</code>)</li> <li>Environment variable expansion (<code>$VAR</code>)</li> <li>Built-in shell commands (<code>cd</code>, <code>export</code>, etc.)</li> <li>Working directory resolved before command execution via <code>utils.resolve_path()</code></li> <li>Template rendering occurs before command execution</li> <li>Commands are parsed as shell-like arguments (respecting quotes and escapes)</li> <li>Default timeout of 1 hour (configurable via <code>timeout</code> field, see Action Timeouts)</li> <li>On timeout: Process terminated gracefully (SIGTERM \u2192 SIGKILL)</li> <li>stdout and stderr captured and logged at DEBUG level</li> <li>Non-zero exit codes raise <code>subprocess.CalledProcessError</code> (unless <code>ignore_errors=true</code>)</li> </ul>"},{"location":"actions/stages/","title":"Action Stages","text":"<p>Action stages allow workflows to execute actions in distinct phases, enabling powerful patterns like CI monitoring, automated feedback response, and iterative fixes.</p>"},{"location":"actions/stages/#overview","title":"Overview","text":"<p>Actions support a <code>stage</code> field with two values:</p> Stage Execution Time Use Case <code>primary</code> (default) Before PR creation Standard workflow actions - code changes, file updates <code>followup</code> After PR creation CI monitoring, reviewer feedback, automated fixes"},{"location":"actions/stages/#execution-flow","title":"Execution Flow","text":"<pre><code>1. Setup working directory\n2. Check conditions, clone repository\n3. Execute PRIMARY stage actions (with commits)\n4. Create PR or push changes\n5. Execute FOLLOWUP stage actions (with cycling)\n6. Cleanup\n</code></pre>"},{"location":"actions/stages/#primary-stage","title":"Primary Stage","text":"<p>Primary actions execute sequentially before any PR is created:</p> <pre><code>[[actions]]\nname = \"update-dependencies\"\ntype = \"claude\"\n# stage = \"primary\"  # Default, can be omitted\ntask_prompt = \"prompts/update-deps.md.j2\"\n\n[[actions]]\nname = \"run-tests\"\ntype = \"shell\"\ncommand = \"pytest tests/\"\n</code></pre> <ul> <li>Execute in order defined in workflow</li> <li>Each action can commit changes</li> <li>PR created after all primary actions complete</li> </ul>"},{"location":"actions/stages/#followup-stage","title":"Followup Stage","text":"<p>Followup actions execute after the PR is created:</p> <pre><code>[[actions]]\nname = \"monitor-ci\"\ntype = \"claude\"\nstage = \"followup\"\ntask_prompt = \"prompts/monitor-ci.md.j2\"\ncommittable = true  # Can commit fixes\n</code></pre> <p>Followup Behavior: </p> <ol> <li>All followup actions execute in sequence</li> <li>If any action commits, changes push to PR branch</li> <li>If commits were made, followup stage cycles again</li> <li>Cycles continue until no commits or max cycles reached</li> <li>If max cycles reached, workflow fails</li> </ol>"},{"location":"actions/stages/#configuration","title":"Configuration","text":""},{"location":"actions/stages/#workflow-level-settings","title":"Workflow-Level Settings","text":"<pre><code>name = \"update-and-monitor\"\n\n# Maximum followup cycles (default: 5)\nmax_followup_cycles = 3\n\n[github]\ncreate_pull_request = true\n</code></pre>"},{"location":"actions/stages/#action-level-settings","title":"Action-Level Settings","text":"<pre><code>[[actions]]\nname = \"monitor-ci\"\ntype = \"claude\"\nstage = \"followup\"           # Execute after PR creation\ntask_prompt = \"prompts/monitor.md.j2\"\ncommittable = true           # Allow commits (enables cycling)\nai_commit = true             # AI-generated commit messages\n</code></pre>"},{"location":"actions/stages/#template-context","title":"Template Context","text":"<p>Followup actions receive additional context variables:</p>"},{"location":"actions/stages/#pull_request-githubpullrequest","title":"<code>pull_request</code> (GitHubPullRequest)","text":"<p>Full PR model with fields:</p> <pre><code>PR Number: {{ pull_request.number }}\nPR URL: {{ pull_request.html_url }}\nPR State: {{ pull_request.state }}\nHead SHA: {{ pull_request.head.sha }}\nHead Ref: {{ pull_request.head.ref }}\nBase Ref: {{ pull_request.base.ref }}\nMergeable: {{ pull_request.mergeable }}\nMergeable State: {{ pull_request.mergeable_state }}\n</code></pre>"},{"location":"actions/stages/#pr_branch-str","title":"<code>pr_branch</code> (str)","text":"<p>Branch name for the PR:</p> <pre><code>Branch: {{ pr_branch }}\n</code></pre>"},{"location":"actions/stages/#example-followup-prompt","title":"Example Followup Prompt","text":"<pre><code># Monitor CI and Fix Issues\n\nYou are monitoring PR #{{ pull_request.number }} in {{ github_repository.full_name }}.\n\n**PR URL:** {{ pull_request.html_url }}\n**Branch:** {{ pr_branch }}\n**Head SHA:** {{ pull_request.head.sha }}\n\n## Your Task\n\n1. Check GitHub Actions workflow status for this PR\n2. If CI is still running, report status and wait\n3. If CI passed, report success (no changes needed)\n4. If CI failed:\n   - Analyze failure logs\n   - Identify root cause\n   - Make targeted fixes\n   - Commit changes\n\nUse `gh` CLI to check workflow status:\n```bash\ngh run list --branch {{ pr_branch }} --limit 1\ngh run view &lt;run-id&gt; --log-failed\n</code></pre> <p>If you make fixes, ensure they are minimal and targeted. <pre><code>## Use Cases\n\n### 1. CI Monitoring\n\nMonitor GitHub Actions and fix failures:\n\n```toml\n[[actions]]\nname = \"update-code\"\ntype = \"claude\"\ntask_prompt = \"prompts/update.md.j2\"\n\n[[actions]]\nname = \"monitor-ci\"\ntype = \"claude\"\nstage = \"followup\"\ntask_prompt = \"prompts/monitor-ci.md.j2\"\ncommittable = true\nmax_cycles = 5\n</code></pre></p>"},{"location":"actions/stages/#2-reviewer-feedback-response","title":"2. Reviewer Feedback Response","text":"<p>Respond to automated code review comments:</p> <pre><code>[[actions]]\nname = \"refactor-code\"\ntype = \"claude\"\ntask_prompt = \"prompts/refactor.md.j2\"\n\n[[actions]]\nname = \"respond-to-feedback\"\ntype = \"claude\"\nstage = \"followup\"\ntask_prompt = \"prompts/respond-feedback.md.j2\"\ncommittable = true\n</code></pre>"},{"location":"actions/stages/#3-test-verification","title":"3. Test Verification","text":"<p>Wait for tests and fix any failures:</p> <pre><code>[[actions]]\nname = \"migrate-dependencies\"\ntype = \"claude\"\ntask_prompt = \"prompts/migrate.md.j2\"\n\n[[actions]]\nname = \"verify-tests\"\ntype = \"claude\"\nstage = \"followup\"\ntask_prompt = \"prompts/verify-tests.md.j2\"\ncommittable = true\nmax_cycles = 3\n</code></pre>"},{"location":"actions/stages/#cycling-behavior","title":"Cycling Behavior","text":""},{"location":"actions/stages/#when-cycling-occurs","title":"When Cycling Occurs","text":"<p>Followup stage cycles when:</p> <ol> <li>A followup action with <code>committable = true</code> creates a commit</li> <li>The commit is pushed to the PR branch</li> <li>The stage restarts from the first followup action</li> </ol>"},{"location":"actions/stages/#cycle-completion","title":"Cycle Completion","text":"<p>A cycle completes successfully when:</p> <ul> <li>All followup actions execute without error</li> <li>No commits are made during the cycle</li> </ul>"},{"location":"actions/stages/#max-cycles","title":"Max Cycles","text":"<p>If <code>max_followup_cycles</code> is reached:</p> <ul> <li>Workflow fails with RuntimeError</li> <li>Error message indicates max cycles exceeded</li> <li><code>preserve_on_error</code> can save state for debugging</li> </ul> <pre><code>max_followup_cycles = 3  # Fail after 3 cycles with commits\n</code></pre>"},{"location":"actions/stages/#error-handling","title":"Error Handling","text":""},{"location":"actions/stages/#primary-stage-failure","title":"Primary Stage Failure","text":"<p>If a primary action fails:</p> <ul> <li>Followup stage is skipped entirely</li> <li>Normal error handling applies</li> <li><code>preserve_on_error</code> saves state</li> </ul>"},{"location":"actions/stages/#followup-stage-failure","title":"Followup Stage Failure","text":"<p>If a followup action fails:</p> <ul> <li>Workflow fails immediately</li> <li><code>preserve_on_error</code> saves state</li> <li>PR remains open for manual intervention</li> </ul>"},{"location":"actions/stages/#dry-run-mode","title":"Dry-Run Mode","text":"<p>In <code>--dry-run</code> mode:</p> <ul> <li>Primary actions execute normally</li> <li>Followup actions are skipped (no PR exists)</li> <li>Warning logged about skipped followup actions</li> </ul>"},{"location":"actions/stages/#best-practices","title":"Best Practices","text":""},{"location":"actions/stages/#1-keep-followup-actions-focused","title":"1. Keep Followup Actions Focused","text":"<p>Each followup action should have a single responsibility:</p> <pre><code># Good: Focused actions\n[[actions]]\nname = \"check-ci-status\"\nstage = \"followup\"\n\n[[actions]]\nname = \"fix-lint-errors\"\nstage = \"followup\"\n\n# Avoid: Monolithic actions\n[[actions]]\nname = \"monitor-everything\"  # Too broad\nstage = \"followup\"\n</code></pre>"},{"location":"actions/stages/#2-set-reasonable-max-cycles","title":"2. Set Reasonable Max Cycles","text":"<p>Balance automation with safety:</p> <pre><code># Too low: May not complete complex fixes\nmax_followup_cycles = 1\n\n# Too high: May loop indefinitely on unfixable issues\nmax_followup_cycles = 20\n\n# Good: Reasonable limit with room for iteration\nmax_followup_cycles = 5\n</code></pre>"},{"location":"actions/stages/#3-use-conditional-commits","title":"3. Use Conditional Commits","text":"<p>Only commit when changes are actually needed:</p> <pre><code>## Instructions\n\n1. Check CI status\n2. If all checks pass, report success (no commit needed)\n3. Only commit if you made actual fixes\n</code></pre>"},{"location":"actions/stages/#4-provide-clear-exit-conditions","title":"4. Provide Clear Exit Conditions","text":"<p>Define when followup should stop:</p> <pre><code>## Success Criteria\n\n- All CI checks pass\n- No open review comments\n- Tests pass\n\n## When to Stop\n\nReturn without committing if:\n- CI is passing\n- No actionable feedback exists\n</code></pre>"},{"location":"actions/stages/#complete-example","title":"Complete Example","text":"<pre><code>name = \"Update Python Version with CI Monitoring\"\ndescription = \"Update Python version and monitor CI for failures\"\nmax_followup_cycles = 5\n\n[filter]\nproject_types = [\"api\"]\nproject_facts = {\"Programming Language\" = \"Python 3.11\"}\n\n[github]\ncreate_pull_request = true\n\n# Primary stage: Make changes\n[[actions]]\nname = \"update-python-version\"\ntype = \"claude\"\ntask_prompt = \"prompts/update-python.md.j2\"\nvalidation_prompt = \"prompts/validate-update.md.j2\"\n\n# Followup stage: Monitor and fix\n[[actions]]\nname = \"monitor-ci\"\ntype = \"claude\"\nstage = \"followup\"\ntask_prompt = \"prompts/monitor-ci.md.j2\"\ncommittable = true\nai_commit = true\n\n[[actions]]\nname = \"respond-to-reviews\"\ntype = \"claude\"\nstage = \"followup\"\ntask_prompt = \"prompts/respond-reviews.md.j2\"\ncommittable = true\nai_commit = true\n</code></pre>"},{"location":"actions/stages/#see-also","title":"See Also","text":"<ul> <li>Workflow Configuration - <code>max_followup_cycles</code> setting</li> <li>Claude Actions - AI-powered transformations</li> <li>Templating - PR context variables</li> <li>Workflows - Workflow overview</li> </ul>"},{"location":"actions/template/","title":"Template Actions","text":"<p>Template actions render Jinja2 templates with full workflow context, enabling dynamic file generation for configurations, documentation, and code files.</p>"},{"location":"actions/template/#configuration","title":"Configuration","text":"<pre><code>[[actions]]\nname = \"action-name\"\ntype = \"template\"\nsource_path = \"template-file-or-directory\"\ndestination_path = \"output-location\"\n</code></pre> <p>Path Schemes</p> <p>Template actions use path schemes for <code>source_path</code> and <code>destination_path</code>. See the Path Schemes guide for details on all available schemes.</p>"},{"location":"actions/template/#fields","title":"Fields","text":""},{"location":"actions/template/#source_path-required","title":"source_path (required)","text":"<p>Path to template file or directory. Can be:</p> <ul> <li>Single <code>.j2</code> template file</li> <li>Directory containing <code>.j2</code> files (recursively rendered)</li> </ul> <p>Type: <code>ResourceUrl</code> (string path)</p> <p>Conventions: </p> <ul> <li>Template files should use <code>.j2</code> extension</li> <li>Directory paths should NOT include wildcards</li> <li>Relative to working directory by default</li> <li>Usually prefixed with <code>workflow:///</code> for workflow resources</li> </ul>"},{"location":"actions/template/#destination_path-required","title":"destination_path (required)","text":"<p>Output location for rendered templates.</p> <p>Type: <code>ResourceUrl</code> (string path)</p> <p>Behavior: </p> <ul> <li>For single file: Output file path</li> <li>For directory: Output directory (structure mirrored)</li> <li>Parent directories created automatically</li> <li>Existing files overwritten</li> </ul>"},{"location":"actions/template/#template-context","title":"Template Context","text":"<p>Templates have access to all workflow context variables:</p> Variable Type Description <code>workflow</code> <code>Workflow</code> Current workflow configuration <code>imbi_project</code> <code>ImbiProject</code> Complete Imbi project data <code>github_repository</code> <code>GitHubRepository</code> GitHub repo data (if applicable) <code>working_directory</code> <code>Path</code> Workflow execution directory <code>starting_commit</code> <code>str</code> Initial Git commit SHA"},{"location":"actions/template/#examples","title":"Examples","text":""},{"location":"actions/template/#single-file-template","title":"Single File Template","text":"<p>Workflow config: <pre><code>[[actions]]\nname = \"generate-readme\"\ntype = \"template\"\nsource_path = \"workflow:///templates/README.md.j2\"\ndestination_path = \"repository:///README.md\"\n</code></pre></p> <p>Template (<code>templates/README.md.j2</code>): <pre><code># {{ imbi_project.name }}\n\n{{ imbi_project.description }}\n\n## Project Information\n\n- **Type**: {{ imbi_project.project_type }}\n- **Namespace**: {{ imbi_project.namespace }}\n- **Imbi URL**: {{ imbi_project.imbi_url }}\n\n{% if github_repository %}\n## Repository\n\n- **GitHub**: {{ github_repository.html_url }}\n- **Default Branch**: {{ github_repository.default_branch }}\n{% endif %}\n\n## Installation\n\n```bash\npip install {{ imbi_project.slug }}\n</code></pre></p> <p>Generated by {{ workflow.configuration.name }} on {{ now() }} <pre><code>### Directory Template\n\n**Workflow config:**\n```toml\n[[actions]]\nname = \"render-configs\"\ntype = \"template\"\nsource_path = \"workflow:///templates/configs\"\ndestination_path = \"repository:///config/\"\n</code></pre></p> <p>Directory structure: <pre><code>workflow/templates/configs/\n\u251c\u2500\u2500 app.yaml.j2\n\u251c\u2500\u2500 database.yaml.j2\n\u2514\u2500\u2500 logging.yaml.j2\n</code></pre></p> <p>Result: <pre><code>repository/config/\n\u251c\u2500\u2500 app.yaml\n\u251c\u2500\u2500 database.yaml\n\u2514\u2500\u2500 logging.yaml\n</code></pre></p>"},{"location":"actions/template/#github-actions-workflow-template","title":"GitHub Actions Workflow Template","text":"<p>Workflow config: <pre><code>[[actions]]\nname = \"generate-ci-workflow\"\ntype = \"template\"\nsource_path = \"workflow:///ci-template.yml.j2\"\ndestination_path = \"repository:///.github/workflows/ci.yml\"\n</code></pre></p> <p>Template: <pre><code>name: CI\n\non:\n  push:\n    branches: [ {{ github_repository.default_branch }} ]\n  pull_request:\n    branches: [ {{ github_repository.default_branch }} ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      {% if imbi_project.facts.get('Programming Language', '').startswith('Python') %}\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: '{{ imbi_project.facts['Programming Language'].split()[-1] }}'\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          pip install -e .[dev]\n\n      - name: Run tests\n        run: pytest tests/ -v\n      {% elif imbi_project.facts.get('Programming Language') == 'JavaScript' %}\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm test\n      {% endif %}\n</code></pre></p>"},{"location":"actions/template/#dockerfile-template","title":"Dockerfile Template","text":"<p>Workflow config: <pre><code>[[actions]]\nname = \"generate-dockerfile\"\ntype = \"template\"\nsource_path = \"workflow:///Dockerfile.j2\"\ndestination_path = \"repository:///Dockerfile\"\n</code></pre></p> <p>Template: <pre><code>{% set python_version = imbi_project.facts.get('Programming Language', 'Python 3.12').split()[-1] %}\nFROM python:{{ python_version }}-slim\n\nLABEL maintainer=\"{{ imbi_project.namespace }}\"\nLABEL project=\"{{ imbi_project.slug }}\"\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\n{% if imbi_project.project_type == 'api' %}\nCMD [\"uvicorn\", \"{{ imbi_project.slug }}.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n{% elif imbi_project.project_type == 'consumer' %}\nCMD [\"python\", \"-m\", \"{{ imbi_project.slug }}.consumer\"]\n{% else %}\nCMD [\"python\", \"-m\", \"{{ imbi_project.slug }}\"]\n{% endif %}\n</code></pre></p>"},{"location":"actions/template/#jinja2-template-features","title":"Jinja2 Template Features","text":""},{"location":"actions/template/#variables","title":"Variables","text":"<pre><code>{{ imbi_project.name }}\n{{ imbi_project.slug }}\n{{ workflow.configuration.name }}\n</code></pre>"},{"location":"actions/template/#conditionals","title":"Conditionals","text":"<pre><code>{% if imbi_project.project_type == 'api' %}\n  API-specific content\n{% elif imbi_project.project_type == 'consumer' %}\n  Consumer-specific content\n{% else %}\n  Default content\n{% endif %}\n</code></pre>"},{"location":"actions/template/#loops","title":"Loops","text":"<pre><code>{% for env in imbi_project.environments %}\n- {{ env.name }}: {{ env.url }}\n{% endfor %}\n</code></pre>"},{"location":"actions/template/#filters","title":"Filters","text":"<pre><code>{{ imbi_project.name | upper }}\n{{ imbi_project.slug | replace('-', '_') }}\n{{ imbi_project.description | truncate(100) }}\n</code></pre>"},{"location":"actions/template/#tests","title":"Tests","text":"<pre><code>{% if github_repository is defined %}\n  Has GitHub repository\n{% endif %}\n\n{% if imbi_project.facts %}\n  Has facts defined\n{% endif %}\n</code></pre>"},{"location":"actions/template/#comments","title":"Comments","text":"<pre><code>{# This is a comment - won't appear in output #}\n{{ imbi_project.name }}  {# inline comment #}\n</code></pre>"},{"location":"actions/template/#common-patterns","title":"Common Patterns","text":""},{"location":"actions/template/#configuration-file-generation","title":"Configuration File Generation","text":"<pre><code>[[actions]]\nname = \"generate-app-config\"\ntype = \"template\"\nsource_path = \"workflow:///app.yaml.j2\"\ndestination_path = \"repository:///config/app.yaml\"\n</code></pre> <p>Template: <pre><code>application:\n  name: {{ imbi_project.slug }}\n  type: {{ imbi_project.project_type }}\n\n{% if imbi_project.environments %}\nenvironments:\n{% for env in imbi_project.environments %}\n  {{ env.name }}:\n    url: {{ env.url }}\n    enabled: true\n{% endfor %}\n{% endif %}\n\ndatabase:\n  host: ${DB_HOST}\n  port: ${DB_PORT}\n  name: {{ imbi_project.slug | replace('-', '_') }}\n</code></pre></p>"},{"location":"actions/template/#multi-file-template-directory","title":"Multi-File Template Directory","text":"<pre><code>[[actions]]\nname = \"generate-all-configs\"\ntype = \"template\"\nsource_path = \"workflow:///templates\"\ndestination_path = \"repository:///config/\"\n</code></pre> <p>Template directory: <pre><code>workflow/templates/\n\u251c\u2500\u2500 app.yaml.j2\n\u251c\u2500\u2500 database.yaml.j2\n\u251c\u2500\u2500 logging.yaml.j2\n\u2514\u2500\u2500 monitoring.yaml.j2\n</code></pre></p>"},{"location":"actions/template/#documentation-generation","title":"Documentation Generation","text":"<pre><code>[[actions]]\nname = \"generate-docs\"\ntype = \"template\"\nsource_path = \"workflow:///docs\"\ndestination_path = \"repository:///docs/\"\n</code></pre> <p>Template: <pre><code># {{ imbi_project.name }} Documentation\n\n## Overview\n{{ imbi_project.description }}\n\n## Quick Start\n\n### Installation\n```bash\npip install {{ imbi_project.slug }}\n</code></pre></p>"},{"location":"actions/template/#usage","title":"Usage","text":"<pre><code>from {{ imbi_project.slug | replace('-', '_') }} import main\n\nmain()\n</code></pre>"},{"location":"actions/template/#api-reference","title":"API Reference","text":"<p>{% if imbi_project.project_type == 'api' %} The API is available at: <code>https://{{ imbi_project.slug }}.example.com/api</code> {% endif %}</p>"},{"location":"actions/template/#contributing","title":"Contributing","text":"<p>Contributions welcome! See CONTRIBUTING.md in the repository for details.</p> <p>Generated from template by {{ workflow.configuration.name }} <pre><code>## Advanced Templates\n\n### Accessing Nested Data\n\n```jinja2\n{# Access project facts #}\n{% if 'Programming Language' in imbi_project.facts %}\nLanguage: {{ imbi_project.facts['Programming Language'] }}\n{% endif %}\n\n{# Access GitHub repository details #}\n{% if github_repository %}\nStars: {{ github_repository.stargazers_count }}\nForks: {{ github_repository.forks_count }}\n{% endif %}\n</code></pre></p>"},{"location":"actions/template/#template-inheritance","title":"Template Inheritance","text":"<p>Base template (<code>base.j2</code>): <pre><code># {{ imbi_project.name }}\n\n{% block content %}\nDefault content\n{% endblock %}\n\n---\nGenerated by {{ workflow.configuration.name }}\n</code></pre></p> <p>Child template (<code>readme.j2</code>): <pre><code>{% extends \"base.j2\" %}\n\n{% block content %}\n## Description\n{{ imbi_project.description }}\n\n## Installation\npip install {{ imbi_project.slug }}\n{% endblock %}\n</code></pre></p>"},{"location":"actions/template/#macros","title":"Macros","text":"<pre><code>{% macro render_environment(env) %}\n## {{ env.name | title }}\n- URL: {{ env.url }}\n- Active: {{ env.active | default(true) }}\n{% endmacro %}\n\n# Environments\n\n{% for env in imbi_project.environments %}\n{{ render_environment(env) }}\n{% endfor %}\n</code></pre>"},{"location":"actions/template/#custom-filters","title":"Custom Filters","text":"<pre><code>{# Convert kebab-case to snake_case #}\n{{ imbi_project.slug | replace('-', '_') }}\n\n{# Convert to SCREAMING_SNAKE_CASE #}\n{{ imbi_project.slug | replace('-', '_') | upper }}\n\n{# Truncate long descriptions #}\n{{ imbi_project.description | truncate(100, True, '...') }}\n</code></pre>"},{"location":"actions/template/#path-resolution","title":"Path Resolution","text":"<p>Both source and destination support ResourceUrl schemes:</p> <pre><code># Workflow templates to repository\n[[actions]]\ntype = \"template\"\nsource_path = \"workflow:///templates/\"\ndestination_path = \"repository:///config/\"\n\n# Specific file paths\n[[actions]]\ntype = \"template\"\nsource_path = \"workflow:///README.md.j2\"\ndestination_path = \"repository:///README.md\"\n\n# Extracted data with templates\n[[actions]]\ntype = \"template\"\nsource_path = \"workflow:///process-extracted.j2\"\ndestination_path = \"extracted:///processed/output.txt\"\n</code></pre>"},{"location":"actions/template/#error-handling","title":"Error Handling","text":"<p>Template actions raise errors for:</p> <ul> <li>Missing source: Source file/directory doesn't exist</li> <li>Template syntax errors: Invalid Jinja2 syntax</li> <li>Undefined variables: Referenced variables not in context</li> <li>I/O errors: Permission denied, disk full, etc.</li> </ul>"},{"location":"actions/template/#handling-undefined-variables","title":"Handling Undefined Variables","text":"<p>Strict mode (default - raises error): <pre><code>{{ undefined_variable }}  {# Raises error #}\n</code></pre></p> <p>Graceful fallback: <pre><code>{{ undefined_variable | default('fallback value') }}\n{{ undefined_variable | default('') }}\n</code></pre></p> <p>Check before use: <pre><code>{% if undefined_variable is defined %}\n  {{ undefined_variable }}\n{% endif %}\n</code></pre></p>"},{"location":"actions/template/#implementation-notes","title":"Implementation Notes","text":"<ul> <li>Templates rendered using Jinja2 with StrictUndefined by default</li> <li>Context variables automatically passed via <code>context.model_dump()</code> in <code>prompts.render()</code></li> <li><code>.j2</code> extension NOT automatically removed from output filenames</li> <li>Directory rendering is recursive via <code>source_path.rglob('*')</code></li> <li>Existing files overwritten without warning</li> <li>Parent directories created automatically with <code>mkdir(parents=True, exist_ok=True)</code></li> <li>File permissions NOT explicitly preserved (uses default umask)</li> <li>Template context is immutable during rendering</li> <li>All Jinja2 built-in filters and tests available</li> <li>Custom template functions: <code>extract_image_from_dockerfile</code>, <code>extract_package_name_from_pyproject</code>, <code>get_component_version</code>, <code>python_init_file_path</code>, <code>read_file</code>, <code>compare_semver</code></li> </ul> <p>Implementation Location: <code>src/imbi_automations/actions/template.py:24-101</code></p>"},{"location":"actions/template/#best-practices","title":"Best Practices","text":"<ol> <li>Use <code>.j2</code> extension: Makes templates easily identifiable</li> <li>Provide defaults: Use <code>| default()</code> for optional values</li> <li>Check existence: Test <code>is defined</code> before accessing optional data</li> <li>Document templates: Add comments explaining template logic</li> <li>Test templates: Verify output with sample data before production</li> <li>Version control: Keep templates in workflow resources</li> <li>Validate output: Use shell actions to validate generated configs</li> </ol>"}]}